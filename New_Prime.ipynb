{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce7fdeb5-b886-48c8-9991-6796f7dd3325",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f40e7fc4-5236-44ae-ac90-ca6e0ec9e2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import argparse \n",
    "from pathlib import Path\n",
    "import os \n",
    "\n",
    "# Datasets \n",
    "from dataset import ImageNet, CIFAR10, CIFAR100\n",
    "from train_eval import Train_Eval\n",
    "\n",
    "# Models \n",
    "from models.allconvnet import AllConvNet \n",
    "\n",
    "# Utilities \n",
    "from utils import write_to_file, set_seed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8fadb61-27d5-4d06-82a6-c2dbaae55b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: /mnt/research/j.farias/mkang2/Convolutional-Nearest-Neighbor\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"Current directory:\", os.getcwd())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240f5f14-92f5-42d9-b474-6397acaaf600",
   "metadata": {},
   "source": [
    "### I. CONTROL Conv2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9059b00a-db01-4228-a4a2-8516c0d57734",
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import SimpleNamespace\n",
    "\n",
    "# Create default args\n",
    "args = SimpleNamespace(\n",
    "    layer=\"Conv2d\",\n",
    "    num_layers=3,\n",
    "    channels=[8, 16, 32],\n",
    "    K=9,\n",
    "    kernel_size=3,\n",
    "    sampling_type=\"all\",\n",
    "    num_samples=-1,\n",
    "    sample_padding=0,\n",
    "    num_heads=4,\n",
    "    attention_dropout=0.1,\n",
    "    shuffle_pattern=\"BA\",\n",
    "    shuffle_scale=2,\n",
    "    magnitude_type=\"similarity\",\n",
    "    coordinate_encoding=False,\n",
    "    dataset=\"cifar10\",\n",
    "    data_path=\"./Data\",\n",
    "    batch_size=64,\n",
    "    num_epochs=100,\n",
    "    use_amp=False,\n",
    "    clip_grad_norm=None,\n",
    "    criterion=\"CrossEntropy\",\n",
    "    optimizer=\"adamw\",\n",
    "    momentum=0.9,\n",
    "    weight_decay=1e-6,\n",
    "    lr=1e-3,\n",
    "    lr_step=20,\n",
    "    lr_gamma=0.1,\n",
    "    scheduler=\"step\",\n",
    "    device=\"cuda\",\n",
    "    seed=0,\n",
    "    output_dir=\"./Output/Simple/Conv2d_Control\", \n",
    "    resize=False\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80de297f-0e39-4692-a851-d365bd994c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/local/python3.12/lib/python3.12/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upscale transform not defined. Skipping dataset upscale.\n",
      "Model: All Convolutional Network Conv2d\n",
      "Total Parameters: 6362\n",
      "Trainable Parameters: 6362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/local/python3.12/lib/python3.12/site-packages/torch/nn/modules/instancenorm.py:80: UserWarning: input's size at dim=1 does not match num_features. You can silence this warning by not passing in num_features, which is not used because affine=False\n",
      "  warnings.warn(f\"input's size at dim={feature_dim} does not match num_features. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 001] Time: 7.2123s | [Train] Loss: 2.01643919 Accuracy: Top1: 25.9211%, Top5: 76.5465% | [Test] Loss: 1.78093931 Accuracy: Top1: 37.7886%, Top5: 86.6740%\n",
      "[Epoch 002] Time: 6.9808s | [Train] Loss: 1.80737409 Accuracy: Top1: 33.8675%, Top5: 84.3950% | [Test] Loss: 1.67001616 Accuracy: Top1: 42.2373%, Top5: 88.5052%\n",
      "[Epoch 003] Time: 7.0129s | [Train] Loss: 1.74238550 Accuracy: Top1: 36.7807%, Top5: 86.1273% | [Test] Loss: 1.61141083 Accuracy: Top1: 44.2377%, Top5: 90.2070%\n",
      "[Epoch 004] Time: 7.2755s | [Train] Loss: 1.69237972 Accuracy: Top1: 38.7148%, Top5: 87.2822% | [Test] Loss: 1.57868538 Accuracy: Top1: 44.9542%, Top5: 90.6150%\n",
      "[Epoch 005] Time: 7.1388s | [Train] Loss: 1.65905210 Accuracy: Top1: 40.0036%, Top5: 87.9616% | [Test] Loss: 1.54086816 Accuracy: Top1: 45.5215%, Top5: 91.3416%\n",
      "[Epoch 006] Time: 7.1853s | [Train] Loss: 1.63314448 Accuracy: Top1: 40.9407%, Top5: 88.4970% | [Test] Loss: 1.52009429 Accuracy: Top1: 46.4471%, Top5: 91.5605%\n",
      "[Epoch 007] Time: 7.2083s | [Train] Loss: 1.60491312 Accuracy: Top1: 42.2494%, Top5: 89.1324% | [Test] Loss: 1.51447233 Accuracy: Top1: 47.6214%, Top5: 91.6003%\n",
      "[Epoch 008] Time: 7.1751s | [Train] Loss: 1.58285751 Accuracy: Top1: 43.2145%, Top5: 89.5820% | [Test] Loss: 1.47671975 Accuracy: Top1: 48.6564%, Top5: 92.0482%\n",
      "[Epoch 009] Time: 7.1046s | [Train] Loss: 1.56236836 Accuracy: Top1: 43.7960%, Top5: 89.8917% | [Test] Loss: 1.45782333 Accuracy: Top1: 50.3682%, Top5: 92.1576%\n",
      "[Epoch 010] Time: 7.2254s | [Train] Loss: 1.54427102 Accuracy: Top1: 44.8130%, Top5: 90.2873% | [Test] Loss: 1.44299075 Accuracy: Top1: 50.4379%, Top5: 92.6055%\n",
      "[Epoch 011] Time: 7.4725s | [Train] Loss: 1.52739167 Accuracy: Top1: 45.1586%, Top5: 90.6989% | [Test] Loss: 1.43358852 Accuracy: Top1: 51.0848%, Top5: 92.6752%\n",
      "[Epoch 012] Time: 7.2894s | [Train] Loss: 1.51165518 Accuracy: Top1: 45.8140%, Top5: 90.8128% | [Test] Loss: 1.40739007 Accuracy: Top1: 52.0303%, Top5: 93.1827%\n",
      "[Epoch 013] Time: 7.3475s | [Train] Loss: 1.50043898 Accuracy: Top1: 46.2076%, Top5: 91.1305% | [Test] Loss: 1.39635559 Accuracy: Top1: 52.1895%, Top5: 93.4514%\n",
      "[Epoch 014] Time: 7.1391s | [Train] Loss: 1.48735797 Accuracy: Top1: 46.6212%, Top5: 91.4542% | [Test] Loss: 1.38136732 Accuracy: Top1: 52.9359%, Top5: 93.7301%\n",
      "[Epoch 015] Time: 7.2752s | [Train] Loss: 1.47594666 Accuracy: Top1: 46.9829%, Top5: 91.6061% | [Test] Loss: 1.39006446 Accuracy: Top1: 51.2739%, Top5: 93.4912%\n",
      "[Epoch 016] Time: 7.2770s | [Train] Loss: 1.46052818 Accuracy: Top1: 47.8541%, Top5: 91.8159% | [Test] Loss: 1.37370516 Accuracy: Top1: 52.5577%, Top5: 94.0784%\n",
      "[Epoch 017] Time: 7.2347s | [Train] Loss: 1.45171090 Accuracy: Top1: 47.9939%, Top5: 91.9038% | [Test] Loss: 1.37267857 Accuracy: Top1: 52.4881%, Top5: 93.6505%\n",
      "[Epoch 018] Time: 7.3447s | [Train] Loss: 1.44391547 Accuracy: Top1: 48.2777%, Top5: 91.9897% | [Test] Loss: 1.34721856 Accuracy: Top1: 53.2643%, Top5: 94.0585%\n",
      "[Epoch 019] Time: 7.4092s | [Train] Loss: 1.43015652 Accuracy: Top1: 48.5953%, Top5: 92.3873% | [Test] Loss: 1.33977269 Accuracy: Top1: 54.3292%, Top5: 93.7699%\n",
      "[Epoch 020] Time: 7.3602s | [Train] Loss: 1.41847954 Accuracy: Top1: 49.3686%, Top5: 92.4373% | [Test] Loss: 1.33650809 Accuracy: Top1: 53.5430%, Top5: 93.7898%\n",
      "[Epoch 021] Time: 7.3532s | [Train] Loss: 1.39817375 Accuracy: Top1: 49.9441%, Top5: 92.9727% | [Test] Loss: 1.31060582 Accuracy: Top1: 55.0557%, Top5: 94.4566%\n",
      "[Epoch 022] Time: 7.2744s | [Train] Loss: 1.39641539 Accuracy: Top1: 50.1938%, Top5: 92.7130% | [Test] Loss: 1.31193808 Accuracy: Top1: 55.2249%, Top5: 94.4268%\n",
      "[Epoch 023] Time: 7.1675s | [Train] Loss: 1.39783299 Accuracy: Top1: 50.0819%, Top5: 92.9368% | [Test] Loss: 1.30863845 Accuracy: Top1: 54.7771%, Top5: 94.4168%\n",
      "[Epoch 024] Time: 7.2240s | [Train] Loss: 1.39239481 Accuracy: Top1: 50.1638%, Top5: 92.9088% | [Test] Loss: 1.30574235 Accuracy: Top1: 55.1951%, Top5: 94.3670%\n",
      "[Epoch 025] Time: 7.3059s | [Train] Loss: 1.39234947 Accuracy: Top1: 50.4036%, Top5: 92.7590% | [Test] Loss: 1.30617771 Accuracy: Top1: 54.8268%, Top5: 94.4765%\n",
      "[Epoch 026] Time: 7.2451s | [Train] Loss: 1.39240096 Accuracy: Top1: 50.2198%, Top5: 92.8509% | [Test] Loss: 1.30425475 Accuracy: Top1: 55.1055%, Top5: 94.3571%\n",
      "[Epoch 027] Time: 7.2353s | [Train] Loss: 1.39226607 Accuracy: Top1: 50.4136%, Top5: 92.7430% | [Test] Loss: 1.30597420 Accuracy: Top1: 55.1752%, Top5: 94.4964%\n",
      "[Epoch 028] Time: 7.2367s | [Train] Loss: 1.38984452 Accuracy: Top1: 50.5055%, Top5: 92.8768% | [Test] Loss: 1.30386859 Accuracy: Top1: 55.0657%, Top5: 94.5462%\n",
      "[Epoch 029] Time: 7.1932s | [Train] Loss: 1.39412912 Accuracy: Top1: 50.1858%, Top5: 92.6431% | [Test] Loss: 1.30231608 Accuracy: Top1: 55.1453%, Top5: 94.5064%\n",
      "[Epoch 030] Time: 7.2474s | [Train] Loss: 1.39011577 Accuracy: Top1: 50.4556%, Top5: 92.9348% | [Test] Loss: 1.30205288 Accuracy: Top1: 55.2050%, Top5: 94.3471%\n",
      "[Epoch 031] Time: 7.1966s | [Train] Loss: 1.38881332 Accuracy: Top1: 50.0639%, Top5: 92.9508% | [Test] Loss: 1.30013578 Accuracy: Top1: 55.0955%, Top5: 94.4566%\n",
      "[Epoch 032] Time: 7.3064s | [Train] Loss: 1.38791948 Accuracy: Top1: 50.3656%, Top5: 92.8049% | [Test] Loss: 1.30086806 Accuracy: Top1: 55.2548%, Top5: 94.5362%\n",
      "[Epoch 033] Time: 7.2542s | [Train] Loss: 1.38461325 Accuracy: Top1: 50.4995%, Top5: 93.0327% | [Test] Loss: 1.30057381 Accuracy: Top1: 55.2050%, Top5: 94.4367%\n",
      "[Epoch 034] Time: 7.2772s | [Train] Loss: 1.38389985 Accuracy: Top1: 50.5155%, Top5: 92.9807% | [Test] Loss: 1.29724026 Accuracy: Top1: 55.4936%, Top5: 94.5263%\n",
      "[Epoch 035] Time: 7.3008s | [Train] Loss: 1.38482691 Accuracy: Top1: 50.5455%, Top5: 93.0187% | [Test] Loss: 1.29918489 Accuracy: Top1: 55.3941%, Top5: 94.5163%\n",
      "[Epoch 036] Time: 7.2374s | [Train] Loss: 1.38143720 Accuracy: Top1: 50.6574%, Top5: 93.0107% | [Test] Loss: 1.29483055 Accuracy: Top1: 55.5533%, Top5: 94.5064%\n",
      "[Epoch 037] Time: 7.2668s | [Train] Loss: 1.38288882 Accuracy: Top1: 50.5355%, Top5: 92.9228% | [Test] Loss: 1.29430905 Accuracy: Top1: 55.5732%, Top5: 94.4964%\n",
      "[Epoch 038] Time: 7.2789s | [Train] Loss: 1.38132431 Accuracy: Top1: 50.8911%, Top5: 93.0347% | [Test] Loss: 1.29327925 Accuracy: Top1: 55.7225%, Top5: 94.5163%\n",
      "[Epoch 039] Time: 7.2985s | [Train] Loss: 1.37904705 Accuracy: Top1: 50.7013%, Top5: 92.9348% | [Test] Loss: 1.29379628 Accuracy: Top1: 55.4538%, Top5: 94.4566%\n",
      "[Epoch 040] Time: 7.2933s | [Train] Loss: 1.38103901 Accuracy: Top1: 50.6614%, Top5: 93.0367% | [Test] Loss: 1.29541420 Accuracy: Top1: 55.5633%, Top5: 94.4168%\n",
      "[Epoch 041] Time: 7.2167s | [Train] Loss: 1.37789421 Accuracy: Top1: 50.7273%, Top5: 93.0347% | [Test] Loss: 1.29161280 Accuracy: Top1: 55.6230%, Top5: 94.5163%\n",
      "[Epoch 042] Time: 7.3305s | [Train] Loss: 1.37712117 Accuracy: Top1: 50.4895%, Top5: 93.0367% | [Test] Loss: 1.29101575 Accuracy: Top1: 55.6429%, Top5: 94.5362%\n",
      "[Epoch 043] Time: 7.2922s | [Train] Loss: 1.37560998 Accuracy: Top1: 50.9111%, Top5: 93.0447% | [Test] Loss: 1.29095214 Accuracy: Top1: 55.5633%, Top5: 94.5760%\n",
      "[Epoch 044] Time: 7.2983s | [Train] Loss: 1.37411518 Accuracy: Top1: 50.9591%, Top5: 93.2385% | [Test] Loss: 1.29035163 Accuracy: Top1: 55.6330%, Top5: 94.5362%\n",
      "[Epoch 045] Time: 7.2650s | [Train] Loss: 1.37646145 Accuracy: Top1: 50.9111%, Top5: 93.1406% | [Test] Loss: 1.29067938 Accuracy: Top1: 55.6429%, Top5: 94.5661%\n",
      "[Epoch 046] Time: 7.3307s | [Train] Loss: 1.37450818 Accuracy: Top1: 50.9711%, Top5: 93.1426% | [Test] Loss: 1.29063849 Accuracy: Top1: 55.6230%, Top5: 94.5959%\n",
      "[Epoch 047] Time: 7.3137s | [Train] Loss: 1.37571039 Accuracy: Top1: 50.7193%, Top5: 93.1266% | [Test] Loss: 1.29053248 Accuracy: Top1: 55.6429%, Top5: 94.5760%\n",
      "[Epoch 048] Time: 7.3664s | [Train] Loss: 1.37737263 Accuracy: Top1: 50.8392%, Top5: 93.0007% | [Test] Loss: 1.29077091 Accuracy: Top1: 55.5633%, Top5: 94.6158%\n",
      "[Epoch 049] Time: 7.3084s | [Train] Loss: 1.37701173 Accuracy: Top1: 50.9051%, Top5: 92.9967% | [Test] Loss: 1.29070972 Accuracy: Top1: 55.6230%, Top5: 94.5760%\n",
      "[Epoch 050] Time: 7.3694s | [Train] Loss: 1.37426969 Accuracy: Top1: 50.7533%, Top5: 93.1646% | [Test] Loss: 1.29039251 Accuracy: Top1: 55.6628%, Top5: 94.5860%\n",
      "[Epoch 051] Time: 7.1647s | [Train] Loss: 1.37495359 Accuracy: Top1: 51.0790%, Top5: 92.9688% | [Test] Loss: 1.28999979 Accuracy: Top1: 55.7225%, Top5: 94.5860%\n",
      "[Epoch 052] Time: 7.1994s | [Train] Loss: 1.37586656 Accuracy: Top1: 50.7773%, Top5: 92.9767% | [Test] Loss: 1.29071447 Accuracy: Top1: 55.5932%, Top5: 94.5362%\n",
      "[Epoch 053] Time: 7.2417s | [Train] Loss: 1.37254964 Accuracy: Top1: 51.0430%, Top5: 93.1186% | [Test] Loss: 1.28972527 Accuracy: Top1: 55.7225%, Top5: 94.5263%\n",
      "[Epoch 054] Time: 7.4218s | [Train] Loss: 1.37435150 Accuracy: Top1: 50.9751%, Top5: 93.0527% | [Test] Loss: 1.28991969 Accuracy: Top1: 55.6031%, Top5: 94.5661%\n",
      "[Epoch 055] Time: 6.6836s | [Train] Loss: 1.37792004 Accuracy: Top1: 50.8971%, Top5: 93.1186% | [Test] Loss: 1.28980667 Accuracy: Top1: 55.5732%, Top5: 94.5561%\n",
      "[Epoch 056] Time: 6.7296s | [Train] Loss: 1.37257021 Accuracy: Top1: 50.8192%, Top5: 93.1146% | [Test] Loss: 1.28959429 Accuracy: Top1: 55.5932%, Top5: 94.5959%\n",
      "[Epoch 057] Time: 6.7255s | [Train] Loss: 1.37440310 Accuracy: Top1: 50.9291%, Top5: 93.0067% | [Test] Loss: 1.28951048 Accuracy: Top1: 55.6827%, Top5: 94.5661%\n",
      "[Epoch 058] Time: 6.7416s | [Train] Loss: 1.37466119 Accuracy: Top1: 51.0290%, Top5: 93.1406% | [Test] Loss: 1.29020491 Accuracy: Top1: 55.7225%, Top5: 94.5860%\n",
      "[Epoch 059] Time: 6.8178s | [Train] Loss: 1.37406502 Accuracy: Top1: 50.8951%, Top5: 93.0367% | [Test] Loss: 1.28980275 Accuracy: Top1: 55.6728%, Top5: 94.5760%\n",
      "[Epoch 060] Time: 6.7035s | [Train] Loss: 1.37553706 Accuracy: Top1: 51.0570%, Top5: 92.9927% | [Test] Loss: 1.28962172 Accuracy: Top1: 55.7225%, Top5: 94.5362%\n",
      "[Epoch 061] Time: 6.4805s | [Train] Loss: 1.37529679 Accuracy: Top1: 51.0090%, Top5: 93.1346% | [Test] Loss: 1.28953235 Accuracy: Top1: 55.7026%, Top5: 94.5860%\n",
      "[Epoch 062] Time: 6.4838s | [Train] Loss: 1.37630287 Accuracy: Top1: 50.7872%, Top5: 93.0806% | [Test] Loss: 1.28949036 Accuracy: Top1: 55.7424%, Top5: 94.5760%\n",
      "[Epoch 063] Time: 6.3968s | [Train] Loss: 1.37608820 Accuracy: Top1: 50.7573%, Top5: 93.0507% | [Test] Loss: 1.28942995 Accuracy: Top1: 55.7026%, Top5: 94.5760%\n",
      "[Epoch 064] Time: 6.3938s | [Train] Loss: 1.37390319 Accuracy: Top1: 51.0310%, Top5: 93.0806% | [Test] Loss: 1.28944140 Accuracy: Top1: 55.7424%, Top5: 94.5959%\n",
      "[Epoch 065] Time: 6.6200s | [Train] Loss: 1.37463933 Accuracy: Top1: 50.9391%, Top5: 92.9807% | [Test] Loss: 1.28935298 Accuracy: Top1: 55.6827%, Top5: 94.5860%\n",
      "[Epoch 066] Time: 6.6870s | [Train] Loss: 1.37135453 Accuracy: Top1: 51.1629%, Top5: 93.0786% | [Test] Loss: 1.28932711 Accuracy: Top1: 55.7126%, Top5: 94.6158%\n",
      "[Epoch 067] Time: 6.5603s | [Train] Loss: 1.37301307 Accuracy: Top1: 50.8692%, Top5: 93.1805% | [Test] Loss: 1.28928717 Accuracy: Top1: 55.6529%, Top5: 94.5860%\n",
      "[Epoch 068] Time: 6.8522s | [Train] Loss: 1.37260787 Accuracy: Top1: 50.8412%, Top5: 93.0187% | [Test] Loss: 1.28926097 Accuracy: Top1: 55.6628%, Top5: 94.5860%\n",
      "[Epoch 069] Time: 6.7486s | [Train] Loss: 1.37428267 Accuracy: Top1: 50.9291%, Top5: 93.0167% | [Test] Loss: 1.28929952 Accuracy: Top1: 55.6628%, Top5: 94.5860%\n",
      "[Epoch 070] Time: 6.6125s | [Train] Loss: 1.37204106 Accuracy: Top1: 51.0470%, Top5: 93.1326% | [Test] Loss: 1.28923992 Accuracy: Top1: 55.6927%, Top5: 94.5959%\n",
      "[Epoch 071] Time: 6.5005s | [Train] Loss: 1.37102159 Accuracy: Top1: 50.9511%, Top5: 93.1506% | [Test] Loss: 1.28916219 Accuracy: Top1: 55.7026%, Top5: 94.5760%\n",
      "[Epoch 072] Time: 6.6416s | [Train] Loss: 1.37556569 Accuracy: Top1: 50.6813%, Top5: 93.1825% | [Test] Loss: 1.28912866 Accuracy: Top1: 55.6628%, Top5: 94.5561%\n",
      "[Epoch 073] Time: 6.5694s | [Train] Loss: 1.37336849 Accuracy: Top1: 51.1469%, Top5: 93.1126% | [Test] Loss: 1.28920375 Accuracy: Top1: 55.7026%, Top5: 94.5860%\n",
      "[Epoch 074] Time: 6.5664s | [Train] Loss: 1.37113837 Accuracy: Top1: 50.9731%, Top5: 93.0527% | [Test] Loss: 1.28909175 Accuracy: Top1: 55.6827%, Top5: 94.5561%\n",
      "[Epoch 075] Time: 6.5902s | [Train] Loss: 1.37131838 Accuracy: Top1: 51.1649%, Top5: 93.2105% | [Test] Loss: 1.28911300 Accuracy: Top1: 55.6827%, Top5: 94.5760%\n",
      "[Epoch 076] Time: 6.7578s | [Train] Loss: 1.37744150 Accuracy: Top1: 50.6574%, Top5: 92.9887% | [Test] Loss: 1.28915991 Accuracy: Top1: 55.6429%, Top5: 94.6059%\n",
      "[Epoch 077] Time: 6.5628s | [Train] Loss: 1.37436913 Accuracy: Top1: 50.7992%, Top5: 93.1166% | [Test] Loss: 1.28906923 Accuracy: Top1: 55.6728%, Top5: 94.5661%\n",
      "[Epoch 078] Time: 6.5572s | [Train] Loss: 1.37615096 Accuracy: Top1: 50.9131%, Top5: 92.9827% | [Test] Loss: 1.28914724 Accuracy: Top1: 55.6827%, Top5: 94.5860%\n",
      "[Epoch 079] Time: 6.6925s | [Train] Loss: 1.37840156 Accuracy: Top1: 50.7992%, Top5: 92.9188% | [Test] Loss: 1.28919402 Accuracy: Top1: 55.6728%, Top5: 94.5959%\n",
      "[Epoch 080] Time: 6.6668s | [Train] Loss: 1.37301349 Accuracy: Top1: 50.8911%, Top5: 93.0846% | [Test] Loss: 1.28917807 Accuracy: Top1: 55.7225%, Top5: 94.5860%\n",
      "[Epoch 081] Time: 6.5489s | [Train] Loss: 1.37251457 Accuracy: Top1: 51.0570%, Top5: 93.0627% | [Test] Loss: 1.28916763 Accuracy: Top1: 55.7126%, Top5: 94.5959%\n",
      "[Epoch 082] Time: 6.6050s | [Train] Loss: 1.37485417 Accuracy: Top1: 50.8592%, Top5: 93.1106% | [Test] Loss: 1.28916642 Accuracy: Top1: 55.7126%, Top5: 94.5959%\n",
      "[Epoch 083] Time: 6.5481s | [Train] Loss: 1.37488940 Accuracy: Top1: 50.9930%, Top5: 92.9767% | [Test] Loss: 1.28916127 Accuracy: Top1: 55.7026%, Top5: 94.5959%\n",
      "[Epoch 084] Time: 6.7120s | [Train] Loss: 1.37091754 Accuracy: Top1: 51.0530%, Top5: 93.2045% | [Test] Loss: 1.28915865 Accuracy: Top1: 55.7026%, Top5: 94.5959%\n",
      "[Epoch 085] Time: 6.7626s | [Train] Loss: 1.37137242 Accuracy: Top1: 51.0830%, Top5: 93.0427% | [Test] Loss: 1.28915124 Accuracy: Top1: 55.6927%, Top5: 94.5959%\n",
      "[Epoch 086] Time: 6.6293s | [Train] Loss: 1.37618135 Accuracy: Top1: 50.8012%, Top5: 93.0267% | [Test] Loss: 1.28915433 Accuracy: Top1: 55.7026%, Top5: 94.5959%\n",
      "[Epoch 087] Time: 6.6177s | [Train] Loss: 1.37595278 Accuracy: Top1: 50.7852%, Top5: 93.0906% | [Test] Loss: 1.28915107 Accuracy: Top1: 55.6927%, Top5: 94.5959%\n",
      "[Epoch 088] Time: 6.5830s | [Train] Loss: 1.37373512 Accuracy: Top1: 51.1649%, Top5: 93.1206% | [Test] Loss: 1.28914599 Accuracy: Top1: 55.6927%, Top5: 94.5959%\n",
      "[Epoch 089] Time: 6.5459s | [Train] Loss: 1.37340386 Accuracy: Top1: 51.0830%, Top5: 93.0327% | [Test] Loss: 1.28913926 Accuracy: Top1: 55.6927%, Top5: 94.5760%\n",
      "[Epoch 090] Time: 6.7578s | [Train] Loss: 1.37404751 Accuracy: Top1: 50.9511%, Top5: 93.0227% | [Test] Loss: 1.28913332 Accuracy: Top1: 55.7026%, Top5: 94.5760%\n",
      "[Epoch 091] Time: 6.6651s | [Train] Loss: 1.36898362 Accuracy: Top1: 51.1389%, Top5: 93.1985% | [Test] Loss: 1.28912493 Accuracy: Top1: 55.7026%, Top5: 94.5661%\n",
      "[Epoch 092] Time: 6.7041s | [Train] Loss: 1.37648844 Accuracy: Top1: 50.9011%, Top5: 93.0067% | [Test] Loss: 1.28912609 Accuracy: Top1: 55.6927%, Top5: 94.5661%\n",
      "[Epoch 093] Time: 6.6840s | [Train] Loss: 1.37509113 Accuracy: Top1: 51.0350%, Top5: 93.0687% | [Test] Loss: 1.28912690 Accuracy: Top1: 55.7026%, Top5: 94.5760%\n",
      "[Epoch 094] Time: 6.5585s | [Train] Loss: 1.37400609 Accuracy: Top1: 50.8891%, Top5: 93.0527% | [Test] Loss: 1.28911676 Accuracy: Top1: 55.6927%, Top5: 94.5661%\n",
      "[Epoch 095] Time: 6.6510s | [Train] Loss: 1.37684593 Accuracy: Top1: 50.7193%, Top5: 93.0707% | [Test] Loss: 1.28912018 Accuracy: Top1: 55.6927%, Top5: 94.5661%\n",
      "[Epoch 096] Time: 6.7530s | [Train] Loss: 1.37534474 Accuracy: Top1: 50.8252%, Top5: 93.0886% | [Test] Loss: 1.28911982 Accuracy: Top1: 55.6927%, Top5: 94.5661%\n",
      "[Epoch 097] Time: 6.6341s | [Train] Loss: 1.37480956 Accuracy: Top1: 51.1529%, Top5: 93.0926% | [Test] Loss: 1.28911874 Accuracy: Top1: 55.6827%, Top5: 94.5760%\n",
      "[Epoch 098] Time: 6.6312s | [Train] Loss: 1.37566592 Accuracy: Top1: 50.9391%, Top5: 93.0746% | [Test] Loss: 1.28912478 Accuracy: Top1: 55.7126%, Top5: 94.5860%\n",
      "[Epoch 099] Time: 6.6633s | [Train] Loss: 1.37587733 Accuracy: Top1: 50.9851%, Top5: 92.9807% | [Test] Loss: 1.28912527 Accuracy: Top1: 55.7126%, Top5: 94.5860%\n",
      "[Epoch 100] Time: 6.6045s | [Train] Loss: 1.37310324 Accuracy: Top1: 50.9571%, Top5: 93.2325% | [Test] Loss: 1.28912990 Accuracy: Top1: 55.7126%, Top5: 94.5860%\n"
     ]
    }
   ],
   "source": [
    "# Check if the output directory exists, if not create it\n",
    "if args.output_dir:\n",
    "    Path(args.output_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Dataset \n",
    "if args.dataset == \"cifar10\":\n",
    "    dataset = CIFAR10(args)\n",
    "    args.num_classes = dataset.num_classes \n",
    "    args.img_size = dataset.img_size \n",
    "elif args.dataset == \"cifar100\":\n",
    "    dataset = CIFAR100(args)\n",
    "    args.num_classes = dataset.num_classes \n",
    "    args.img_size = dataset.img_size \n",
    "elif args.dataset == \"imagenet\":\n",
    "    dataset = ImageNet(args)\n",
    "    args.num_classes = dataset.num_classes \n",
    "    args.img_size = dataset.img_size\n",
    "else:\n",
    "    raise ValueError(\"Dataset not supported\")\n",
    "\n",
    "# Model \n",
    "model = AllConvNet(args)\n",
    "print(f\"Model: {model.name}\")\n",
    "\n",
    "# Parameters\n",
    "total_params, trainable_params = model.parameter_count()\n",
    "print(f\"Total Parameters: {total_params}\")\n",
    "print(f\"Trainable Parameters: {trainable_params}\")\n",
    "args.total_params = total_params\n",
    "args.trainable_params = trainable_params\n",
    "\n",
    "# Set the seed for reproducibility\n",
    "set_seed(args.seed)\n",
    "\n",
    "\n",
    "# Training Modules \n",
    "train_eval_results = Train_Eval(args, \n",
    "                            model, \n",
    "                            dataset.train_loader, \n",
    "                            dataset.test_loader\n",
    "                            )\n",
    "\n",
    "# Storing Results in output directory \n",
    "write_to_file(os.path.join(args.output_dir, \"args.txt\"), args)\n",
    "write_to_file(os.path.join(args.output_dir, \"model.txt\"), model)\n",
    "write_to_file(os.path.join(args.output_dir, \"train_eval_results.txt\"), train_eval_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12b3b7a-7657-4585-ab6d-eaeb5dc1b95a",
   "metadata": {},
   "source": [
    "### II. Original ConvNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2c772f1-25a3-4d89-a6aa-4bfb4174ec60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import SimpleNamespace\n",
    "\n",
    "# Create default args\n",
    "args = SimpleNamespace(\n",
    "    layer=\"ConvNN\",\n",
    "    num_layers=3,\n",
    "    channels=[8, 16, 32],\n",
    "    K=9,\n",
    "    kernel_size=3,\n",
    "    sampling_type=\"spatial\",\n",
    "    num_samples=6,\n",
    "    sample_padding=0,\n",
    "    num_heads=4,\n",
    "    attention_dropout=0.1,\n",
    "    shuffle_pattern=\"BA\",\n",
    "    shuffle_scale=2,\n",
    "    magnitude_type=\"similarity\",\n",
    "    coordinate_encoding=False,\n",
    "    dataset=\"cifar10\",\n",
    "    data_path=\"./Data\",\n",
    "    batch_size=64,\n",
    "    num_epochs=100,\n",
    "    use_amp=False,\n",
    "    clip_grad_norm=None,\n",
    "    criterion=\"CrossEntropy\",\n",
    "    optimizer=\"adamw\",\n",
    "    momentum=0.9,\n",
    "    weight_decay=1e-6,\n",
    "    lr=1e-3,\n",
    "    lr_step=20,\n",
    "    lr_gamma=0.1,\n",
    "    scheduler=\"step\",\n",
    "    device=\"cuda\",\n",
    "    seed=0,\n",
    "    output_dir=\"./Output/Simple/ConvNN_Spat\", \n",
    "    resize=False\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f0692ee-9aff-469a-8d7c-b7f5186e0c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Upscale transform not defined. Skipping dataset upscale.\n",
      "Model: All Convolutional Network ConvNN\n",
      "Total Parameters: 97452\n",
      "Trainable Parameters: 97452\n",
      "[Epoch 001] Time: 10.0946s | [Train] Loss: 2.10904080 Accuracy: Top1: 24.8242%, Top5: 73.3256% | [Test] Loss: 1.96597065 Accuracy: Top1: 32.3746%, Top5: 82.4841%\n",
      "[Epoch 002] Time: 10.1116s | [Train] Loss: 1.94094051 Accuracy: Top1: 33.2041%, Top5: 82.9344% | [Test] Loss: 1.86873518 Accuracy: Top1: 36.1266%, Top5: 85.6389%\n",
      "[Epoch 003] Time: 10.1402s | [Train] Loss: 1.86896201 Accuracy: Top1: 36.6428%, Top5: 85.7057% | [Test] Loss: 1.81621471 Accuracy: Top1: 39.3710%, Top5: 87.1318%\n",
      "[Epoch 004] Time: 10.1520s | [Train] Loss: 1.82236847 Accuracy: Top1: 39.0225%, Top5: 86.9945% | [Test] Loss: 1.78607956 Accuracy: Top1: 40.7842%, Top5: 88.1369%\n",
      "[Epoch 005] Time: 10.2137s | [Train] Loss: 1.78477724 Accuracy: Top1: 40.9767%, Top5: 88.1074% | [Test] Loss: 1.75255738 Accuracy: Top1: 42.0780%, Top5: 89.7094%\n",
      "[Epoch 006] Time: 10.2588s | [Train] Loss: 1.75874077 Accuracy: Top1: 42.1096%, Top5: 88.8008% | [Test] Loss: 1.73386724 Accuracy: Top1: 42.9439%, Top5: 89.6895%\n",
      "[Epoch 007] Time: 9.9403s | [Train] Loss: 1.73384462 Accuracy: Top1: 43.4942%, Top5: 89.4741% | [Test] Loss: 1.72920955 Accuracy: Top1: 44.4765%, Top5: 89.6497%\n",
      "[Epoch 008] Time: 9.8092s | [Train] Loss: 1.71408499 Accuracy: Top1: 44.6671%, Top5: 90.0156% | [Test] Loss: 1.71017726 Accuracy: Top1: 43.9988%, Top5: 90.4857%\n",
      "[Epoch 009] Time: 10.0876s | [Train] Loss: 1.69217974 Accuracy: Top1: 45.7501%, Top5: 90.6370% | [Test] Loss: 1.68423818 Accuracy: Top1: 45.7205%, Top5: 91.0231%\n",
      "[Epoch 010] Time: 9.8860s | [Train] Loss: 1.67830822 Accuracy: Top1: 46.2256%, Top5: 90.9307% | [Test] Loss: 1.66654754 Accuracy: Top1: 46.8850%, Top5: 91.5705%\n",
      "[Epoch 011] Time: 10.1803s | [Train] Loss: 1.66355377 Accuracy: Top1: 46.8750%, Top5: 91.2344% | [Test] Loss: 1.66534425 Accuracy: Top1: 46.6361%, Top5: 91.3814%\n",
      "[Epoch 012] Time: 10.3495s | [Train] Loss: 1.64862275 Accuracy: Top1: 47.5923%, Top5: 91.5121% | [Test] Loss: 1.64744514 Accuracy: Top1: 47.3428%, Top5: 92.0880%\n",
      "[Epoch 013] Time: 10.2817s | [Train] Loss: 1.63681940 Accuracy: Top1: 48.4115%, Top5: 91.8838% | [Test] Loss: 1.61912378 Accuracy: Top1: 48.8455%, Top5: 92.4164%\n",
      "[Epoch 014] Time: 10.1460s | [Train] Loss: 1.62515534 Accuracy: Top1: 48.8431%, Top5: 92.0277% | [Test] Loss: 1.64701387 Accuracy: Top1: 47.6811%, Top5: 91.6103%\n",
      "[Epoch 015] Time: 10.2065s | [Train] Loss: 1.61570832 Accuracy: Top1: 49.3606%, Top5: 92.3074% | [Test] Loss: 1.62046860 Accuracy: Top1: 49.5223%, Top5: 92.3169%\n",
      "[Epoch 016] Time: 11.0486s | [Train] Loss: 1.60299986 Accuracy: Top1: 49.8861%, Top5: 92.5092% | [Test] Loss: 1.61238011 Accuracy: Top1: 49.6915%, Top5: 92.4562%\n",
      "[Epoch 017] Time: 10.1561s | [Train] Loss: 1.59610217 Accuracy: Top1: 50.3936%, Top5: 92.5452% | [Test] Loss: 1.61096595 Accuracy: Top1: 49.6915%, Top5: 92.6752%\n",
      "[Epoch 018] Time: 9.9085s | [Train] Loss: 1.58872790 Accuracy: Top1: 50.9031%, Top5: 92.8089% | [Test] Loss: 1.61304027 Accuracy: Top1: 48.9550%, Top5: 92.7448%\n",
      "[Epoch 019] Time: 10.3402s | [Train] Loss: 1.57907012 Accuracy: Top1: 51.1769%, Top5: 92.8728% | [Test] Loss: 1.60807167 Accuracy: Top1: 49.5721%, Top5: 92.7747%\n",
      "[Epoch 020] Time: 10.2261s | [Train] Loss: 1.57152038 Accuracy: Top1: 51.6264%, Top5: 93.2285% | [Test] Loss: 1.59855429 Accuracy: Top1: 50.3284%, Top5: 92.7946%\n",
      "[Epoch 021] Time: 10.1725s | [Train] Loss: 1.52113385 Accuracy: Top1: 53.9562%, Top5: 94.1117% | [Test] Loss: 1.56408160 Accuracy: Top1: 52.5975%, Top5: 93.2723%\n",
      "[Epoch 022] Time: 10.0308s | [Train] Loss: 1.51131710 Accuracy: Top1: 54.5656%, Top5: 94.1476% | [Test] Loss: 1.55951111 Accuracy: Top1: 52.6771%, Top5: 93.4813%\n",
      "[Epoch 023] Time: 9.9881s | [Train] Loss: 1.50826498 Accuracy: Top1: 54.5876%, Top5: 94.2116% | [Test] Loss: 1.55946913 Accuracy: Top1: 52.3288%, Top5: 93.5609%\n",
      "[Epoch 024] Time: 10.0196s | [Train] Loss: 1.50660626 Accuracy: Top1: 54.7734%, Top5: 94.2615% | [Test] Loss: 1.55722013 Accuracy: Top1: 52.6473%, Top5: 93.4514%\n",
      "[Epoch 025] Time: 10.5134s | [Train] Loss: 1.50355643 Accuracy: Top1: 55.0891%, Top5: 94.2875% | [Test] Loss: 1.55690982 Accuracy: Top1: 52.6871%, Top5: 93.5510%\n",
      "[Epoch 026] Time: 9.9444s | [Train] Loss: 1.49987273 Accuracy: Top1: 55.1151%, Top5: 94.5153% | [Test] Loss: 1.55663459 Accuracy: Top1: 52.6572%, Top5: 93.6604%\n",
      "[Epoch 027] Time: 10.1506s | [Train] Loss: 1.50284640 Accuracy: Top1: 54.9213%, Top5: 94.3514% | [Test] Loss: 1.55625282 Accuracy: Top1: 52.5577%, Top5: 93.7002%\n",
      "[Epoch 028] Time: 10.1238s | [Train] Loss: 1.49951313 Accuracy: Top1: 55.1351%, Top5: 94.2375% | [Test] Loss: 1.55306052 Accuracy: Top1: 52.8662%, Top5: 93.5211%\n",
      "[Epoch 029] Time: 10.1617s | [Train] Loss: 1.49723413 Accuracy: Top1: 55.1830%, Top5: 94.4273% | [Test] Loss: 1.55297850 Accuracy: Top1: 52.9260%, Top5: 93.4614%\n",
      "[Epoch 030] Time: 10.1039s | [Train] Loss: 1.49497847 Accuracy: Top1: 55.1850%, Top5: 94.4713% | [Test] Loss: 1.55226074 Accuracy: Top1: 53.2046%, Top5: 93.5311%\n",
      "[Epoch 031] Time: 10.1737s | [Train] Loss: 1.49399737 Accuracy: Top1: 55.3509%, Top5: 94.4913% | [Test] Loss: 1.55123151 Accuracy: Top1: 53.2146%, Top5: 93.7102%\n",
      "[Epoch 032] Time: 9.9319s | [Train] Loss: 1.49414587 Accuracy: Top1: 55.6166%, Top5: 94.5352% | [Test] Loss: 1.55140293 Accuracy: Top1: 52.7667%, Top5: 93.5311%\n",
      "[Epoch 033] Time: 9.9771s | [Train] Loss: 1.49305708 Accuracy: Top1: 55.4967%, Top5: 94.4873% | [Test] Loss: 1.55009240 Accuracy: Top1: 53.0155%, Top5: 93.6206%\n",
      "[Epoch 034] Time: 10.0241s | [Train] Loss: 1.48869285 Accuracy: Top1: 55.6506%, Top5: 94.5193% | [Test] Loss: 1.55340249 Accuracy: Top1: 53.1350%, Top5: 93.5808%\n",
      "[Epoch 035] Time: 10.2564s | [Train] Loss: 1.48896877 Accuracy: Top1: 55.5727%, Top5: 94.5452% | [Test] Loss: 1.54906597 Accuracy: Top1: 53.0852%, Top5: 93.6704%\n",
      "[Epoch 036] Time: 10.1585s | [Train] Loss: 1.48569237 Accuracy: Top1: 55.6506%, Top5: 94.5672% | [Test] Loss: 1.55069738 Accuracy: Top1: 53.1250%, Top5: 93.6704%\n",
      "[Epoch 037] Time: 9.8901s | [Train] Loss: 1.48457704 Accuracy: Top1: 56.0142%, Top5: 94.6072% | [Test] Loss: 1.54969222 Accuracy: Top1: 53.0255%, Top5: 93.6206%\n",
      "[Epoch 038] Time: 10.0928s | [Train] Loss: 1.48420443 Accuracy: Top1: 56.0442%, Top5: 94.6811% | [Test] Loss: 1.54850929 Accuracy: Top1: 53.1748%, Top5: 93.6206%\n",
      "[Epoch 039] Time: 9.9742s | [Train] Loss: 1.48326788 Accuracy: Top1: 55.8124%, Top5: 94.5752% | [Test] Loss: 1.54863225 Accuracy: Top1: 53.2643%, Top5: 93.7002%\n",
      "[Epoch 040] Time: 9.9976s | [Train] Loss: 1.48360513 Accuracy: Top1: 55.8504%, Top5: 94.7331% | [Test] Loss: 1.54930448 Accuracy: Top1: 53.0454%, Top5: 93.6903%\n",
      "[Epoch 041] Time: 10.0071s | [Train] Loss: 1.47651002 Accuracy: Top1: 55.9942%, Top5: 94.8130% | [Test] Loss: 1.54657517 Accuracy: Top1: 53.1250%, Top5: 93.7102%\n",
      "[Epoch 042] Time: 10.1205s | [Train] Loss: 1.47614159 Accuracy: Top1: 56.3020%, Top5: 94.7191% | [Test] Loss: 1.54662011 Accuracy: Top1: 53.1150%, Top5: 93.7002%\n",
      "[Epoch 043] Time: 10.2647s | [Train] Loss: 1.47387148 Accuracy: Top1: 56.3219%, Top5: 94.7990% | [Test] Loss: 1.54585049 Accuracy: Top1: 53.2345%, Top5: 93.6704%\n",
      "[Epoch 044] Time: 10.3457s | [Train] Loss: 1.47357347 Accuracy: Top1: 56.3699%, Top5: 94.7610% | [Test] Loss: 1.54585268 Accuracy: Top1: 53.2245%, Top5: 93.7201%\n",
      "[Epoch 045] Time: 9.8715s | [Train] Loss: 1.47233819 Accuracy: Top1: 56.5297%, Top5: 94.7510% | [Test] Loss: 1.54597424 Accuracy: Top1: 53.1350%, Top5: 93.7500%\n",
      "[Epoch 046] Time: 10.0786s | [Train] Loss: 1.47087523 Accuracy: Top1: 56.3419%, Top5: 94.8749% | [Test] Loss: 1.54572738 Accuracy: Top1: 53.4236%, Top5: 93.7301%\n",
      "[Epoch 047] Time: 10.2499s | [Train] Loss: 1.47092536 Accuracy: Top1: 56.6656%, Top5: 94.8070% | [Test] Loss: 1.54631474 Accuracy: Top1: 53.2146%, Top5: 93.7201%\n",
      "[Epoch 048] Time: 9.8366s | [Train] Loss: 1.47279838 Accuracy: Top1: 56.3239%, Top5: 94.7730% | [Test] Loss: 1.54562304 Accuracy: Top1: 53.3141%, Top5: 93.6803%\n",
      "[Epoch 049] Time: 10.0790s | [Train] Loss: 1.47468042 Accuracy: Top1: 56.2880%, Top5: 94.7171% | [Test] Loss: 1.54571584 Accuracy: Top1: 53.2444%, Top5: 93.7301%\n",
      "[Epoch 050] Time: 9.7296s | [Train] Loss: 1.47208247 Accuracy: Top1: 56.4378%, Top5: 94.7870% | [Test] Loss: 1.54595712 Accuracy: Top1: 53.2842%, Top5: 93.6206%\n",
      "[Epoch 051] Time: 10.1444s | [Train] Loss: 1.47093009 Accuracy: Top1: 56.5098%, Top5: 95.0148% | [Test] Loss: 1.54581780 Accuracy: Top1: 53.1250%, Top5: 93.7201%\n",
      "[Epoch 052] Time: 10.1325s | [Train] Loss: 1.47153906 Accuracy: Top1: 56.4138%, Top5: 94.8829% | [Test] Loss: 1.54599894 Accuracy: Top1: 53.2245%, Top5: 93.6505%\n",
      "[Epoch 053] Time: 9.7983s | [Train] Loss: 1.47323940 Accuracy: Top1: 56.4478%, Top5: 94.7071% | [Test] Loss: 1.54539203 Accuracy: Top1: 53.1150%, Top5: 93.7102%\n",
      "[Epoch 054] Time: 10.4413s | [Train] Loss: 1.47346363 Accuracy: Top1: 56.2380%, Top5: 94.8290% | [Test] Loss: 1.54538493 Accuracy: Top1: 53.2842%, Top5: 93.7201%\n",
      "[Epoch 055] Time: 9.7912s | [Train] Loss: 1.47147469 Accuracy: Top1: 56.4938%, Top5: 94.8290% | [Test] Loss: 1.54545571 Accuracy: Top1: 53.3539%, Top5: 93.6007%\n",
      "[Epoch 056] Time: 10.0563s | [Train] Loss: 1.47065801 Accuracy: Top1: 56.3419%, Top5: 94.9289% | [Test] Loss: 1.54559184 Accuracy: Top1: 53.3340%, Top5: 93.7002%\n",
      "[Epoch 057] Time: 10.0952s | [Train] Loss: 1.47351649 Accuracy: Top1: 56.5058%, Top5: 94.9169% | [Test] Loss: 1.54525503 Accuracy: Top1: 53.2444%, Top5: 93.6306%\n",
      "[Epoch 058] Time: 10.1861s | [Train] Loss: 1.47039877 Accuracy: Top1: 56.5277%, Top5: 94.9089% | [Test] Loss: 1.54547819 Accuracy: Top1: 53.3439%, Top5: 93.5410%\n",
      "[Epoch 059] Time: 10.0878s | [Train] Loss: 1.47176817 Accuracy: Top1: 56.4938%, Top5: 94.8090% | [Test] Loss: 1.54571908 Accuracy: Top1: 53.2842%, Top5: 93.6903%\n",
      "[Epoch 060] Time: 10.3165s | [Train] Loss: 1.47138246 Accuracy: Top1: 56.4478%, Top5: 94.8230% | [Test] Loss: 1.54527496 Accuracy: Top1: 53.3240%, Top5: 93.7400%\n",
      "[Epoch 061] Time: 10.4677s | [Train] Loss: 1.47191580 Accuracy: Top1: 56.4758%, Top5: 94.8130% | [Test] Loss: 1.54526783 Accuracy: Top1: 53.3141%, Top5: 93.7201%\n",
      "[Epoch 062] Time: 10.2645s | [Train] Loss: 1.46943034 Accuracy: Top1: 56.6156%, Top5: 94.8449% | [Test] Loss: 1.54533254 Accuracy: Top1: 53.2743%, Top5: 93.7002%\n",
      "[Epoch 063] Time: 10.1822s | [Train] Loss: 1.46919966 Accuracy: Top1: 56.3759%, Top5: 94.8889% | [Test] Loss: 1.54537180 Accuracy: Top1: 53.3639%, Top5: 93.6704%\n",
      "[Epoch 064] Time: 10.4342s | [Train] Loss: 1.47190207 Accuracy: Top1: 56.3039%, Top5: 94.8509% | [Test] Loss: 1.54539416 Accuracy: Top1: 53.3639%, Top5: 93.7002%\n",
      "[Epoch 065] Time: 10.2342s | [Train] Loss: 1.47040607 Accuracy: Top1: 56.5997%, Top5: 94.8729% | [Test] Loss: 1.54548439 Accuracy: Top1: 53.3240%, Top5: 93.7400%\n",
      "[Epoch 066] Time: 10.5361s | [Train] Loss: 1.47115128 Accuracy: Top1: 56.3799%, Top5: 94.7890% | [Test] Loss: 1.54545924 Accuracy: Top1: 53.3340%, Top5: 93.7201%\n",
      "[Epoch 067] Time: 10.0196s | [Train] Loss: 1.47168636 Accuracy: Top1: 56.3099%, Top5: 94.9089% | [Test] Loss: 1.54536907 Accuracy: Top1: 53.3639%, Top5: 93.6803%\n",
      "[Epoch 068] Time: 9.9744s | [Train] Loss: 1.46993023 Accuracy: Top1: 56.4778%, Top5: 94.8130% | [Test] Loss: 1.54542933 Accuracy: Top1: 53.3340%, Top5: 93.7102%\n",
      "[Epoch 069] Time: 10.3013s | [Train] Loss: 1.47049805 Accuracy: Top1: 56.4938%, Top5: 94.8370% | [Test] Loss: 1.54531627 Accuracy: Top1: 53.3738%, Top5: 93.7102%\n",
      "[Epoch 070] Time: 9.9108s | [Train] Loss: 1.46991131 Accuracy: Top1: 56.5437%, Top5: 94.8969% | [Test] Loss: 1.54525167 Accuracy: Top1: 53.2643%, Top5: 93.6604%\n",
      "[Epoch 071] Time: 9.9030s | [Train] Loss: 1.46886584 Accuracy: Top1: 56.7275%, Top5: 94.8909% | [Test] Loss: 1.54525243 Accuracy: Top1: 53.2544%, Top5: 93.7301%\n",
      "[Epoch 072] Time: 9.7693s | [Train] Loss: 1.46990941 Accuracy: Top1: 56.5197%, Top5: 94.8070% | [Test] Loss: 1.54532594 Accuracy: Top1: 53.3439%, Top5: 93.7301%\n",
      "[Epoch 073] Time: 9.9348s | [Train] Loss: 1.46923782 Accuracy: Top1: 56.6216%, Top5: 94.7371% | [Test] Loss: 1.54530788 Accuracy: Top1: 53.2942%, Top5: 93.7002%\n",
      "[Epoch 074] Time: 9.8543s | [Train] Loss: 1.47035319 Accuracy: Top1: 56.7156%, Top5: 94.8330% | [Test] Loss: 1.54522507 Accuracy: Top1: 53.2842%, Top5: 93.7301%\n",
      "[Epoch 075] Time: 10.1157s | [Train] Loss: 1.46983101 Accuracy: Top1: 56.5397%, Top5: 94.8190% | [Test] Loss: 1.54531639 Accuracy: Top1: 53.2842%, Top5: 93.7201%\n",
      "[Epoch 076] Time: 10.3464s | [Train] Loss: 1.47058286 Accuracy: Top1: 56.7215%, Top5: 94.8549% | [Test] Loss: 1.54533467 Accuracy: Top1: 53.3439%, Top5: 93.6803%\n",
      "[Epoch 077] Time: 10.0115s | [Train] Loss: 1.46847092 Accuracy: Top1: 56.5797%, Top5: 94.9189% | [Test] Loss: 1.54538942 Accuracy: Top1: 53.3639%, Top5: 93.6604%\n",
      "[Epoch 078] Time: 10.4135s | [Train] Loss: 1.46944927 Accuracy: Top1: 56.4438%, Top5: 94.7910% | [Test] Loss: 1.54535602 Accuracy: Top1: 53.3141%, Top5: 93.7400%\n",
      "[Epoch 079] Time: 9.9351s | [Train] Loss: 1.47134092 Accuracy: Top1: 56.3339%, Top5: 94.8649% | [Test] Loss: 1.54544462 Accuracy: Top1: 53.4236%, Top5: 93.6903%\n",
      "[Epoch 080] Time: 9.8964s | [Train] Loss: 1.46976834 Accuracy: Top1: 56.6316%, Top5: 94.8709% | [Test] Loss: 1.54537273 Accuracy: Top1: 53.3639%, Top5: 93.7002%\n",
      "[Epoch 081] Time: 9.7984s | [Train] Loss: 1.47011553 Accuracy: Top1: 56.6696%, Top5: 94.7410% | [Test] Loss: 1.54541299 Accuracy: Top1: 53.3639%, Top5: 93.6903%\n",
      "[Epoch 082] Time: 10.2880s | [Train] Loss: 1.47003715 Accuracy: Top1: 56.3999%, Top5: 94.7630% | [Test] Loss: 1.54542703 Accuracy: Top1: 53.3439%, Top5: 93.7102%\n",
      "[Epoch 083] Time: 10.2718s | [Train] Loss: 1.47166623 Accuracy: Top1: 56.4019%, Top5: 94.7870% | [Test] Loss: 1.54539920 Accuracy: Top1: 53.4037%, Top5: 93.7102%\n",
      "[Epoch 084] Time: 10.0568s | [Train] Loss: 1.46908044 Accuracy: Top1: 56.6296%, Top5: 94.8010% | [Test] Loss: 1.54538291 Accuracy: Top1: 53.3240%, Top5: 93.7002%\n",
      "[Epoch 085] Time: 10.2550s | [Train] Loss: 1.46938313 Accuracy: Top1: 56.4039%, Top5: 94.7650% | [Test] Loss: 1.54534974 Accuracy: Top1: 53.3639%, Top5: 93.7002%\n",
      "[Epoch 086] Time: 10.0663s | [Train] Loss: 1.47156325 Accuracy: Top1: 56.4818%, Top5: 94.8669% | [Test] Loss: 1.54536488 Accuracy: Top1: 53.3141%, Top5: 93.7002%\n",
      "[Epoch 087] Time: 10.0134s | [Train] Loss: 1.46915135 Accuracy: Top1: 56.5657%, Top5: 94.8629% | [Test] Loss: 1.54538451 Accuracy: Top1: 53.3539%, Top5: 93.7102%\n",
      "[Epoch 088] Time: 9.9122s | [Train] Loss: 1.47022031 Accuracy: Top1: 56.5777%, Top5: 94.7790% | [Test] Loss: 1.54535243 Accuracy: Top1: 53.3141%, Top5: 93.7002%\n",
      "[Epoch 089] Time: 9.8051s | [Train] Loss: 1.47022274 Accuracy: Top1: 56.4358%, Top5: 94.8689% | [Test] Loss: 1.54535194 Accuracy: Top1: 53.2743%, Top5: 93.7102%\n",
      "[Epoch 090] Time: 9.9306s | [Train] Loss: 1.46998852 Accuracy: Top1: 56.4158%, Top5: 94.8370% | [Test] Loss: 1.54538016 Accuracy: Top1: 53.3041%, Top5: 93.7002%\n",
      "[Epoch 091] Time: 9.7546s | [Train] Loss: 1.46969673 Accuracy: Top1: 56.5137%, Top5: 94.8150% | [Test] Loss: 1.54537718 Accuracy: Top1: 53.3539%, Top5: 93.6903%\n",
      "[Epoch 092] Time: 10.5283s | [Train] Loss: 1.46910491 Accuracy: Top1: 56.5517%, Top5: 94.8390% | [Test] Loss: 1.54540375 Accuracy: Top1: 53.2942%, Top5: 93.7102%\n",
      "[Epoch 093] Time: 10.0887s | [Train] Loss: 1.46945281 Accuracy: Top1: 56.4418%, Top5: 94.8609% | [Test] Loss: 1.54544725 Accuracy: Top1: 53.3041%, Top5: 93.7002%\n",
      "[Epoch 094] Time: 10.1282s | [Train] Loss: 1.47142439 Accuracy: Top1: 56.5098%, Top5: 94.7750% | [Test] Loss: 1.54543469 Accuracy: Top1: 53.2842%, Top5: 93.7002%\n",
      "[Epoch 095] Time: 10.4178s | [Train] Loss: 1.47054085 Accuracy: Top1: 56.4498%, Top5: 94.7970% | [Test] Loss: 1.54543234 Accuracy: Top1: 53.3141%, Top5: 93.7002%\n",
      "[Epoch 096] Time: 10.1514s | [Train] Loss: 1.46870216 Accuracy: Top1: 56.6896%, Top5: 94.8649% | [Test] Loss: 1.54545451 Accuracy: Top1: 53.3439%, Top5: 93.6903%\n",
      "[Epoch 097] Time: 10.1936s | [Train] Loss: 1.47103567 Accuracy: Top1: 56.3000%, Top5: 94.8669% | [Test] Loss: 1.54546300 Accuracy: Top1: 53.3539%, Top5: 93.7002%\n",
      "[Epoch 098] Time: 10.2039s | [Train] Loss: 1.46832375 Accuracy: Top1: 56.5337%, Top5: 94.8130% | [Test] Loss: 1.54541314 Accuracy: Top1: 53.3738%, Top5: 93.7201%\n",
      "[Epoch 099] Time: 10.0168s | [Train] Loss: 1.46938377 Accuracy: Top1: 56.5677%, Top5: 94.9009% | [Test] Loss: 1.54538712 Accuracy: Top1: 53.3439%, Top5: 93.7201%\n",
      "[Epoch 100] Time: 10.1087s | [Train] Loss: 1.46942453 Accuracy: Top1: 56.7435%, Top5: 94.8250% | [Test] Loss: 1.54531429 Accuracy: Top1: 53.3539%, Top5: 93.7201%\n"
     ]
    }
   ],
   "source": [
    "# Check if the output directory exists, if not create it\n",
    "if args.output_dir:\n",
    "    Path(args.output_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Dataset \n",
    "if args.dataset == \"cifar10\":\n",
    "    dataset = CIFAR10(args)\n",
    "    args.num_classes = dataset.num_classes \n",
    "    args.img_size = dataset.img_size \n",
    "elif args.dataset == \"cifar100\":\n",
    "    dataset = CIFAR100(args)\n",
    "    args.num_classes = dataset.num_classes \n",
    "    args.img_size = dataset.img_size \n",
    "elif args.dataset == \"imagenet\":\n",
    "    dataset = ImageNet(args)\n",
    "    args.num_classes = dataset.num_classes \n",
    "    args.img_size = dataset.img_size\n",
    "else:\n",
    "    raise ValueError(\"Dataset not supported\")\n",
    "\n",
    "# Model \n",
    "model = AllConvNet(args)\n",
    "print(f\"Model: {model.name}\")\n",
    "\n",
    "# Parameters\n",
    "total_params, trainable_params = model.parameter_count()\n",
    "print(f\"Total Parameters: {total_params}\")\n",
    "print(f\"Trainable Parameters: {trainable_params}\")\n",
    "args.total_params = total_params\n",
    "args.trainable_params = trainable_params\n",
    "\n",
    "# Set the seed for reproducibility\n",
    "set_seed(args.seed)\n",
    "\n",
    "\n",
    "# Training Modules \n",
    "train_eval_results = Train_Eval(args, \n",
    "                            model, \n",
    "                            dataset.train_loader, \n",
    "                            dataset.test_loader\n",
    "                            )\n",
    "\n",
    "# Storing Results in output directory \n",
    "write_to_file(os.path.join(args.output_dir, \"args.txt\"), args)\n",
    "write_to_file(os.path.join(args.output_dir, \"model.txt\"), model)\n",
    "write_to_file(os.path.join(args.output_dir, \"train_eval_results.txt\"), train_eval_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7063905-1419-4c54-b67f-f335b65a6b5b",
   "metadata": {},
   "source": [
    "# NEW _PRIME_NEW function = multiply topk values with topk indexed values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b461a3fb-f802-4867-ba4f-a23142c445f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "\n",
    "class Conv2d_NN(nn.Module): \n",
    "    \"\"\"Convolution 2D Nearest Neighbor Layer\"\"\"\n",
    "    def __init__(self, \n",
    "                in_channels, \n",
    "                out_channels, \n",
    "                K,\n",
    "                stride, \n",
    "                sampling_type, \n",
    "                num_samples, \n",
    "                sample_padding,\n",
    "                shuffle_pattern, \n",
    "                shuffle_scale, \n",
    "                magnitude_type,\n",
    "                coordinate_encoding=False\n",
    "                ): \n",
    "        \"\"\"\n",
    "        Parameters: \n",
    "            in_channels (int): Number of input channels.\n",
    "            out_channels (int): Number of output channels.\n",
    "            K (int): Number of Nearest Neighbors for consideration.\n",
    "            stride (int): Stride size.\n",
    "            sampling_type (str): Sampling type: \"all\", \"random\", \"spatial\".\n",
    "            num_samples (int): Number of samples to consider. -1 for all samples.\n",
    "            shuffle_pattern (str): Shuffle pattern: \"B\", \"A\", \"BA\".\n",
    "            shuffle_scale (int): Shuffle scale factor.\n",
    "            magnitude_type (str): Distance or Similarity.\n",
    "        \"\"\"\n",
    "        super(Conv2d_NN, self).__init__()\n",
    "        \n",
    "        # Assertions \n",
    "        assert K == stride, \"Error: K must be same as stride. K == stride.\"\n",
    "        assert shuffle_pattern in [\"B\", \"A\", \"BA\", \"NA\"], \"Error: shuffle_pattern must be one of ['B', 'A', 'BA', 'NA']\"\n",
    "        assert magnitude_type in [\"distance\", \"similarity\"], \"Error: magnitude_type must be one of ['distance', 'similarity']\"\n",
    "        assert sampling_type in [\"all\", \"random\", \"spatial\"], \"Error: sampling_type must be one of ['all', 'random', 'spatial']\"\n",
    "        assert int(num_samples) > 0 or int(num_samples) == -1, \"Error: num_samples must be greater than 0 or -1 for all samples\"\n",
    "        assert (sampling_type == \"all\" and int(num_samples) == -1) or (sampling_type != \"all\" and isinstance(num_samples, int)), \"Error: num_samples must be -1 for 'all' sampling or an integer for 'random' and 'spatial' sampling\"\n",
    "        \n",
    "        # Initialize parameters\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.K = K\n",
    "        self.stride = stride\n",
    "        self.sampling_type = sampling_type\n",
    "        self.num_samples = num_samples if num_samples != -1 else 'all'  # -1 for all samples\n",
    "        self.sample_padding = sample_padding if sampling_type == \"spatial\" else 0\n",
    "        self.shuffle_pattern = shuffle_pattern\n",
    "        self.shuffle_scale = shuffle_scale\n",
    "        self.magnitude_type = magnitude_type\n",
    "        self.maximum = True if self.magnitude_type == 'similarity' else False\n",
    "\n",
    "        # Positional Encoding (optional)\n",
    "        self.coordinate_encoding = coordinate_encoding\n",
    "        self.coordinate_cache = {} \n",
    "        self.in_channels = in_channels + 2 if self.coordinate_encoding else in_channels\n",
    "        self.out_channels = out_channels + 2 if self.coordinate_encoding else out_channels\n",
    "\n",
    "        # Shuffle2D/Unshuffle2D Layers\n",
    "        self.shuffle_layer = nn.PixelShuffle(upscale_factor=self.shuffle_scale)\n",
    "        self.unshuffle_layer = nn.PixelUnshuffle(downscale_factor=self.shuffle_scale)\n",
    "        \n",
    "        # Adjust Channels for PixelShuffle\n",
    "        self.in_channels_1d = self.in_channels * (self.shuffle_scale**2) if self.shuffle_pattern in [\"B\", \"BA\"] else self.in_channels\n",
    "        self.out_channels_1d = self.out_channels * (self.shuffle_scale**2) if self.shuffle_pattern in [\"A\", \"BA\"] else self.out_channels\n",
    "\n",
    "        # Conv1d Layer\n",
    "        self.conv1d_layer = nn.Conv1d(in_channels=self.in_channels_1d, \n",
    "                                      out_channels=self.out_channels_1d, \n",
    "                                      kernel_size=self.K, \n",
    "                                      stride=self.stride, \n",
    "                                      padding=0)\n",
    "\n",
    "        # Flatten Layer\n",
    "        self.flatten = nn.Flatten(start_dim=2)\n",
    "\n",
    "        # Pointwise Convolution Layer\n",
    "        self.pointwise_conv = nn.Conv2d(in_channels=self.out_channels,\n",
    "                                         out_channels=self.out_channels - 2,\n",
    "                                         kernel_size=1,\n",
    "                                         stride=1,\n",
    "                                         padding=0)\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, x): \n",
    "        # Coordinate Channels (optional) + Unshuffle + Flatten \n",
    "        x = self._add_coordinate_encoding(x) if self.coordinate_encoding else x\n",
    "        x_2d = self.unshuffle_layer(x) if self.shuffle_pattern in [\"B\", \"BA\"] else x\n",
    "        x = self.flatten(x_2d)\n",
    "\n",
    "        if self.sampling_type == \"all\":    \n",
    "            # ConvNN Algorithm \n",
    "            matrix_magnitude = self._calculate_distance_matrix(x, sqrt=True) if self.magnitude_type == 'distance' else self._calculate_similarity_matrix(x)\n",
    "            \n",
    "            prime = self._prime_new(x, matrix_magnitude, self.K, self.maximum) ### CHANGED\n",
    "             \n",
    "        elif self.sampling_type == \"random\":\n",
    "            # Select random samples\n",
    "            rand_idx = torch.randperm(x.shape[2], device=x.device)[:self.num_samples]\n",
    "            x_sample = x[:, :, rand_idx]\n",
    "\n",
    "            # ConvNN Algorithm \n",
    "            matrix_magnitude = self._calculate_distance_matrix_N(x, x_sample, sqrt=True) if self.magnitude_type == 'distance' else self._calculate_similarity_matrix_N(x, x_sample)\n",
    "            range_idx = torch.arange(len(rand_idx), device=x.device)\n",
    "            matrix_magnitude[:, rand_idx, range_idx] = float('inf') if self.magnitude_type == 'distance' else float('-inf')\n",
    "            \n",
    "            prime = self._prime_N_new(x, matrix_magnitude, self.K, rand_idx, self.maximum)\n",
    "            \n",
    "        elif self.sampling_type == \"spatial\":\n",
    "            # Get spatial sampled indices\n",
    "            x_ind = torch.linspace(0 + self.sample_padding, x_2d.shape[2] - self.sample_padding - 1, self.num_samples, device=x.device).to(torch.long)\n",
    "            y_ind = torch.linspace(0 + self.sample_padding, x_2d.shape[3] - self.sample_padding - 1, self.num_samples, device=x.device).to(torch.long)\n",
    "            x_grid, y_grid = torch.meshgrid(x_ind, y_ind, indexing='ij')\n",
    "            x_idx_flat, y_idx_flat = x_grid.flatten(), y_grid.flatten()\n",
    "            width = x_2d.shape[2] \n",
    "            flat_indices = y_idx_flat * width + x_idx_flat  \n",
    "            x_sample = x[:, :, flat_indices]\n",
    "\n",
    "            # ConvNN Algorithm\n",
    "            matrix_magnitude = self._calculate_distance_matrix_N(x, x_sample, sqrt=True) if self.magnitude_type == 'distance' else self._calculate_similarity_matrix_N(x, x_sample)\n",
    "            range_idx = torch.arange(len(flat_indices), device=x.device)\n",
    "            matrix_magnitude[:, flat_indices, range_idx] = float('inf') if self.magnitude_type == 'distance' else float('-inf')\n",
    "            prime = self._prime_N_new(x, matrix_magnitude, self.K, flat_indices, self.maximum)\n",
    "        else: \n",
    "            raise ValueError(\"Invalid sampling_type. Must be one of ['all', 'random', 'spatial'].\")\n",
    "\n",
    "        # Post-Processing \n",
    "        x_conv = self.conv1d_layer(prime) \n",
    "        \n",
    "        # Unflatten + Shuffle\n",
    "        unflatten = nn.Unflatten(dim=2, unflattened_size=x_2d.shape[2:])\n",
    "        x = unflatten(x_conv)  # [batch_size, out_channels\n",
    "        x = self.shuffle_layer(x) if self.shuffle_pattern in [\"A\", \"BA\"] else x\n",
    "        x = self.pointwise_conv(x) if self.coordinate_encoding else x\n",
    "        return x\n",
    "\n",
    "    def _calculate_distance_matrix(self, matrix, sqrt=False):\n",
    "        norm_squared = torch.sum(matrix ** 2, dim=1, keepdim=True)\n",
    "        dot_product = torch.bmm(matrix.transpose(2, 1), matrix)\n",
    "        \n",
    "        dist_matrix = norm_squared + norm_squared.transpose(2, 1) - 2 * dot_product\n",
    "        # dist_matrix = torch.clamp(dist_matrix, min=0) # remove negative values\n",
    "        dist_matrix = torch.sqrt(dist_matrix) if sqrt else dist_matrix # take square root if needed\n",
    "        \n",
    "        return dist_matrix\n",
    "    \n",
    "    def _calculate_distance_matrix_N(self, matrix, matrix_sample, sqrt=False):\n",
    "        norm_squared = torch.sum(matrix ** 2, dim=1, keepdim=True).permute(0, 2, 1)\n",
    "        norm_squared_sample = torch.sum(matrix_sample ** 2, dim=1, keepdim=True).transpose(2, 1).permute(0, 2, 1)\n",
    "        dot_product = torch.bmm(matrix.transpose(2, 1), matrix_sample)\n",
    "        \n",
    "        dist_matrix = norm_squared + norm_squared_sample - 2 * dot_product\n",
    "        # dist_matrix = torch.clamp(dist_matrix, min=0) # remove negative values\n",
    "        dist_matrix = torch.sqrt(dist_matrix) if sqrt else dist_matrix\n",
    "\n",
    "        return dist_matrix\n",
    "    \n",
    "    def _calculate_similarity_matrix(self, matrix):\n",
    "        # p=2 (L2 Norm - Euclidean Distance), dim=1 (across the channels)\n",
    "        norm_matrix = F.normalize(matrix, p=2, dim=1) \n",
    "        similarity_matrix = torch.bmm(norm_matrix.transpose(2, 1), norm_matrix)\n",
    "        return similarity_matrix\n",
    "    \n",
    "    def _calculate_similarity_matrix_N(self, matrix, matrix_sample):\n",
    "        # p=2 (L2 Norm - Euclidean Distance), dim=1 (across the channels)\n",
    "        norm_matrix = F.normalize(matrix, p=2, dim=1) \n",
    "        norm_sample = F.normalize(matrix_sample, p=2, dim=1)\n",
    "        similarity_matrix = torch.bmm(norm_matrix.transpose(2, 1), norm_sample)\n",
    "        return similarity_matrix\n",
    "\n",
    "    def _prime_new(self, matrix, magnitude_matrix, K, maximum):\n",
    "        b, c, t = matrix.shape\n",
    "        topk_values, topk_indices = torch.topk(magnitude_matrix, k=K, dim=2, largest=maximum)\n",
    "        topk_indices_exp = topk_indices.unsqueeze(1).expand(b, c, t, K)    \n",
    "        topk_values_exp = topk_values.unsqueeze(1).expand(b, c, t, K)    \n",
    "        matrix_expanded = matrix.unsqueeze(-1).expand(b, c, t, K).contiguous()\n",
    "        prime = torch.gather(matrix_expanded, dim=2, index=topk_indices_exp)\n",
    "        prime = topk_values_exp * prime\n",
    "        prime = prime.view(b, c, -1)\n",
    "        return prime\n",
    "    \n",
    "    def _prime_N(self, matrix, magnitude_matrix, K, rand_idx, maximum):\n",
    "        b, c, t = matrix.shape\n",
    "        _, topk_indices = torch.topk(magnitude_matrix, k=K - 1, dim=2, largest=maximum)\n",
    "        tk = topk_indices.shape[-1]\n",
    "        assert K == tk + 1, \"Error: K must be same as tk + 1. K == tk + 1.\"\n",
    "\n",
    "        mapped_tensor = rand_idx[topk_indices]\n",
    "        token_indices = torch.arange(t, device=matrix.device).view(1, t, 1).expand(b, t, 1)\n",
    "        final_indices = torch.cat([token_indices, mapped_tensor], dim=2)\n",
    "        indices_expanded = final_indices.unsqueeze(1).expand(b, c, t, K)\n",
    "\n",
    "        matrix_expanded = matrix.unsqueeze(-1).expand(b, c, t, K).contiguous()\n",
    "        prime = torch.gather(matrix_expanded, dim=2, index=indices_expanded)  \n",
    "        prime = prime.view(b, c, -1)\n",
    "        return prime\n",
    "    \n",
    "    def _prime_N_new(self, matrix, magnitude_matrix, K, rand_idx, maximum):\n",
    "        b, c, t = matrix.shape\n",
    "        topk_values, topk_indices = torch.topk(magnitude_matrix, k=K - 1, dim=2, largest=maximum)\n",
    "        tk = topk_indices.shape[-1]\n",
    "        assert K == tk + 1, \"Error: K must be same as tk + 1. K == tk + 1.\"\n",
    "\n",
    "        mapped_tensor = rand_idx[topk_indices]\n",
    "        token_indices = torch.arange(t, device=matrix.device).view(1, t, 1).expand(b, t, 1)\n",
    "        final_indices = torch.cat([token_indices, mapped_tensor], dim=2)\n",
    "        indices_expanded = final_indices.unsqueeze(1).expand(b, c, t, K)\n",
    "\n",
    "        topk_values_exp = topk_values.unsqueeze(1).expand(b, c, t, K-1)\n",
    "        ones = torch.ones((b, c, t, 1), device=matrix.device)\n",
    "        topk_values_exp = torch.cat((ones, topk_values_exp), dim=-1)\n",
    "        \n",
    "\n",
    "        matrix_expanded = matrix.unsqueeze(-1).expand(b, c, t, K).contiguous()\n",
    "        prime = torch.gather(matrix_expanded, dim=2, index=indices_expanded)  \n",
    "        prime = topk_values_exp * prime\n",
    "        prime = prime.view(b, c, -1)\n",
    "        return prime\n",
    "\n",
    "    \n",
    "    def _add_coordinate_encoding(self, x):\n",
    "        b, _, h, w = x.shape\n",
    "        cache_key = f\"{b}_{h}_{w}_{x.device}\"\n",
    "\n",
    "        if cache_key in self.coordinate_cache:\n",
    "            expanded_grid = self.coordinate_cache[cache_key]\n",
    "        else:\n",
    "            y_coords_vec = torch.linspace(start=-1, end=1, steps=h, device=x.device)\n",
    "            x_coords_vec = torch.linspace(start=-1, end=1, steps=w, device=x.device)\n",
    "\n",
    "            y_grid, x_grid = torch.meshgrid(y_coords_vec, x_coords_vec, indexing='ij')\n",
    "            grid = torch.stack((x_grid, y_grid), dim=0).unsqueeze(0)\n",
    "            expanded_grid = grid.expand(b, -1, -1, -1)\n",
    "            self.coordinate_cache[cache_key] = expanded_grid\n",
    "\n",
    "        x_with_coords = torch.cat((x, expanded_grid), dim=1)\n",
    "        return x_with_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b47c7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Conv2d_New(nn.Module): \n",
    "    \"\"\"Convolution 2D Nearest Neighbor Layer\"\"\"\n",
    "    def __init__(self, \n",
    "                in_channels, \n",
    "                out_channels, \n",
    "                kernel_size,\n",
    "                stride, \n",
    "                shuffle_pattern, \n",
    "                shuffle_scale, \n",
    "                coordinate_encoding\n",
    "                ): \n",
    "        \n",
    "        super(Conv2d_New, self).__init__()\n",
    "        \n",
    "        # Assertions \n",
    "        assert shuffle_pattern in [\"B\", \"A\", \"BA\", \"NA\"], \"Error: shuffle_pattern must be one of ['B', 'A', 'BA', 'NA']\"\n",
    "        \n",
    "        # Initialize parameters\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.shuffle_pattern = shuffle_pattern\n",
    "        self.shuffle_scale = shuffle_scale\n",
    "\n",
    "        # Positional Encoding (optional)\n",
    "        self.coordinate_encoding = coordinate_encoding\n",
    "        self.coordinate_cache = {} \n",
    "        self.in_channels = in_channels + 2 if self.coordinate_encoding else in_channels\n",
    "        self.out_channels = out_channels + 2 if self.coordinate_encoding else out_channels\n",
    "\n",
    "        # Shuffle2D/Unshuffle2D Layers\n",
    "        self.shuffle_layer = nn.PixelShuffle(upscale_factor=self.shuffle_scale)\n",
    "        self.unshuffle_layer = nn.PixelUnshuffle(downscale_factor=self.shuffle_scale)\n",
    "        \n",
    "        # Adjust Channels for PixelShuffle\n",
    "        self.in_channels_shuff = self.in_channels * (self.shuffle_scale**2) if self.shuffle_pattern in [\"B\", \"BA\"] else self.in_channels\n",
    "        self.out_channels_shuff = self.out_channels * (self.shuffle_scale**2) if self.shuffle_pattern in [\"A\", \"BA\"] else self.out_channels\n",
    "\n",
    "        # Conv2d Layer\n",
    "        self.conv2d_layer = nn.Conv2d(in_channels=self.in_channels_shuff, \n",
    "                                      out_channels=self.out_channels_shuff, \n",
    "                                      kernel_size=self.kernel_size, \n",
    "                                      stride=self.stride, \n",
    "                                      padding=\"same\")\n",
    "\n",
    "\n",
    "        # Pointwise Convolution Layer\n",
    "        self.pointwise_conv = nn.Conv2d(in_channels=self.out_channels,\n",
    "                                         out_channels=self.out_channels - 2,\n",
    "                                         kernel_size=1,\n",
    "                                         stride=1,\n",
    "                                         padding=0)\n",
    "        \n",
    "        \n",
    "    def forward(self, x): \n",
    "        # Coordinate Channels (optional) + Unshuffle + Flatten \n",
    "        x = self._add_coordinate_encoding(x) if self.coordinate_encoding else x\n",
    "        x_2d = self.unshuffle_layer(x) if self.shuffle_pattern in [\"B\", \"BA\"] else x\n",
    "\n",
    "        # Conv2d Layer\n",
    "        x = self.conv2d_layer(x_2d)\n",
    "\n",
    "        x = self.shuffle_layer(x) if self.shuffle_pattern in [\"A\", \"BA\"] else x\n",
    "        x = self.pointwise_conv(x) if self.coordinate_encoding else x\n",
    "        return x\n",
    "\n",
    "    def _add_coordinate_encoding(self, x):\n",
    "        b, _, h, w = x.shape\n",
    "        cache_key = f\"{b}_{h}_{w}_{x.device}\"\n",
    "\n",
    "        if cache_key in self.coordinate_cache:\n",
    "            expanded_grid = self.coordinate_cache[cache_key]\n",
    "        else:\n",
    "            y_coords_vec = torch.linspace(start=-1, end=1, steps=h, device=x.device)\n",
    "            x_coords_vec = torch.linspace(start=-1, end=1, steps=w, device=x.device)\n",
    "\n",
    "            y_grid, x_grid = torch.meshgrid(y_coords_vec, x_coords_vec, indexing='ij')\n",
    "            grid = torch.stack((x_grid, y_grid), dim=0).unsqueeze(0)\n",
    "            expanded_grid = grid.expand(b, -1, -1, -1)\n",
    "            self.coordinate_cache[cache_key] = expanded_grid\n",
    "\n",
    "        x_with_coords = torch.cat((x, expanded_grid), dim=1)\n",
    "        return x_with_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16e75c1-defa-4198-a14d-11fb2d8fcbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AllConvNet(nn.Module): \n",
    "    def __init__(self, args): \n",
    "        super(AllConvNet, self).__init__()\n",
    "        self.args = args\n",
    "        self.model = \"All Convolutional Network\"\n",
    "        self.name = f\"{self.model} {self.args.layer}\"\n",
    "        \n",
    "        layers = []\n",
    "        in_ch = self.args.img_size[0] \n",
    "\n",
    "        for i in range(self.args.num_layers):\n",
    "            out_ch = self.args.channels[i]\n",
    "\n",
    "            # A dictionary to hold parameters for the current layer\n",
    "            layer_params = {\n",
    "                \"in_channels\": in_ch,\n",
    "                \"out_channels\": out_ch,\n",
    "                \"shuffle_pattern\": self.args.shuffle_pattern,\n",
    "                \"shuffle_scale\": self.args.shuffle_scale,\n",
    "            }\n",
    "\n",
    "            if self.args.layer == \"Conv2d\":\n",
    "                layer = Conv2d_New(\n",
    "                    in_channels=in_ch, \n",
    "                    out_channels=out_ch, \n",
    "                    kernel_size=self.args.kernel_size, \n",
    "                    stride=1, \n",
    "                    shuffle_pattern=self.args.shuffle_pattern,\n",
    "                    shuffle_scale=self.args.shuffle_scale,\n",
    "                    coordinate_encoding=self.args.coordinate_encoding\n",
    "                )\n",
    "            \n",
    "            elif self.args.layer == \"ConvNN\":\n",
    "                layer_params.update({\n",
    "                    \"K\": self.args.K,\n",
    "                    \"stride\": self.args.K, # Stride is always K\n",
    "                    \"sampling_type\": self.args.sampling_type,\n",
    "                    \"num_samples\": self.args.num_samples,\n",
    "                    \"sample_padding\": self.args.sample_padding,\n",
    "                    \"magnitude_type\": self.args.magnitude_type,\n",
    "                    \"coordinate_encoding\": self.args.coordinate_encoding\n",
    "                })\n",
    "                layer = Conv2d_NN(**layer_params)\n",
    "\n",
    "            # elif self.args.layer == \"ConvNN_Attn\":\n",
    "            #     layer_params.update({\n",
    "            #         \"K\": self.args.K,\n",
    "            #         \"stride\": self.args.K,\n",
    "            #         \"sampling_type\": self.args.sampling_type,\n",
    "            #         \"num_samples\": self.args.num_samples,\n",
    "            #         \"sample_padding\": self.args.sample_padding,\n",
    "            #         \"magnitude_type\": self.args.magnitude_type,\n",
    "            #         \"img_size\": self.args.img_size[1:], # Pass H, W\n",
    "            #         \"attention_dropout\": self.args.attention_dropout,\n",
    "            #         \"coordinate_encoding\": self.args.coordinate_encoding\n",
    "            #     })\n",
    "            #     layer = Conv2d_NN_Attn(**layer_params)\n",
    "            \n",
    "            # elif self.args.layer == \"Attention\":\n",
    "            #     layer_params.update({\n",
    "            #         \"num_heads\": self.args.num_heads,\n",
    "            #     })\n",
    "            #     layer = Attention2d(**layer_params)\n",
    "            # elif \"/\" in self.args.layer: # Handle all branching cases\n",
    "            #     ch1 = out_ch // 2 if out_ch % 2 == 0 else out_ch // 2 + 1\n",
    "            #     ch2 = out_ch - ch1\n",
    "                \n",
    "            #     layer_params.update({\"channel_ratio\": (ch1, ch2)})\n",
    "                \n",
    "            #     # --- Check all sub-cases for branching layers ---\n",
    "            #     if self.args.layer == \"Conv2d/ConvNN\":\n",
    "            #         layer_params.update({\n",
    "            #             \"kernel_size\": self.args.kernel_size,\n",
    "            #             \"K\": self.args.K, \"stride\": self.args.K,\n",
    "            #             \"sampling_type\": self.args.sampling_type, \"num_samples\": self.args.num_samples,\n",
    "            #             \"sample_padding\": self.args.sample_padding, \"magnitude_type\": self.args.magnitude_type,\n",
    "            #             \"coordinate_encoding\": self.args.coordinate_encoding\n",
    "            #         })\n",
    "            #         layer = Conv2d_ConvNN_Branching(**layer_params)\n",
    "                \n",
    "            #     elif self.args.layer == \"Conv2d/ConvNN_Attn\":\n",
    "            #         layer_params.update({\n",
    "            #             \"kernel_size\": self.args.kernel_size,\n",
    "            #             \"K\": self.args.K, \"stride\": self.args.K,\n",
    "            #             \"sampling_type\": self.args.sampling_type, \"num_samples\": self.args.num_samples,\n",
    "            #             \"sample_padding\": self.args.sample_padding, \"magnitude_type\": self.args.magnitude_type,\n",
    "            #             \"img_size\": self.args.img_size[1:],\n",
    "            #             \"coordinate_encoding\": self.args.coordinate_encoding\n",
    "            #         })\n",
    "            #         layer = Conv2d_ConvNN_Attn_Branching(**layer_params)\n",
    "                \n",
    "            #     elif self.args.layer == \"Attention/ConvNN\":\n",
    "            #         layer_params.update({\n",
    "            #             \"num_heads\": self.args.num_heads,\n",
    "            #             \"K\": self.args.K, \"stride\": self.args.K,\n",
    "            #             \"sampling_type\": self.args.sampling_type, \"num_samples\": self.args.num_samples,\n",
    "            #             \"sample_padding\": self.args.sample_padding, \"magnitude_type\": self.args.magnitude_type,\n",
    "            #             \"coordinate_encoding\": self.args.coordinate_encoding\n",
    "            #         })\n",
    "            #         layer = Attention_ConvNN_Branching(**layer_params)\n",
    "\n",
    "            #     elif self.args.layer == \"Attention/ConvNN_Attn\":\n",
    "            #         layer_params.update({\n",
    "            #             \"num_heads\": self.args.num_heads,\n",
    "            #             \"K\": self.args.K, \"stride\": self.args.K,\n",
    "            #             \"sampling_type\": self.args.sampling_type, \"num_samples\": self.args.num_samples,\n",
    "            #             \"sample_padding\": self.args.sample_padding, \"magnitude_type\": self.args.magnitude_type,\n",
    "            #             \"img_size\": self.args.img_size[1:],\n",
    "            #             \"coordinate_encoding\": self.args.coordinate_encoding\n",
    "            #         })\n",
    "            #         layer = Attention_ConvNN_Attn_Branching(**layer_params)\n",
    "                \n",
    "            #     # This is the specific case that was failing\n",
    "            #     elif self.args.layer == \"Conv2d/Attention\":\n",
    "            #         layer_params.update({\n",
    "            #             \"num_heads\": self.args.num_heads,\n",
    "            #             \"kernel_size\": self.args.kernel_size, \n",
    "            #             \"coordinate_encoding\": self.args.coordinate_encoding\n",
    "            #         })\n",
    "            #         layer = Attention_Conv2d_Branching(**layer_params)\n",
    "                \n",
    "            #     else:\n",
    "            #         # This else now only catches unknown branching types\n",
    "            #         raise ValueError(f\"Unknown branching layer type: {self.args.layer}\")\n",
    "\n",
    "            else:\n",
    "                # This is the final else for non-branching types\n",
    "                raise ValueError(f\"Layer type {self.args.layer} not supported in AllConvNet\")\n",
    "\n",
    "            layers.append(nn.InstanceNorm2d(num_features=out_ch)) # Pre-layer normalization\n",
    "            layers.append(layer)\n",
    "            if self.args.layer == \"ConvNN_Attn\":\n",
    "                pass #layers.append(nn.Dropout(p=self.args.attention_dropout))\n",
    "            layers.append(nn.ReLU(inplace=True))\n",
    "            \n",
    "            # Update in_ch for the next layer\n",
    "            in_ch = out_ch\n",
    "            \n",
    "        self.features = nn.Sequential(*layers)\n",
    "        \n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.flatten = nn.Flatten()\n",
    "            \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.Linear(in_ch, self.args.num_classes) # Use the final in_ch value\n",
    "        )\n",
    "        \n",
    "        self.to(self.args.device)\n",
    "\n",
    "    def forward(self, x): \n",
    "        x = self.features(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    \n",
    "    def summary(self): \n",
    "        original_device = next(self.parameters()).device\n",
    "        try:\n",
    "            self.to(\"cpu\")\n",
    "            print(f\"--- Summary for {self.name} ---\")\n",
    "            # torchsummary expects batch dimension, but img_size doesn't include it\n",
    "            summary(self, input_size=self.img_size, device=\"cpu\") \n",
    "        except Exception as e:\n",
    "            print(f\"Could not generate summary: {e}\")\n",
    "        finally:\n",
    "            # Move model back to its original device\n",
    "            self.to(original_device)\n",
    "        \n",
    "    def parameter_count(self): \n",
    "        total_params = sum(p.numel() for p in self.parameters())\n",
    "        trainable_params = sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
    "        return total_params, trainable_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e88ef343-b9e7-4877-875f-10f3c0d3133e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import SimpleNamespace\n",
    "\n",
    "# Create default args\n",
    "args = SimpleNamespace(\n",
    "    layer=\"ConvNN\",\n",
    "    num_layers=3,\n",
    "    channels=[8, 16, 32],\n",
    "    K=9,\n",
    "    kernel_size=3,\n",
    "    sampling_type=\"all\",\n",
    "    num_samples=-1,\n",
    "    sample_padding=0,\n",
    "    num_heads=4,\n",
    "    attention_dropout=0.1,\n",
    "    shuffle_pattern=\"BA\",\n",
    "    shuffle_scale=2,\n",
    "    magnitude_type=\"similarity\",\n",
    "    coordinate_encoding=True,\n",
    "    dataset=\"cifar10\",\n",
    "    data_path=\"./Data\",\n",
    "    batch_size=64,\n",
    "    num_epochs=100,\n",
    "    use_amp=False,\n",
    "    clip_grad_norm=None,\n",
    "    criterion=\"CrossEntropy\",\n",
    "    optimizer=\"adamw\",\n",
    "    momentum=0.9,\n",
    "    weight_decay=1e-6,\n",
    "    lr=1e-3,\n",
    "    lr_step=20,\n",
    "    lr_gamma=0.1,\n",
    "    scheduler=\"step\",\n",
    "    device=\"cuda\",\n",
    "    seed=0,\n",
    "    output_dir=\"./Output/Simple/ConvNN_Coord_New_Prime_No_Clamp\", \n",
    "    resize=False\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4420f8bd-ed2b-4260-84b4-fec270b475d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Upscale transform not defined. Skipping dataset upscale.\n",
      "Model: All Convolutional Network ConvNN\n",
      "Total Parameters: 123338\n",
      "Trainable Parameters: 123338\n",
      "[Epoch 001] Time: 9.6555s | [Train] Loss: 2.00876740 Accuracy: Top1: 28.9242%, Top5: 79.1820% | [Test] Loss: 1.82081600 Accuracy: Top1: 37.6095%, Top5: 87.2811%\n",
      "[Epoch 002] Time: 9.7364s | [Train] Loss: 1.77392406 Accuracy: Top1: 40.9607%, Top5: 88.5730% | [Test] Loss: 1.68247658 Accuracy: Top1: 45.3921%, Top5: 90.6847%\n",
      "[Epoch 003] Time: 9.6794s | [Train] Loss: 1.67284842 Accuracy: Top1: 46.1857%, Top5: 90.9607% | [Test] Loss: 1.60171279 Accuracy: Top1: 49.9701%, Top5: 92.0880%\n",
      "[Epoch 004] Time: 9.7322s | [Train] Loss: 1.61192420 Accuracy: Top1: 49.4865%, Top5: 92.3054% | [Test] Loss: 1.56095310 Accuracy: Top1: 51.7217%, Top5: 93.0434%\n",
      "[Epoch 005] Time: 9.4963s | [Train] Loss: 1.57910795 Accuracy: Top1: 50.7992%, Top5: 92.9408% | [Test] Loss: 1.53900927 Accuracy: Top1: 52.6373%, Top5: 93.9192%\n",
      "[Epoch 006] Time: 9.7846s | [Train] Loss: 1.55060404 Accuracy: Top1: 52.7633%, Top5: 93.5602% | [Test] Loss: 1.51931901 Accuracy: Top1: 54.2197%, Top5: 93.9590%\n",
      "[Epoch 007] Time: 9.5332s | [Train] Loss: 1.53501939 Accuracy: Top1: 53.3628%, Top5: 93.8319% | [Test] Loss: 1.51242366 Accuracy: Top1: 54.9363%, Top5: 94.1979%\n",
      "[Epoch 008] Time: 9.5741s | [Train] Loss: 1.51354867 Accuracy: Top1: 54.6236%, Top5: 94.0497% | [Test] Loss: 1.48700372 Accuracy: Top1: 55.6429%, Top5: 94.8248%\n",
      "[Epoch 009] Time: 9.6632s | [Train] Loss: 1.50144050 Accuracy: Top1: 54.9792%, Top5: 94.2535% | [Test] Loss: 1.46728864 Accuracy: Top1: 56.6381%, Top5: 94.8248%\n",
      "[Epoch 010] Time: 9.9919s | [Train] Loss: 1.48939358 Accuracy: Top1: 55.8464%, Top5: 94.2795% | [Test] Loss: 1.47597166 Accuracy: Top1: 56.6182%, Top5: 94.7651%\n",
      "[Epoch 011] Time: 9.7994s | [Train] Loss: 1.47744618 Accuracy: Top1: 56.3939%, Top5: 94.4813% | [Test] Loss: 1.46234841 Accuracy: Top1: 57.1357%, Top5: 94.8746%\n",
      "[Epoch 012] Time: 9.5455s | [Train] Loss: 1.46401935 Accuracy: Top1: 57.1531%, Top5: 94.6232% | [Test] Loss: 1.43965836 Accuracy: Top1: 58.8575%, Top5: 95.5414%\n",
      "[Epoch 013] Time: 9.5983s | [Train] Loss: 1.45396713 Accuracy: Top1: 57.5228%, Top5: 94.9129% | [Test] Loss: 1.44981474 Accuracy: Top1: 58.0016%, Top5: 94.7950%\n",
      "[Epoch 014] Time: 9.5109s | [Train] Loss: 1.44610102 Accuracy: Top1: 58.2761%, Top5: 95.0188% | [Test] Loss: 1.41230311 Accuracy: Top1: 59.9224%, Top5: 95.4717%\n",
      "[Epoch 015] Time: 9.6858s | [Train] Loss: 1.43835793 Accuracy: Top1: 58.5558%, Top5: 95.1566% | [Test] Loss: 1.42503345 Accuracy: Top1: 59.4447%, Top5: 95.2329%\n",
      "[Epoch 016] Time: 9.7317s | [Train] Loss: 1.42934488 Accuracy: Top1: 58.9594%, Top5: 95.2026% | [Test] Loss: 1.42390896 Accuracy: Top1: 58.8276%, Top5: 95.1135%\n",
      "[Epoch 017] Time: 9.6487s | [Train] Loss: 1.42304627 Accuracy: Top1: 59.3031%, Top5: 95.1826% | [Test] Loss: 1.40375942 Accuracy: Top1: 60.6986%, Top5: 95.3822%\n",
      "[Epoch 018] Time: 9.7402s | [Train] Loss: 1.41284273 Accuracy: Top1: 59.7786%, Top5: 95.4863% | [Test] Loss: 1.39923660 Accuracy: Top1: 60.8380%, Top5: 95.5514%\n",
      "[Epoch 019] Time: 9.6907s | [Train] Loss: 1.40879015 Accuracy: Top1: 59.9744%, Top5: 95.5663% | [Test] Loss: 1.38611308 Accuracy: Top1: 60.9375%, Top5: 95.7902%\n",
      "[Epoch 020] Time: 9.6601s | [Train] Loss: 1.40299476 Accuracy: Top1: 60.2082%, Top5: 95.6142% | [Test] Loss: 1.38019786 Accuracy: Top1: 61.7834%, Top5: 95.7604%\n",
      "[Epoch 021] Time: 9.5646s | [Train] Loss: 1.35022968 Accuracy: Top1: 62.7977%, Top5: 96.1877% | [Test] Loss: 1.34510050 Accuracy: Top1: 63.1967%, Top5: 96.1385%\n",
      "[Epoch 022] Time: 9.6369s | [Train] Loss: 1.34362525 Accuracy: Top1: 63.0715%, Top5: 96.2136% | [Test] Loss: 1.34351930 Accuracy: Top1: 63.6445%, Top5: 96.4172%\n",
      "[Epoch 023] Time: 9.6210s | [Train] Loss: 1.34204936 Accuracy: Top1: 63.2952%, Top5: 96.3155% | [Test] Loss: 1.33908652 Accuracy: Top1: 63.6843%, Top5: 96.4072%\n",
      "[Epoch 024] Time: 9.8875s | [Train] Loss: 1.33958959 Accuracy: Top1: 63.3712%, Top5: 96.3635% | [Test] Loss: 1.33796854 Accuracy: Top1: 63.8037%, Top5: 96.3077%\n",
      "[Epoch 025] Time: 9.4816s | [Train] Loss: 1.33809613 Accuracy: Top1: 63.3792%, Top5: 96.3055% | [Test] Loss: 1.33700700 Accuracy: Top1: 63.7540%, Top5: 96.4670%\n",
      "[Epoch 026] Time: 9.8098s | [Train] Loss: 1.33613735 Accuracy: Top1: 63.6609%, Top5: 96.4314% | [Test] Loss: 1.33803887 Accuracy: Top1: 63.7440%, Top5: 96.2779%\n",
      "[Epoch 027] Time: 9.6477s | [Train] Loss: 1.33612193 Accuracy: Top1: 63.5670%, Top5: 96.3775% | [Test] Loss: 1.33676421 Accuracy: Top1: 63.9729%, Top5: 96.4371%\n",
      "[Epoch 028] Time: 9.8345s | [Train] Loss: 1.33347304 Accuracy: Top1: 63.6149%, Top5: 96.4614% | [Test] Loss: 1.33396934 Accuracy: Top1: 64.2217%, Top5: 96.3873%\n",
      "[Epoch 029] Time: 9.6323s | [Train] Loss: 1.33380104 Accuracy: Top1: 63.7468%, Top5: 96.4254% | [Test] Loss: 1.33197158 Accuracy: Top1: 64.1620%, Top5: 96.3774%\n",
      "[Epoch 030] Time: 9.6761s | [Train] Loss: 1.33272715 Accuracy: Top1: 63.7548%, Top5: 96.3795% | [Test] Loss: 1.33697359 Accuracy: Top1: 63.7838%, Top5: 96.3774%\n",
      "[Epoch 031] Time: 9.7618s | [Train] Loss: 1.32949607 Accuracy: Top1: 63.7908%, Top5: 96.4134% | [Test] Loss: 1.33232318 Accuracy: Top1: 64.1919%, Top5: 96.4072%\n",
      "[Epoch 032] Time: 9.4626s | [Train] Loss: 1.33080831 Accuracy: Top1: 63.8947%, Top5: 96.4914% | [Test] Loss: 1.33222037 Accuracy: Top1: 63.9928%, Top5: 96.4670%\n",
      "[Epoch 033] Time: 9.6754s | [Train] Loss: 1.32809913 Accuracy: Top1: 63.9686%, Top5: 96.5133% | [Test] Loss: 1.33125076 Accuracy: Top1: 63.9729%, Top5: 96.3077%\n",
      "[Epoch 034] Time: 9.5875s | [Train] Loss: 1.32713897 Accuracy: Top1: 64.1364%, Top5: 96.5273% | [Test] Loss: 1.32964851 Accuracy: Top1: 64.4506%, Top5: 96.3276%\n",
      "[Epoch 035] Time: 9.8406s | [Train] Loss: 1.32589950 Accuracy: Top1: 64.3203%, Top5: 96.4634% | [Test] Loss: 1.32957403 Accuracy: Top1: 64.2914%, Top5: 96.4670%\n",
      "[Epoch 036] Time: 9.8172s | [Train] Loss: 1.32239707 Accuracy: Top1: 64.3462%, Top5: 96.3715% | [Test] Loss: 1.32658961 Accuracy: Top1: 64.5303%, Top5: 96.3774%\n",
      "[Epoch 037] Time: 9.7335s | [Train] Loss: 1.32282387 Accuracy: Top1: 64.4441%, Top5: 96.4494% | [Test] Loss: 1.32641062 Accuracy: Top1: 64.1720%, Top5: 96.4769%\n",
      "[Epoch 038] Time: 9.5672s | [Train] Loss: 1.32384320 Accuracy: Top1: 64.2343%, Top5: 96.5373% | [Test] Loss: 1.32630450 Accuracy: Top1: 64.5502%, Top5: 96.4371%\n",
      "[Epoch 039] Time: 9.4866s | [Train] Loss: 1.32197057 Accuracy: Top1: 64.3762%, Top5: 96.5533% | [Test] Loss: 1.32555848 Accuracy: Top1: 64.6895%, Top5: 96.3973%\n",
      "[Epoch 040] Time: 9.6266s | [Train] Loss: 1.32048734 Accuracy: Top1: 64.4062%, Top5: 96.4694% | [Test] Loss: 1.32865901 Accuracy: Top1: 64.3312%, Top5: 96.3276%\n",
      "[Epoch 041] Time: 9.3562s | [Train] Loss: 1.31541935 Accuracy: Top1: 64.8418%, Top5: 96.6013% | [Test] Loss: 1.32300686 Accuracy: Top1: 64.6397%, Top5: 96.4072%\n",
      "[Epoch 042] Time: 9.4783s | [Train] Loss: 1.31432915 Accuracy: Top1: 64.5680%, Top5: 96.6053% | [Test] Loss: 1.32241658 Accuracy: Top1: 64.7791%, Top5: 96.4471%\n",
      "[Epoch 043] Time: 9.3292s | [Train] Loss: 1.31155685 Accuracy: Top1: 64.9516%, Top5: 96.5833% | [Test] Loss: 1.32211014 Accuracy: Top1: 64.6994%, Top5: 96.4769%\n",
      "[Epoch 044] Time: 9.8585s | [Train] Loss: 1.31253263 Accuracy: Top1: 64.8617%, Top5: 96.6252% | [Test] Loss: 1.32183816 Accuracy: Top1: 64.7492%, Top5: 96.4172%\n",
      "[Epoch 045] Time: 9.5628s | [Train] Loss: 1.31344871 Accuracy: Top1: 64.6719%, Top5: 96.5813% | [Test] Loss: 1.32174740 Accuracy: Top1: 64.6895%, Top5: 96.5068%\n",
      "[Epoch 046] Time: 9.6386s | [Train] Loss: 1.31294742 Accuracy: Top1: 64.7319%, Top5: 96.6152% | [Test] Loss: 1.32166878 Accuracy: Top1: 64.5999%, Top5: 96.4670%\n",
      "[Epoch 047] Time: 9.6024s | [Train] Loss: 1.31166351 Accuracy: Top1: 64.9796%, Top5: 96.7251% | [Test] Loss: 1.32140819 Accuracy: Top1: 64.7193%, Top5: 96.4471%\n",
      "[Epoch 048] Time: 9.4128s | [Train] Loss: 1.31223240 Accuracy: Top1: 64.9017%, Top5: 96.6832% | [Test] Loss: 1.32141356 Accuracy: Top1: 64.6397%, Top5: 96.4271%\n",
      "[Epoch 049] Time: 9.5555s | [Train] Loss: 1.31207587 Accuracy: Top1: 64.8138%, Top5: 96.6452% | [Test] Loss: 1.32179847 Accuracy: Top1: 64.6696%, Top5: 96.4271%\n",
      "[Epoch 050] Time: 9.5928s | [Train] Loss: 1.31162015 Accuracy: Top1: 64.9496%, Top5: 96.6892% | [Test] Loss: 1.32111290 Accuracy: Top1: 64.7393%, Top5: 96.4371%\n",
      "[Epoch 051] Time: 9.5203s | [Train] Loss: 1.31226983 Accuracy: Top1: 64.9616%, Top5: 96.6592% | [Test] Loss: 1.32126217 Accuracy: Top1: 64.7592%, Top5: 96.4072%\n",
      "[Epoch 052] Time: 9.6210s | [Train] Loss: 1.31226064 Accuracy: Top1: 64.8438%, Top5: 96.6033% | [Test] Loss: 1.32115244 Accuracy: Top1: 64.6198%, Top5: 96.4769%\n",
      "[Epoch 053] Time: 9.7219s | [Train] Loss: 1.31222620 Accuracy: Top1: 64.8777%, Top5: 96.7032% | [Test] Loss: 1.32108147 Accuracy: Top1: 64.9084%, Top5: 96.5267%\n",
      "[Epoch 054] Time: 9.9350s | [Train] Loss: 1.31244287 Accuracy: Top1: 64.7179%, Top5: 96.5733% | [Test] Loss: 1.32117164 Accuracy: Top1: 64.6198%, Top5: 96.4769%\n",
      "[Epoch 055] Time: 9.6303s | [Train] Loss: 1.31130415 Accuracy: Top1: 65.0156%, Top5: 96.7231% | [Test] Loss: 1.32091736 Accuracy: Top1: 64.8089%, Top5: 96.4968%\n",
      "[Epoch 056] Time: 9.7681s | [Train] Loss: 1.31271233 Accuracy: Top1: 64.8058%, Top5: 96.5993% | [Test] Loss: 1.32115340 Accuracy: Top1: 64.5999%, Top5: 96.4371%\n",
      "[Epoch 057] Time: 9.6777s | [Train] Loss: 1.31039686 Accuracy: Top1: 64.9836%, Top5: 96.6792% | [Test] Loss: 1.32073535 Accuracy: Top1: 64.7193%, Top5: 96.4670%\n",
      "[Epoch 058] Time: 9.5036s | [Train] Loss: 1.31141847 Accuracy: Top1: 65.0895%, Top5: 96.6632% | [Test] Loss: 1.32101181 Accuracy: Top1: 64.6795%, Top5: 96.4769%\n",
      "[Epoch 059] Time: 9.7202s | [Train] Loss: 1.30940669 Accuracy: Top1: 64.8617%, Top5: 96.5833% | [Test] Loss: 1.32062802 Accuracy: Top1: 64.8587%, Top5: 96.4570%\n",
      "[Epoch 060] Time: 9.5987s | [Train] Loss: 1.31172359 Accuracy: Top1: 64.8158%, Top5: 96.6572% | [Test] Loss: 1.32092647 Accuracy: Top1: 64.6696%, Top5: 96.4570%\n",
      "[Epoch 061] Time: 9.5728s | [Train] Loss: 1.31095511 Accuracy: Top1: 64.9277%, Top5: 96.6872% | [Test] Loss: 1.32079375 Accuracy: Top1: 64.7193%, Top5: 96.4769%\n",
      "[Epoch 062] Time: 9.5912s | [Train] Loss: 1.31104507 Accuracy: Top1: 64.8258%, Top5: 96.6512% | [Test] Loss: 1.32069670 Accuracy: Top1: 64.7094%, Top5: 96.4968%\n",
      "[Epoch 063] Time: 9.3270s | [Train] Loss: 1.31000593 Accuracy: Top1: 64.9996%, Top5: 96.6472% | [Test] Loss: 1.32064263 Accuracy: Top1: 64.7592%, Top5: 96.4769%\n",
      "[Epoch 064] Time: 9.5462s | [Train] Loss: 1.31165257 Accuracy: Top1: 65.0236%, Top5: 96.6532% | [Test] Loss: 1.32063528 Accuracy: Top1: 64.7094%, Top5: 96.4570%\n",
      "[Epoch 065] Time: 9.4008s | [Train] Loss: 1.30884737 Accuracy: Top1: 65.0775%, Top5: 96.6592% | [Test] Loss: 1.32052268 Accuracy: Top1: 64.7293%, Top5: 96.4769%\n",
      "[Epoch 066] Time: 9.7482s | [Train] Loss: 1.31214610 Accuracy: Top1: 64.9816%, Top5: 96.5953% | [Test] Loss: 1.32057912 Accuracy: Top1: 64.7193%, Top5: 96.4769%\n",
      "[Epoch 067] Time: 9.6151s | [Train] Loss: 1.30891120 Accuracy: Top1: 64.8637%, Top5: 96.6133% | [Test] Loss: 1.32060792 Accuracy: Top1: 64.7193%, Top5: 96.4968%\n",
      "[Epoch 068] Time: 9.3079s | [Train] Loss: 1.31268295 Accuracy: Top1: 64.8797%, Top5: 96.7491% | [Test] Loss: 1.32059113 Accuracy: Top1: 64.7492%, Top5: 96.4769%\n",
      "[Epoch 069] Time: 9.5361s | [Train] Loss: 1.30977186 Accuracy: Top1: 65.0575%, Top5: 96.7351% | [Test] Loss: 1.32065013 Accuracy: Top1: 64.7193%, Top5: 96.4670%\n",
      "[Epoch 070] Time: 9.6025s | [Train] Loss: 1.30980802 Accuracy: Top1: 64.8158%, Top5: 96.6472% | [Test] Loss: 1.32061131 Accuracy: Top1: 64.6895%, Top5: 96.4670%\n",
      "[Epoch 071] Time: 9.8057s | [Train] Loss: 1.31021846 Accuracy: Top1: 64.9257%, Top5: 96.6452% | [Test] Loss: 1.32061888 Accuracy: Top1: 64.7890%, Top5: 96.4769%\n",
      "[Epoch 072] Time: 9.7513s | [Train] Loss: 1.31284889 Accuracy: Top1: 64.7179%, Top5: 96.7072% | [Test] Loss: 1.32059378 Accuracy: Top1: 64.7791%, Top5: 96.4968%\n",
      "[Epoch 073] Time: 9.5239s | [Train] Loss: 1.31086631 Accuracy: Top1: 65.0775%, Top5: 96.6472% | [Test] Loss: 1.32056580 Accuracy: Top1: 64.7592%, Top5: 96.4968%\n",
      "[Epoch 074] Time: 9.8795s | [Train] Loss: 1.30920627 Accuracy: Top1: 65.0276%, Top5: 96.6073% | [Test] Loss: 1.32053252 Accuracy: Top1: 64.7393%, Top5: 96.4869%\n",
      "[Epoch 075] Time: 9.5802s | [Train] Loss: 1.30936812 Accuracy: Top1: 65.0036%, Top5: 96.5993% | [Test] Loss: 1.32051930 Accuracy: Top1: 64.6895%, Top5: 96.4968%\n",
      "[Epoch 076] Time: 9.4800s | [Train] Loss: 1.30919599 Accuracy: Top1: 65.1255%, Top5: 96.6972% | [Test] Loss: 1.32046843 Accuracy: Top1: 64.7691%, Top5: 96.4869%\n",
      "[Epoch 077] Time: 9.6511s | [Train] Loss: 1.31240506 Accuracy: Top1: 64.8837%, Top5: 96.5733% | [Test] Loss: 1.32049653 Accuracy: Top1: 64.7691%, Top5: 96.4769%\n",
      "[Epoch 078] Time: 9.8431s | [Train] Loss: 1.31167076 Accuracy: Top1: 64.9277%, Top5: 96.6552% | [Test] Loss: 1.32049570 Accuracy: Top1: 64.8089%, Top5: 96.4869%\n",
      "[Epoch 079] Time: 9.6043s | [Train] Loss: 1.30780672 Accuracy: Top1: 65.1095%, Top5: 96.6812% | [Test] Loss: 1.32040808 Accuracy: Top1: 64.7492%, Top5: 96.4968%\n",
      "[Epoch 080] Time: 9.7908s | [Train] Loss: 1.31105994 Accuracy: Top1: 64.8158%, Top5: 96.7231% | [Test] Loss: 1.32044220 Accuracy: Top1: 64.6795%, Top5: 96.5068%\n",
      "[Epoch 081] Time: 9.9297s | [Train] Loss: 1.31194932 Accuracy: Top1: 64.7978%, Top5: 96.6152% | [Test] Loss: 1.32044223 Accuracy: Top1: 64.6795%, Top5: 96.4968%\n",
      "[Epoch 082] Time: 9.5659s | [Train] Loss: 1.31294410 Accuracy: Top1: 64.7718%, Top5: 96.6212% | [Test] Loss: 1.32047010 Accuracy: Top1: 64.6795%, Top5: 96.4968%\n",
      "[Epoch 083] Time: 9.4381s | [Train] Loss: 1.30965733 Accuracy: Top1: 64.9077%, Top5: 96.7631% | [Test] Loss: 1.32046287 Accuracy: Top1: 64.6596%, Top5: 96.4968%\n",
      "[Epoch 084] Time: 9.9746s | [Train] Loss: 1.31149878 Accuracy: Top1: 64.8777%, Top5: 96.6792% | [Test] Loss: 1.32047522 Accuracy: Top1: 64.6497%, Top5: 96.4968%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 37\u001b[0m\n\u001b[1;32m     33\u001b[0m set_seed(args\u001b[38;5;241m.\u001b[39mseed)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Training Modules \u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m train_eval_results \u001b[38;5;241m=\u001b[39m \u001b[43mTrain_Eval\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_loader\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m                            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Storing Results in output directory \u001b[39;00m\n\u001b[1;32m     44\u001b[0m write_to_file(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(args\u001b[38;5;241m.\u001b[39moutput_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margs.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m), args)\n",
      "File \u001b[0;32m/mnt/research/j.farias/mkang2/Convolutional-Nearest-Neighbor/train_eval.py:92\u001b[0m, in \u001b[0;36mTrain_Eval\u001b[0;34m(args, model, train_loader, test_loader)\u001b[0m\n\u001b[1;32m     90\u001b[0m     scaler\u001b[38;5;241m.\u001b[39mupdate()\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:    \n\u001b[0;32m---> 92\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     94\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/mnt/local/python3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/local/python3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[15], line 150\u001b[0m, in \u001b[0;36mAllConvNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x): \n\u001b[0;32m--> 150\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(x)\n\u001b[1;32m    152\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflatten(x)\n",
      "File \u001b[0;32m/mnt/local/python3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/local/python3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/local/python3.12/lib/python3.12/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/mnt/local/python3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/local/python3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[14], line 98\u001b[0m, in \u001b[0;36mConv2d_NN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m:    \n\u001b[1;32m     95\u001b[0m     \u001b[38;5;66;03m# ConvNN Algorithm \u001b[39;00m\n\u001b[1;32m     96\u001b[0m     matrix_magnitude \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_calculate_distance_matrix(x, sqrt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmagnitude_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdistance\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_calculate_similarity_matrix(x)\n\u001b[0;32m---> 98\u001b[0m     prime \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prime_new\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmatrix_magnitude\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mK\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaximum\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m### CHANGED\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrandom\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;66;03m# Select random samples\u001b[39;00m\n\u001b[1;32m    102\u001b[0m     rand_idx \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandperm(x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m], device\u001b[38;5;241m=\u001b[39mx\u001b[38;5;241m.\u001b[39mdevice)[:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples]\n",
      "Cell \u001b[0;32mIn[14], line 174\u001b[0m, in \u001b[0;36mConv2d_NN._prime_new\u001b[0;34m(self, matrix, magnitude_matrix, K, maximum)\u001b[0m\n\u001b[1;32m    171\u001b[0m     similarity_matrix \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mbmm(norm_matrix\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m), norm_sample)\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m similarity_matrix\n\u001b[0;32m--> 174\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_prime_new\u001b[39m(\u001b[38;5;28mself\u001b[39m, matrix, magnitude_matrix, K, maximum):\n\u001b[1;32m    175\u001b[0m     b, c, t \u001b[38;5;241m=\u001b[39m matrix\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    176\u001b[0m     topk_values, topk_indices \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtopk(magnitude_matrix, k\u001b[38;5;241m=\u001b[39mK, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, largest\u001b[38;5;241m=\u001b[39mmaximum)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Check if the output directory exists, if not create it\n",
    "if args.output_dir:\n",
    "    Path(args.output_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Dataset \n",
    "if args.dataset == \"cifar10\":\n",
    "    dataset = CIFAR10(args)\n",
    "    args.num_classes = dataset.num_classes \n",
    "    args.img_size = dataset.img_size \n",
    "elif args.dataset == \"cifar100\":\n",
    "    dataset = CIFAR100(args)\n",
    "    args.num_classes = dataset.num_classes \n",
    "    args.img_size = dataset.img_size \n",
    "elif args.dataset == \"imagenet\":\n",
    "    dataset = ImageNet(args)\n",
    "    args.num_classes = dataset.num_classes \n",
    "    args.img_size = dataset.img_size\n",
    "else:\n",
    "    raise ValueError(\"Dataset not supported\")\n",
    "\n",
    "# Model \n",
    "model = AllConvNet(args)\n",
    "print(f\"Model: {model.name}\")\n",
    "\n",
    "# Parameters\n",
    "total_params, trainable_params = model.parameter_count()\n",
    "print(f\"Total Parameters: {total_params}\")\n",
    "print(f\"Trainable Parameters: {trainable_params}\")\n",
    "args.total_params = total_params\n",
    "args.trainable_params = trainable_params\n",
    "\n",
    "# Set the seed for reproducibility\n",
    "set_seed(args.seed)\n",
    "\n",
    "\n",
    "# Training Modules \n",
    "train_eval_results = Train_Eval(args, \n",
    "                            model, \n",
    "                            dataset.train_loader, \n",
    "                            dataset.test_loader\n",
    "                            )\n",
    "\n",
    "# Storing Results in output directory \n",
    "write_to_file(os.path.join(args.output_dir, \"args.txt\"), args)\n",
    "write_to_file(os.path.join(args.output_dir, \"model.txt\"), model)\n",
    "write_to_file(os.path.join(args.output_dir, \"train_eval_results.txt\"), train_eval_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b69b44",
   "metadata": {},
   "source": [
    "# New Conv2d with pixel shuffle n coordinate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1f46db-02f3-4441-a49b-96789053f148",
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import SimpleNamespace\n",
    "\n",
    "# Create default args\n",
    "args = SimpleNamespace(\n",
    "    layer=\"Conv2d\",\n",
    "    num_layers=3,\n",
    "    channels=[8, 16, 32],\n",
    "    K=9,\n",
    "    kernel_size=3,\n",
    "    sampling_type=\"all\",\n",
    "    num_samples=-1,\n",
    "    sample_padding=0,\n",
    "    num_heads=4,\n",
    "    attention_dropout=0.1,\n",
    "    shuffle_pattern=\"BA\",\n",
    "    shuffle_scale=2,\n",
    "    magnitude_type=\"similarity\",\n",
    "    coordinate_encoding=True,\n",
    "    dataset=\"cifar10\",\n",
    "    data_path=\"./Data\",\n",
    "    batch_size=64,\n",
    "    num_epochs=100,\n",
    "    use_amp=False,\n",
    "    clip_grad_norm=None,\n",
    "    criterion=\"CrossEntropy\",\n",
    "    optimizer=\"adamw\",\n",
    "    momentum=0.9,\n",
    "    weight_decay=1e-6,\n",
    "    lr=1e-3,\n",
    "    lr_step=20,\n",
    "    lr_gamma=0.1,\n",
    "    scheduler=\"step\",\n",
    "    device=\"cuda\",\n",
    "    seed=0,\n",
    "    output_dir=\"./Output/Simple/Conv2d_New\", \n",
    "    resize=False\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d58405b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the output directory exists, if not create it\n",
    "if args.output_dir:\n",
    "    Path(args.output_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Dataset \n",
    "if args.dataset == \"cifar10\":\n",
    "    dataset = CIFAR10(args)\n",
    "    args.num_classes = dataset.num_classes \n",
    "    args.img_size = dataset.img_size \n",
    "elif args.dataset == \"cifar100\":\n",
    "    dataset = CIFAR100(args)\n",
    "    args.num_classes = dataset.num_classes \n",
    "    args.img_size = dataset.img_size \n",
    "elif args.dataset == \"imagenet\":\n",
    "    dataset = ImageNet(args)\n",
    "    args.num_classes = dataset.num_classes \n",
    "    args.img_size = dataset.img_size\n",
    "else:\n",
    "    raise ValueError(\"Dataset not supported\")\n",
    "\n",
    "# Model \n",
    "model = AllConvNet(args)\n",
    "print(f\"Model: {model.name}\")\n",
    "\n",
    "# Parameters\n",
    "total_params, trainable_params = model.parameter_count()\n",
    "print(f\"Total Parameters: {total_params}\")\n",
    "print(f\"Trainable Parameters: {trainable_params}\")\n",
    "args.total_params = total_params\n",
    "args.trainable_params = trainable_params\n",
    "\n",
    "# Set the seed for reproducibility\n",
    "set_seed(args.seed)\n",
    "\n",
    "\n",
    "# Training Modules \n",
    "train_eval_results = Train_Eval(args, \n",
    "                            model, \n",
    "                            dataset.train_loader, \n",
    "                            dataset.test_loader\n",
    "                            )\n",
    "\n",
    "# Storing Results in output directory \n",
    "write_to_file(os.path.join(args.output_dir, \"args.txt\"), args)\n",
    "write_to_file(os.path.join(args.output_dir, \"model.txt\"), model)\n",
    "write_to_file(os.path.join(args.output_dir, \"train_eval_results.txt\"), train_eval_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
