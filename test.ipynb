{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3fce27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2aa1d480",
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinate_cache = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8671829",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _add_coordinate_encoding( x):\n",
    "    b, c, t = x.shape \n",
    "    cache_key = f\"{t}_{x.device}\"\n",
    "    if cache_key in coordinate_cache:\n",
    "        coords_vec = coordinate_cache[cache_key]\n",
    "    else:\n",
    "        coords_vec = torch.linspace(start=-1, end=1, steps=t, device=x.device).unsqueeze(0).expand(b, -1)\n",
    "        coordinate_cache[cache_key] = coords_vec\n",
    "\n",
    "    expanded_coords = coords_vec.unsqueeze(1).expand(b, -1, -1)\n",
    "    x_with_coords = torch.cat((x, expanded_coords), dim=1)  \n",
    "    return x_with_coords\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7bada92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([256, 3, 10])\n",
      "With Coordinate Encoding shape: torch.Size([256, 4, 10])\n",
      "Coordinate Cache Size: 1\n",
      "Coordinate Cache Keys: ['10_cpu']\n",
      "coordinate cache: tensor([-1.0000, -0.7778, -0.5556, -0.3333, -0.1111,  0.1111,  0.3333,  0.5556,\n",
      "         0.7778,  1.0000])\n",
      "x_with_coords: tensor([-1.0000, -0.7778, -0.5556, -0.3333, -0.1111,  0.1111,  0.3333,  0.5556,\n",
      "         0.7778,  1.0000])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(256, 3, 10)\n",
    "x_with_coords = _add_coordinate_encoding(x)\n",
    "print(f\"Input shape: {x.shape}\")\n",
    "print(f\"With Coordinate Encoding shape: {x_with_coords.shape}\")\n",
    "\n",
    "print(f\"Coordinate Cache Size: {len(coordinate_cache)}\")\n",
    "print(f\"Coordinate Cache Keys: {list(coordinate_cache.keys())}\")\n",
    "\n",
    "print(f\"coordinate cache: {coordinate_cache['10_cpu'][0, ]}\")\n",
    "\n",
    "print(f\"x_with_coords: {x_with_coords[0, 3, :]}\")  # Print the first channel of the first sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad6791ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinate_cache = {} \n",
    "def _add_coordinate_encoding( x):\n",
    "    b, c, t = x.shape \n",
    "    cache_key = f\"{b}_{t}_{x.device}\"\n",
    "    if cache_key in coordinate_cache:\n",
    "        expanded_coords = coordinate_cache[cache_key]\n",
    "    else:\n",
    "        coords_vec = torch.linspace(start=-1, end=1, steps=t, device=x.device).unsqueeze(0).expand(b, -1)\n",
    "        expanded_coords = coords_vec.unsqueeze(1).expand(b, -1, -1)\n",
    "        coordinate_cache[cache_key] = expanded_coords\n",
    "\n",
    "\n",
    "    x_with_coords = torch.cat((x, expanded_coords), dim=1)  \n",
    "    return x_with_coords\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e46532a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([64, 3, 10])\n",
      "With Coordinate Encoding shape: torch.Size([64, 4, 10])\n",
      "Coordinate Cache Size: 2\n",
      "Coordinate Cache Keys: ['256_10_cpu', '64_10_cpu']\n",
      "coordinate cache: tensor([[-1.0000, -0.7778, -0.5556, -0.3333, -0.1111,  0.1111,  0.3333,  0.5556,\n",
      "          0.7778,  1.0000]])\n",
      "x_with_coords: tensor([-1.0000, -0.7778, -0.5556, -0.3333, -0.1111,  0.1111,  0.3333,  0.5556,\n",
      "         0.7778,  1.0000])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(64, 3, 10)\n",
    "x_with_coords = _add_coordinate_encoding(x)\n",
    "print(f\"Input shape: {x.shape}\")\n",
    "print(f\"With Coordinate Encoding shape: {x_with_coords.shape}\")\n",
    "\n",
    "print(f\"Coordinate Cache Size: {len(coordinate_cache)}\")\n",
    "print(f\"Coordinate Cache Keys: {list(coordinate_cache.keys())}\")\n",
    "\n",
    "print(f\"coordinate cache: {coordinate_cache['64_10_cpu'][0, ]}\")\n",
    "\n",
    "print(f\"x_with_coords: {x_with_coords[0, 3, :]}\")  # Print the first channel of the first sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5066b810",
   "metadata": {},
   "source": [
    "## ConvNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd12247b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "ConvNN\n",
    "Total parameters: 185,150\n",
    "Trainable parameters: 185,150\n",
    "\n",
    "Input shape: torch.Size([64, 197, 64])\n",
    "After Permute: torch.Size([64, 64, 197])\n",
    "After Split_head: torch.Size([64, 4, 197, 16])\n",
    "After Batch_Combine: torch.Size([256, 16, 197]) ### [256, 17, 197] added coordinate encoding\n",
    "After Conv1d: torch.Size([256, 16, 197]) ###    [256, 17, 197] added coordinate encoding\n",
    "After batch_split: torch.Size([64, 4, 197, 16]) ### [64, 4, 197, 17] added coordinate encoding\n",
    "After Combine_Heads: torch.Size([64, 64, 197]) ### [64, 68, 197] added coordinate encoding\n",
    "\n",
    "Output shape: torch.Size([64, 100])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2bf967",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2659c0f1",
   "metadata": {},
   "source": [
    "## ConvNNAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d351b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ConvNNAttention\n",
    "Total parameters: 83,716\n",
    "Trainable parameters: 83,716\n",
    "\n",
    "Input shape: torch.Size([64, 197, 64])\n",
    "After Split_head: torch.Size([64, 4, 197, 16])\n",
    "After Batch_Combine: torch.Size([256, 16, 197])\n",
    "After Conv1d: torch.Size([256, 16, 197])\n",
    "After permute: torch.Size([256, 197, 16])\n",
    "After Batch_Split: torch.Size([64, 4, 197, 16])\n",
    "After Combine_Heads: torch.Size([64, 197, 64])\n",
    "\n",
    "Output shape: torch.Size([64, 100])\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08b2cea",
   "metadata": {},
   "source": [
    "╰─$ python -u \"/Users/mingikang/Developer/Convolutional-Nearest-Neighbor/vit.py\"\n",
    "Regular Attention\n",
    "Total parameters: 70,228\n",
    "Trainable parameters: 70,228\n",
    "Output shape: torch.Size([64, 100])\n",
    "\n",
    "ConvNN\n",
    "Total parameters: 218,546\n",
    "Trainable parameters: 218,546\n",
    "Output shape: torch.Size([64, 100])\n",
    "\n",
    "ConvNNAttention\n",
    "Total parameters: 71,930\n",
    "Trainable parameters: 71,930\n",
    "Output shape: torch.Size([64, 100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b31576",
   "metadata": {},
   "source": [
    "╰─$ python -u \"/Users/mingikang/Developer/Convolutional-Nearest-Neighbor/vit.py\"\n",
    "Regular Attention\n",
    "Total parameters: 70,228\n",
    "Trainable parameters: 70,228\n",
    "Output shape: torch.Size([64, 100])\n",
    "\n",
    "ConvNN\n",
    "Total parameters: 218,295\n",
    "Trainable parameters: 218,295\n",
    "Output shape: torch.Size([64, 100])\n",
    "\n",
    "ConvNNAttention\n",
    "Total parameters: 71,679\n",
    "Trainable parameters: 71,679\n",
    "Output shape: torch.Size([64, 100])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
