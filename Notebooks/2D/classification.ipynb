{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Test for CNN + Conv2d_NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('../')\n",
    "import time\n",
    "import os \n",
    "\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchsummary import summary \n",
    "\n",
    "from Conv2d_NN_spatial import Conv2d_NN_spatial\n",
    "from Conv2d_NN import Conv2d_NN\n",
    "from pixelshuffle import PixelShuffle1D, PixelUnshuffle1D\n",
    "\n",
    "\n",
    "from data import MNIST, FashionMNIST, CIFAR10\n",
    "from train import train_model, evaluate_accuracy \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST + FashionMNIST + CIFAR10 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mnist = MNIST()\n",
    "fashionmnist = FashionMNIST()\n",
    "cifar10 = CIFAR10()\n",
    "\n",
    "\n",
    "\n",
    "mnist.visual()\n",
    "fashionmnist.visual()\n",
    "cifar10.visual()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. MNIST + Fashion MNIST TEST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i. Conv2d_NN all sample Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "           Flatten-1               [-1, 4, 196]               0\n",
      "            Conv1d-2              [-1, 20, 196]             660\n",
      "              ReLU-3              [-1, 20, 196]               0\n",
      "         Conv1d_NN-4              [-1, 20, 196]               0\n",
      "         Conv2d_NN-5            [-1, 5, 28, 28]               0\n",
      "           Flatten-6              [-1, 20, 196]               0\n",
      "            Conv1d-7              [-1, 40, 196]           6,440\n",
      "              ReLU-8              [-1, 40, 196]               0\n",
      "         Conv1d_NN-9              [-1, 40, 196]               0\n",
      "        Conv2d_NN-10           [-1, 10, 28, 28]               0\n",
      "          Flatten-11              [-1, 40, 196]               0\n",
      "           Conv1d-12              [-1, 80, 196]          25,680\n",
      "             ReLU-13              [-1, 80, 196]               0\n",
      "        Conv1d_NN-14              [-1, 80, 196]               0\n",
      "        Conv2d_NN-15           [-1, 20, 28, 28]               0\n",
      "          Flatten-16                [-1, 15680]               0\n",
      "           Linear-17                   [-1, 10]         156,810\n",
      "================================================================\n",
      "Total params: 189,590\n",
      "Trainable params: 189,590\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 1.05\n",
      "Params size (MB): 0.72\n",
      "Estimated Total Size (MB): 1.78\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Model \n",
    "conv2d_nn_all = nn.Sequential(\n",
    "   Conv2d_NN(\n",
    "      in_channels=1,\n",
    "      out_channels=5,\n",
    "      K=8,\n",
    "      stride=8,\n",
    "      padding=0,\n",
    "      shuffle_scale=2\n",
    "   ), \n",
    "   Conv2d_NN(\n",
    "      in_channels=5,\n",
    "      out_channels=10,\n",
    "      K=8,\n",
    "      stride=8,\n",
    "      padding=0,\n",
    "      shuffle_scale=2\n",
    "   ),\n",
    "   Conv2d_NN(\n",
    "      in_channels=10,\n",
    "      out_channels=20,\n",
    "      K=8,\n",
    "      stride=8,\n",
    "      padding=0,\n",
    "      shuffle_scale=2\n",
    "   ),\n",
    "   nn.Flatten(), \n",
    "   nn.Linear(15680, 10)\n",
    "   \n",
    ").to('cpu')\n",
    "   \n",
    "\n",
    "from torchsummary import summary\n",
    "summary(conv2d_nn_all, (1, 28, 28))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Time: 50.76565194129944, Loss: 0.395222249355461\n",
      "Epoch 2, Time: 48.43545699119568, Loss: 0.28505940358045256\n",
      "Epoch 3, Time: 48.43069505691528, Loss: 0.23820897341886563\n",
      "Epoch 4, Time: 48.554861068725586, Loss: 0.20976646410138494\n",
      "Epoch 5, Time: 48.7927827835083, Loss: 0.1852923391490126\n",
      "Epoch 6, Time: 48.684605836868286, Loss: 0.16969119698833873\n",
      "Epoch 7, Time: 48.62673902511597, Loss: 0.15526772164074437\n",
      "Epoch 8, Time: 48.80111002922058, Loss: 0.14701102189084234\n",
      "Epoch 9, Time: 48.815690994262695, Loss: 0.13361351180082953\n",
      "Epoch 10, Time: 48.944226026535034, Loss: 0.12517256671830868\n",
      "\n",
      " Average epoch time: 48.88518197536469\n",
      "Accuracy on test set: 94.74%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "94.74"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MNIST results \n",
    "conv2d_nn_all.to('mps')\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(conv2d_nn_all.parameters(), lr=0.001)\n",
    "num_epochs = 10 \n",
    "train_model(conv2d_nn_all, mnist.train_loader, criterion, optimizer, num_epochs)\n",
    "evaluate_accuracy(conv2d_nn_all, mnist.test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Time: 45.70274996757507, Loss: 0.4886427748559126\n",
      "Epoch 2, Time: 45.533416986465454, Loss: 0.37205283355706537\n",
      "Epoch 3, Time: 45.46400713920593, Loss: 0.34134637871022416\n",
      "Epoch 4, Time: 45.73551917076111, Loss: 0.32046100512337583\n",
      "Epoch 5, Time: 45.42999196052551, Loss: 0.2995621865428587\n",
      "Epoch 6, Time: 45.48528718948364, Loss: 0.2838749874359382\n",
      "Epoch 7, Time: 45.46282196044922, Loss: 0.2682511402027948\n",
      "Epoch 8, Time: 45.51191997528076, Loss: 0.25358781184373635\n",
      "Epoch 9, Time: 45.48625993728638, Loss: 0.24333831468529538\n",
      "Epoch 10, Time: 45.57072114944458, Loss: 0.23079304418949556\n",
      "\n",
      " Average epoch time: 45.538269543647765\n",
      "Accuracy on test set: 86.95%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "86.95"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fashion MNIST results\n",
    "conv2d_nn_all.apply(lambda m: m.reset_parameters() if hasattr(m, 'reset_parameters') else None)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(conv2d_nn_all.parameters(), lr=0.001)\n",
    "num_epochs = 10 \n",
    "train_model(conv2d_nn_all, fashionmnist.train_loader, criterion, optimizer, num_epochs)\n",
    "evaluate_accuracy(conv2d_nn_all, fashionmnist.test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ii. Conv2d NN N (10) Sample Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "           Flatten-1               [-1, 4, 196]               0\n",
      "            Conv1d-2              [-1, 20, 196]             660\n",
      "              ReLU-3              [-1, 20, 196]               0\n",
      "         Conv1d_NN-4              [-1, 20, 196]               0\n",
      "         Conv2d_NN-5            [-1, 5, 28, 28]               0\n",
      "           Flatten-6              [-1, 20, 196]               0\n",
      "            Conv1d-7              [-1, 40, 196]           6,440\n",
      "              ReLU-8              [-1, 40, 196]               0\n",
      "         Conv1d_NN-9              [-1, 40, 196]               0\n",
      "        Conv2d_NN-10           [-1, 10, 28, 28]               0\n",
      "          Flatten-11              [-1, 40, 196]               0\n",
      "           Conv1d-12              [-1, 80, 196]          25,680\n",
      "             ReLU-13              [-1, 80, 196]               0\n",
      "        Conv1d_NN-14              [-1, 80, 196]               0\n",
      "        Conv2d_NN-15           [-1, 20, 28, 28]               0\n",
      "          Flatten-16                [-1, 15680]               0\n",
      "           Linear-17                   [-1, 10]         156,810\n",
      "================================================================\n",
      "Total params: 189,590\n",
      "Trainable params: 189,590\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 1.05\n",
      "Params size (MB): 0.72\n",
      "Estimated Total Size (MB): 1.78\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Model \n",
    "conv2d_nn_n = nn.Sequential(\n",
    "   Conv2d_NN(\n",
    "      in_channels=1,\n",
    "      out_channels=5,\n",
    "      K=8,\n",
    "      stride=8,\n",
    "      padding=0,\n",
    "      shuffle_scale=2, \n",
    "      samples = 10\n",
    "      \n",
    "   ), \n",
    "   Conv2d_NN(\n",
    "      in_channels=5,\n",
    "      out_channels=10,\n",
    "      K=8,\n",
    "      stride=8,\n",
    "      padding=0,\n",
    "      shuffle_scale=2, \n",
    "      samples = 10\n",
    "   ),\n",
    "   Conv2d_NN(\n",
    "      in_channels=10,\n",
    "      out_channels=20,\n",
    "      K=8,\n",
    "      stride=8,\n",
    "      padding=0,\n",
    "      shuffle_scale=2, \n",
    "      samples = 10\n",
    "   ),\n",
    "   nn.Flatten(), \n",
    "   nn.Linear(15680, 10)\n",
    "   \n",
    ").to('cpu')\n",
    "   \n",
    "\n",
    "from torchsummary import summary\n",
    "summary(conv2d_nn_n, (1, 28, 28))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Time: 50.36802625656128, Loss: 0.4923113819314981\n",
      "Epoch 2, Time: 50.28737282752991, Loss: 0.2828874581300818\n",
      "Epoch 3, Time: 50.259093046188354, Loss: 0.2586979058656548\n",
      "Epoch 4, Time: 50.32127809524536, Loss: 0.24474306331911702\n",
      "Epoch 5, Time: 50.324918031692505, Loss: 0.23229428561432147\n",
      "Epoch 6, Time: 50.36748790740967, Loss: 0.2220112123667622\n",
      "Epoch 7, Time: 50.309467792510986, Loss: 0.21408166480002436\n",
      "Epoch 8, Time: 50.313941955566406, Loss: 0.19994358667162562\n",
      "Epoch 9, Time: 50.278324127197266, Loss: 0.17139332480569766\n",
      "Epoch 10, Time: 50.23194408416748, Loss: 0.14564617772076302\n",
      "\n",
      " Average epoch time: 50.30618541240692\n",
      "Accuracy on test set: 95.73%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "95.73"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MNIST results \n",
    "conv2d_nn_n.to('mps')\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(conv2d_nn_n.parameters(), lr=0.001)\n",
    "num_epochs = 10 \n",
    "train_model(conv2d_nn_n, mnist.train_loader, criterion, optimizer, num_epochs)\n",
    "evaluate_accuracy(conv2d_nn_n, mnist.test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Time: 49.28506898880005, Loss: 0.5804819499632952\n",
      "Epoch 2, Time: 49.34972286224365, Loss: 0.40762329482828885\n",
      "Epoch 3, Time: 49.24613308906555, Loss: 0.37934364586560204\n",
      "Epoch 4, Time: 49.31911826133728, Loss: 0.3606364101425671\n",
      "Epoch 5, Time: 49.323676109313965, Loss: 0.3466842062215307\n",
      "Epoch 6, Time: 49.30271816253662, Loss: 0.3358400629273356\n",
      "Epoch 7, Time: 49.36181902885437, Loss: 0.3272329672599144\n",
      "Epoch 8, Time: 49.33924198150635, Loss: 0.3183384804027294\n",
      "Epoch 9, Time: 49.33195495605469, Loss: 0.3109081112134304\n",
      "Epoch 10, Time: 49.31736779212952, Loss: 0.3037602575396551\n",
      "\n",
      " Average epoch time: 49.317682123184206\n",
      "Accuracy on test set: 86.53%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "86.53"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fashion MNIST results\n",
    "conv2d_nn_n.apply(lambda m: m.reset_parameters() if hasattr(m, 'reset_parameters') else None)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(conv2d_nn_n.parameters(), lr=0.001)\n",
    "num_epochs = 10 \n",
    "train_model(conv2d_nn_n, fashionmnist.train_loader, criterion, optimizer, num_epochs)\n",
    "evaluate_accuracy(conv2d_nn_n, fashionmnist.test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iii. Conv2d NN Spatial samples Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "           Flatten-1               [-1, 1, 784]               0\n",
      "            Conv1d-2               [-1, 5, 784]              45\n",
      "              ReLU-3               [-1, 5, 784]               0\n",
      " Conv1d_NN_spatial-4               [-1, 5, 784]               0\n",
      " Conv2d_NN_spatial-5            [-1, 5, 28, 28]               0\n",
      "           Flatten-6               [-1, 5, 784]               0\n",
      "            Conv1d-7              [-1, 10, 784]             410\n",
      "              ReLU-8              [-1, 10, 784]               0\n",
      " Conv1d_NN_spatial-9              [-1, 10, 784]               0\n",
      "Conv2d_NN_spatial-10           [-1, 10, 28, 28]               0\n",
      "          Flatten-11              [-1, 10, 784]               0\n",
      "           Conv1d-12              [-1, 20, 784]           1,620\n",
      "             ReLU-13              [-1, 20, 784]               0\n",
      "Conv1d_NN_spatial-14              [-1, 20, 784]               0\n",
      "Conv2d_NN_spatial-15           [-1, 20, 28, 28]               0\n",
      "          Flatten-16                [-1, 15680]               0\n",
      "           Linear-17                   [-1, 10]         156,810\n",
      "================================================================\n",
      "Total params: 158,885\n",
      "Trainable params: 158,885\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 1.05\n",
      "Params size (MB): 0.61\n",
      "Estimated Total Size (MB): 1.66\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Model \n",
    "conv2d_nn_spatial = nn.Sequential(\n",
    "   Conv2d_NN_spatial(\n",
    "      in_channels=1,\n",
    "      out_channels=5,\n",
    "      K=8,\n",
    "      stride=8,\n",
    "      padding=0,\n",
    "      shuffle_scale=2, \n",
    "      samples=3\n",
    "      \n",
    "   ), \n",
    "   Conv2d_NN_spatial(\n",
    "      in_channels=5,\n",
    "      out_channels=10,\n",
    "      K=8,\n",
    "      stride=8,\n",
    "      padding=0,\n",
    "      shuffle_scale=2, \n",
    "      samples=3\n",
    "   ),\n",
    "   Conv2d_NN_spatial(\n",
    "      in_channels=10,\n",
    "      out_channels=20,\n",
    "      K=8,\n",
    "      stride=8,\n",
    "      padding=0,\n",
    "      shuffle_scale=2, \n",
    "      samples=3\n",
    "   ),\n",
    "   nn.Flatten(), \n",
    "   nn.Linear(15680, 10)\n",
    "   \n",
    ").to('cpu')\n",
    "   \n",
    "\n",
    "from torchsummary import summary\n",
    "summary(conv2d_nn_spatial, (1, 28, 28))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Time: 89.54429221153259, Loss: 2.302743795329828\n",
      "Epoch 2, Time: 87.63583207130432, Loss: 2.3012995963920155\n",
      "Epoch 3, Time: 87.68997597694397, Loss: 2.301297891877099\n",
      "Epoch 4, Time: 87.6235249042511, Loss: 2.3013042259826335\n",
      "Epoch 5, Time: 87.61026883125305, Loss: 2.301300457799867\n",
      "Epoch 6, Time: 87.6958839893341, Loss: 2.3013017670686313\n",
      "Epoch 7, Time: 87.60521388053894, Loss: 2.3012853698181446\n",
      "Epoch 8, Time: 87.60860800743103, Loss: 2.301316419389965\n",
      "Epoch 9, Time: 87.64317202568054, Loss: 2.301300043744573\n",
      "Epoch 10, Time: 87.62095904350281, Loss: 2.301303668571179\n",
      "\n",
      " Average epoch time: 87.82777309417725\n",
      "Accuracy on test set: 11.35%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11.35"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MNIST results \n",
    "conv2d_nn_spatial.to('mps')\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(conv2d_nn_spatial.parameters(), lr=0.001)\n",
    "num_epochs = 10 \n",
    "train_model(conv2d_nn_spatial, mnist.train_loader, criterion, optimizer, num_epochs)\n",
    "evaluate_accuracy(conv2d_nn_spatial, mnist.test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Time: 91.90598917007446, Loss: 2.2617369547073265\n",
      "Epoch 2, Time: 90.5119559764862, Loss: 2.2338889804221926\n",
      "Epoch 3, Time: 90.55145120620728, Loss: 2.1631129911459333\n",
      "Epoch 4, Time: 91.1064920425415, Loss: 2.126566750281401\n",
      "Epoch 5, Time: 90.08047318458557, Loss: 2.1209207712205997\n",
      "Epoch 6, Time: 89.7628881931305, Loss: 2.1412102792308785\n",
      "Epoch 7, Time: 89.89161610603333, Loss: 2.113275536341962\n",
      "Epoch 8, Time: 89.65816402435303, Loss: 2.144702168034592\n",
      "Epoch 9, Time: 89.4534592628479, Loss: 2.171282206898305\n",
      "Epoch 10, Time: 89.80284023284912, Loss: 2.116005119230193\n",
      "\n",
      " Average epoch time: 90.27253293991089\n",
      "Accuracy on test set: 16.17%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16.17"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fashion MNIST results\n",
    "conv2d_nn_spatial.apply(lambda m: m.reset_parameters() if hasattr(m, 'reset_parameters') else None)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(conv2d_nn_spatial.parameters(), lr=0.001)\n",
    "num_epochs = 10 \n",
    "train_model(conv2d_nn_spatial, fashionmnist.train_loader, criterion, optimizer, num_epochs)\n",
    "evaluate_accuracy(conv2d_nn_spatial, fashionmnist.test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iv. CNN Model 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 5, 26, 26]              50\n",
      "              ReLU-2            [-1, 5, 26, 26]               0\n",
      "            Conv2d-3           [-1, 10, 24, 24]             460\n",
      "              ReLU-4           [-1, 10, 24, 24]               0\n",
      "            Conv2d-5           [-1, 20, 22, 22]           1,820\n",
      "              ReLU-6           [-1, 20, 22, 22]               0\n",
      "           Flatten-7                 [-1, 9680]               0\n",
      "            Linear-8                   [-1, 10]          96,810\n",
      "================================================================\n",
      "Total params: 99,140\n",
      "Trainable params: 99,140\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.36\n",
      "Params size (MB): 0.38\n",
      "Estimated Total Size (MB): 0.74\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "cnn = nn.Sequential(\n",
    "   nn.Conv2d(\n",
    "      in_channels=1,\n",
    "      out_channels=5,\n",
    "      kernel_size=3\n",
    "   ), \n",
    "   nn.ReLU(),\n",
    "   nn.Conv2d(\n",
    "      in_channels=5,\n",
    "      out_channels=10,\n",
    "      kernel_size=3\n",
    "   ), \n",
    "   nn.ReLU(),\n",
    "   nn.Conv2d(\n",
    "      in_channels=10,\n",
    "      out_channels=20,\n",
    "      kernel_size=3\n",
    "   ), \n",
    "   nn.ReLU(),\n",
    "   nn.Flatten(), \n",
    "   nn.Linear(9680, 10)\n",
    "   \n",
    ").to('cpu')\n",
    "   \n",
    "\n",
    "from torchsummary import summary\n",
    "summary(cnn, (1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Time: 6.554674863815308, Loss: 0.2298657124969306\n",
      "Epoch 2, Time: 6.43576192855835, Loss: 0.06720239816502586\n",
      "Epoch 3, Time: 6.427160024642944, Loss: 0.04810162721465387\n",
      "Epoch 4, Time: 6.405361890792847, Loss: 0.03746452377309828\n",
      "Epoch 5, Time: 6.481661796569824, Loss: 0.02769153001317347\n",
      "Epoch 6, Time: 6.493584156036377, Loss: 0.023612363033957515\n",
      "Epoch 7, Time: 6.5032360553741455, Loss: 0.017023767540507183\n",
      "Epoch 8, Time: 6.4567999839782715, Loss: 0.013632887368130507\n",
      "Epoch 9, Time: 6.564166069030762, Loss: 0.012427107928241832\n",
      "Epoch 10, Time: 6.488992214202881, Loss: 0.0098262744819655\n",
      "\n",
      " Average epoch time: 6.481139898300171\n",
      "Accuracy on test set: 98.45%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "98.45"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MNIST results \n",
    "cnn.to('mps')\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(cnn.parameters(), lr=0.001)\n",
    "num_epochs = 10 \n",
    "train_model(cnn, mnist.train_loader, criterion, optimizer, num_epochs)\n",
    "evaluate_accuracy(cnn, mnist.test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Time: 6.49987268447876, Loss: 0.48946688143111494\n",
      "Epoch 2, Time: 6.542877197265625, Loss: 0.3259995362159413\n",
      "Epoch 3, Time: 6.488325119018555, Loss: 0.280969231597968\n",
      "Epoch 4, Time: 6.490761995315552, Loss: 0.24997997153669532\n",
      "Epoch 5, Time: 6.495134353637695, Loss: 0.2263177202136786\n",
      "Epoch 6, Time: 6.528858184814453, Loss: 0.20458607463789646\n",
      "Epoch 7, Time: 6.498862981796265, Loss: 0.18830535723678848\n",
      "Epoch 8, Time: 6.506685972213745, Loss: 0.17291635055261761\n",
      "Epoch 9, Time: 6.50192403793335, Loss: 0.1584574477052066\n",
      "Epoch 10, Time: 6.535745859146118, Loss: 0.14568228088716453\n",
      "\n",
      " Average epoch time: 6.508904838562012\n",
      "Accuracy on test set: 90.58%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "90.58"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fashion MNIST results\n",
    "cnn.apply(lambda m: m.reset_parameters() if hasattr(m, 'reset_parameters') else None)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(cnn.parameters(), lr=0.001)\n",
    "num_epochs = 10 \n",
    "train_model(cnn, fashionmnist.train_loader, criterion, optimizer, num_epochs)\n",
    "evaluate_accuracy(cnn, fashionmnist.test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### v. CNN Model 2 (More Channels - from slides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 26, 26]             640\n",
      "         MaxPool2d-2           [-1, 64, 13, 13]               0\n",
      "              ReLU-3           [-1, 64, 13, 13]               0\n",
      "            Conv2d-4          [-1, 128, 11, 11]          73,856\n",
      "         MaxPool2d-5            [-1, 128, 5, 5]               0\n",
      "              ReLU-6            [-1, 128, 5, 5]               0\n",
      "           Flatten-7                 [-1, 3200]               0\n",
      "            Linear-8                  [-1, 200]         640,200\n",
      "              ReLU-9                  [-1, 200]               0\n",
      "           Linear-10                   [-1, 10]           2,010\n",
      "================================================================\n",
      "Total params: 716,706\n",
      "Trainable params: 716,706\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.69\n",
      "Params size (MB): 2.73\n",
      "Estimated Total Size (MB): 3.43\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "cnn2 = nn.Sequential(\n",
    "   nn.Conv2d(1, 64, 3), \n",
    "   nn.MaxPool2d(2),\n",
    "   nn.ReLU(),\n",
    "   nn.Conv2d(64, 128, 3),\n",
    "   nn.MaxPool2d(2),\n",
    "   nn.ReLU(),\n",
    "   nn.Flatten(), \n",
    "   nn.Linear(3200, 200), \n",
    "   nn.ReLU(), \n",
    "   nn.Linear(200, 10)\n",
    ").to('cpu')\n",
    "\n",
    "summary(cnn2, (1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Time: 8.406018018722534, Loss: 0.13125496588859345\n",
      "Epoch 2, Time: 8.329875946044922, Loss: 0.040012451520473606\n",
      "Epoch 3, Time: 8.514298915863037, Loss: 0.02700278012224459\n",
      "Epoch 4, Time: 7.982968807220459, Loss: 0.019342483498305252\n",
      "Epoch 5, Time: 8.369792222976685, Loss: 0.014202846011867921\n",
      "Epoch 6, Time: 8.39670991897583, Loss: 0.011261602917329583\n",
      "Epoch 7, Time: 8.391427755355835, Loss: 0.009226213445687184\n",
      "Epoch 8, Time: 8.302953958511353, Loss: 0.006774881786262847\n",
      "Epoch 9, Time: 8.440776109695435, Loss: 0.007205607422457891\n",
      "Epoch 10, Time: 8.341483116149902, Loss: 0.00581101518712793\n",
      "\n",
      " Average epoch time: 8.347630476951599\n",
      "Accuracy on test set: 99.26%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "99.26"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MNIST results \n",
    "cnn2.to('mps')\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(cnn2.parameters(), lr=0.001)\n",
    "num_epochs = 10 \n",
    "train_model(cnn2, mnist.train_loader, criterion, optimizer, num_epochs)\n",
    "evaluate_accuracy(cnn2, mnist.test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Time: 7.986433029174805, Loss: 0.45910827219803957\n",
      "Epoch 2, Time: 8.406078100204468, Loss: 0.2920994571388276\n",
      "Epoch 3, Time: 8.306495904922485, Loss: 0.24279824097845346\n",
      "Epoch 4, Time: 8.563752889633179, Loss: 0.21081925633111234\n",
      "Epoch 5, Time: 8.48746395111084, Loss: 0.1816873661498589\n",
      "Epoch 6, Time: 8.281869888305664, Loss: 0.15876234060665692\n",
      "Epoch 7, Time: 8.368393898010254, Loss: 0.13540973622542518\n",
      "Epoch 8, Time: 8.28542685508728, Loss: 0.1180425205591645\n",
      "Epoch 9, Time: 8.551209926605225, Loss: 0.09962201004486475\n",
      "Epoch 10, Time: 8.544275045394897, Loss: 0.08391685549195593\n",
      "\n",
      " Average epoch time: 8.37813994884491\n",
      "Accuracy on test set: 91.88%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "91.88"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fashion MNIST results\n",
    "cnn2.apply(lambda m: m.reset_parameters() if hasattr(m, 'reset_parameters') else None)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(cnn2.parameters(), lr=0.001)\n",
    "num_epochs = 10 \n",
    "train_model(cnn2, fashionmnist.train_loader, criterion, optimizer, num_epochs)\n",
    "evaluate_accuracy(cnn2, fashionmnist.test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. CIFAR TEST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i. Conv2d_NN all sample Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "           Flatten-1              [-1, 12, 256]               0\n",
      "            Conv1d-2              [-1, 20, 256]           1,940\n",
      "              ReLU-3              [-1, 20, 256]               0\n",
      "         Conv1d_NN-4              [-1, 20, 256]               0\n",
      "         Conv2d_NN-5            [-1, 5, 32, 32]               0\n",
      "           Flatten-6              [-1, 20, 256]               0\n",
      "            Conv1d-7              [-1, 40, 256]           6,440\n",
      "              ReLU-8              [-1, 40, 256]               0\n",
      "         Conv1d_NN-9              [-1, 40, 256]               0\n",
      "        Conv2d_NN-10           [-1, 10, 32, 32]               0\n",
      "          Flatten-11              [-1, 40, 256]               0\n",
      "           Conv1d-12              [-1, 80, 256]          25,680\n",
      "             ReLU-13              [-1, 80, 256]               0\n",
      "        Conv1d_NN-14              [-1, 80, 256]               0\n",
      "        Conv2d_NN-15           [-1, 20, 32, 32]               0\n",
      "          Flatten-16                [-1, 20480]               0\n",
      "           Linear-17                   [-1, 10]         204,810\n",
      "================================================================\n",
      "Total params: 238,870\n",
      "Trainable params: 238,870\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 1.39\n",
      "Params size (MB): 0.91\n",
      "Estimated Total Size (MB): 2.31\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Model \n",
    "conv2d_nn_all = nn.Sequential(\n",
    "   Conv2d_NN(\n",
    "      in_channels=3,\n",
    "      out_channels=5,\n",
    "      K=8,\n",
    "      stride=8,\n",
    "      padding=0,\n",
    "      shuffle_scale=2\n",
    "   ), \n",
    "   Conv2d_NN(\n",
    "      in_channels=5,\n",
    "      out_channels=10,\n",
    "      K=8,\n",
    "      stride=8,\n",
    "      padding=0,\n",
    "      shuffle_scale=2\n",
    "   ),\n",
    "   Conv2d_NN(\n",
    "      in_channels=10,\n",
    "      out_channels=20,\n",
    "      K=8,\n",
    "      stride=8,\n",
    "      padding=0,\n",
    "      shuffle_scale=2\n",
    "   ),\n",
    "   nn.Flatten(), \n",
    "   nn.Linear(20480, 10)\n",
    "   \n",
    ").to('cpu')\n",
    "   \n",
    "\n",
    "from torchsummary import summary\n",
    "summary(conv2d_nn_all, (3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Time: 44.94942808151245, Loss: 1.5116322546663796\n",
      "Epoch 2, Time: 43.84271478652954, Loss: 1.2481971537822958\n",
      "Epoch 3, Time: 44.71447801589966, Loss: 1.126823582231541\n",
      "Epoch 4, Time: 44.18211483955383, Loss: 1.024094424208107\n",
      "Epoch 5, Time: 45.80501103401184, Loss: 0.9289168209371055\n",
      "Epoch 6, Time: 44.525792837142944, Loss: 0.847721411825141\n",
      "Epoch 7, Time: 43.80231714248657, Loss: 0.7739647525884307\n",
      "Epoch 8, Time: 43.79373121261597, Loss: 0.7099080827382519\n",
      "Epoch 9, Time: 43.885058641433716, Loss: 0.6469783549151762\n",
      "Epoch 10, Time: 43.86063814163208, Loss: 0.588055506939321\n",
      "\n",
      " Average epoch time: 44.33612847328186\n",
      "Accuracy on test set: 54.06%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "54.06"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CIFAR10 results \n",
    "conv2d_nn_all.to('mps')\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(conv2d_nn_all.parameters(), lr=0.001)\n",
    "num_epochs = 10 \n",
    "train_model(conv2d_nn_all, cifar10.train_loader, criterion, optimizer, num_epochs)\n",
    "evaluate_accuracy(conv2d_nn_all, cifar10.test_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ii. Conv2d NN N (10) Sample Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "           Flatten-1              [-1, 12, 256]               0\n",
      "            Conv1d-2              [-1, 20, 256]           1,940\n",
      "              ReLU-3              [-1, 20, 256]               0\n",
      "         Conv1d_NN-4              [-1, 20, 256]               0\n",
      "         Conv2d_NN-5            [-1, 5, 32, 32]               0\n",
      "           Flatten-6              [-1, 20, 256]               0\n",
      "            Conv1d-7              [-1, 40, 256]           6,440\n",
      "              ReLU-8              [-1, 40, 256]               0\n",
      "         Conv1d_NN-9              [-1, 40, 256]               0\n",
      "        Conv2d_NN-10           [-1, 10, 32, 32]               0\n",
      "          Flatten-11              [-1, 40, 256]               0\n",
      "           Conv1d-12              [-1, 80, 256]          25,680\n",
      "             ReLU-13              [-1, 80, 256]               0\n",
      "        Conv1d_NN-14              [-1, 80, 256]               0\n",
      "        Conv2d_NN-15           [-1, 20, 32, 32]               0\n",
      "          Flatten-16                [-1, 20480]               0\n",
      "           Linear-17                   [-1, 10]         204,810\n",
      "================================================================\n",
      "Total params: 238,870\n",
      "Trainable params: 238,870\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 1.39\n",
      "Params size (MB): 0.91\n",
      "Estimated Total Size (MB): 2.31\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Model \n",
    "conv2d_nn_n = nn.Sequential(\n",
    "   Conv2d_NN(\n",
    "      in_channels=3,\n",
    "      out_channels=5,\n",
    "      K=8,\n",
    "      stride=8,\n",
    "      padding=0,\n",
    "      shuffle_scale=2, \n",
    "      samples = 10\n",
    "      \n",
    "   ), \n",
    "   Conv2d_NN(\n",
    "      in_channels=5,\n",
    "      out_channels=10,\n",
    "      K=8,\n",
    "      stride=8,\n",
    "      padding=0,\n",
    "      shuffle_scale=2, \n",
    "      samples = 10\n",
    "   ),\n",
    "   Conv2d_NN(\n",
    "      in_channels=10,\n",
    "      out_channels=20,\n",
    "      K=8,\n",
    "      stride=8,\n",
    "      padding=0,\n",
    "      shuffle_scale=2, \n",
    "      samples = 10\n",
    "   ),\n",
    "   nn.Flatten(), \n",
    "   nn.Linear(20480, 10)\n",
    "   \n",
    ").to('cpu')\n",
    "   \n",
    "\n",
    "from torchsummary import summary\n",
    "summary(conv2d_nn_n, (3, 32, 32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Time: 55.51019787788391, Loss: 1.8156808456191627\n",
      "Epoch 2, Time: 55.413949966430664, Loss: 1.568489188123542\n",
      "Epoch 3, Time: 55.28556299209595, Loss: 1.4359307264732888\n",
      "Epoch 4, Time: 55.38216590881348, Loss: 1.346325790333321\n",
      "Epoch 5, Time: 55.43906617164612, Loss: 1.257848706849091\n",
      "Epoch 6, Time: 55.52065992355347, Loss: 1.1793412768170046\n",
      "Epoch 7, Time: 55.60967206954956, Loss: 1.1047723770446485\n",
      "Epoch 8, Time: 55.62544894218445, Loss: 1.0443759583451253\n",
      "Epoch 9, Time: 55.6436550617218, Loss: 1.0010980764770752\n",
      "Epoch 10, Time: 55.66088604927063, Loss: 0.9578575901210765\n",
      "\n",
      " Average epoch time: 55.509126496315005\n",
      "Accuracy on test set: 57.15%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "57.15"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CIFAR10 results \n",
    "conv2d_nn_n.to('mps')\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(conv2d_nn_n.parameters(), lr=0.001)\n",
    "num_epochs = 10 \n",
    "train_model(conv2d_nn_n, cifar10.train_loader, criterion, optimizer, num_epochs)\n",
    "evaluate_accuracy(conv2d_nn_n, cifar10.test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iii. Conv2d NN Spatial samples Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "           Flatten-1              [-1, 3, 1024]               0\n",
      "            Conv1d-2              [-1, 5, 1024]             125\n",
      "              ReLU-3              [-1, 5, 1024]               0\n",
      " Conv1d_NN_spatial-4              [-1, 5, 1024]               0\n",
      " Conv2d_NN_spatial-5            [-1, 5, 32, 32]               0\n",
      "           Flatten-6              [-1, 5, 1024]               0\n",
      "            Conv1d-7             [-1, 10, 1024]             410\n",
      "              ReLU-8             [-1, 10, 1024]               0\n",
      " Conv1d_NN_spatial-9             [-1, 10, 1024]               0\n",
      "Conv2d_NN_spatial-10           [-1, 10, 32, 32]               0\n",
      "          Flatten-11             [-1, 10, 1024]               0\n",
      "           Conv1d-12             [-1, 20, 1024]           1,620\n",
      "             ReLU-13             [-1, 20, 1024]               0\n",
      "Conv1d_NN_spatial-14             [-1, 20, 1024]               0\n",
      "Conv2d_NN_spatial-15           [-1, 20, 32, 32]               0\n",
      "          Flatten-16                [-1, 20480]               0\n",
      "           Linear-17                   [-1, 10]         204,810\n",
      "================================================================\n",
      "Total params: 206,965\n",
      "Trainable params: 206,965\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 1.39\n",
      "Params size (MB): 0.79\n",
      "Estimated Total Size (MB): 2.19\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Model \n",
    "conv2d_nn_spatial = nn.Sequential(\n",
    "   Conv2d_NN_spatial(\n",
    "      in_channels=3,\n",
    "      out_channels=5,\n",
    "      K=8,\n",
    "      stride=8,\n",
    "      padding=0,\n",
    "      shuffle_scale=2, \n",
    "      samples=3\n",
    "      \n",
    "   ), \n",
    "   Conv2d_NN_spatial(\n",
    "      in_channels=5,\n",
    "      out_channels=10,\n",
    "      K=8,\n",
    "      stride=8,\n",
    "      padding=0,\n",
    "      shuffle_scale=2, \n",
    "      samples=3\n",
    "   ),\n",
    "   Conv2d_NN_spatial(\n",
    "      in_channels=10,\n",
    "      out_channels=20,\n",
    "      K=8,\n",
    "      stride=8,\n",
    "      padding=0,\n",
    "      shuffle_scale=2, \n",
    "      samples=3\n",
    "   ),\n",
    "   nn.Flatten(), \n",
    "   nn.Linear(20480, 10)\n",
    "   \n",
    ").to('cpu')\n",
    "   \n",
    "\n",
    "from torchsummary import summary\n",
    "summary(conv2d_nn_spatial, (3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Time: 108.96385383605957, Loss: 2.1575859288120514\n",
      "Epoch 2, Time: 107.93930196762085, Loss: 2.122828946698962\n",
      "Epoch 3, Time: 107.96826004981995, Loss: 2.1113657471164107\n",
      "Epoch 4, Time: 107.9063630104065, Loss: 2.1127377908553004\n",
      "Epoch 5, Time: 107.7992000579834, Loss: 2.110430291699022\n",
      "Epoch 6, Time: 107.88676905632019, Loss: 2.112298115135154\n",
      "Epoch 7, Time: 107.80075192451477, Loss: 2.113089960859255\n",
      "Epoch 8, Time: 107.82844018936157, Loss: 2.111495120293649\n",
      "Epoch 9, Time: 107.8477737903595, Loss: 2.110899940780971\n",
      "Epoch 10, Time: 107.81518197059631, Loss: 2.1091887732905805\n",
      "\n",
      " Average epoch time: 107.97558958530426\n",
      "Accuracy on test set: 20.93%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20.93"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CIFAR10 results \n",
    "conv2d_nn_spatial.to('mps')\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(conv2d_nn_spatial.parameters(), lr=0.001)\n",
    "num_epochs = 10 \n",
    "train_model(conv2d_nn_spatial, cifar10.train_loader, criterion, optimizer, num_epochs)\n",
    "evaluate_accuracy(conv2d_nn_spatial, cifar10.test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iv. CNN Model 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 5, 30, 30]             140\n",
      "              ReLU-2            [-1, 5, 30, 30]               0\n",
      "            Conv2d-3           [-1, 10, 28, 28]             460\n",
      "              ReLU-4           [-1, 10, 28, 28]               0\n",
      "            Conv2d-5           [-1, 20, 26, 26]           1,820\n",
      "              ReLU-6           [-1, 20, 26, 26]               0\n",
      "           Flatten-7                [-1, 13520]               0\n",
      "            Linear-8                   [-1, 10]         135,210\n",
      "================================================================\n",
      "Total params: 137,630\n",
      "Trainable params: 137,630\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.50\n",
      "Params size (MB): 0.53\n",
      "Estimated Total Size (MB): 1.03\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "cnn = nn.Sequential(\n",
    "   nn.Conv2d(\n",
    "      in_channels=3,\n",
    "      out_channels=5,\n",
    "      kernel_size=3\n",
    "   ), \n",
    "   nn.ReLU(),\n",
    "   nn.Conv2d(\n",
    "      in_channels=5,\n",
    "      out_channels=10,\n",
    "      kernel_size=3\n",
    "   ), \n",
    "   nn.ReLU(),\n",
    "   nn.Conv2d(\n",
    "      in_channels=10,\n",
    "      out_channels=20,\n",
    "      kernel_size=3\n",
    "   ), \n",
    "   nn.ReLU(),\n",
    "   nn.Flatten(), \n",
    "   nn.Linear(13520, 10)\n",
    "   \n",
    ").to('cpu')\n",
    "   \n",
    "\n",
    "from torchsummary import summary\n",
    "summary(cnn, (3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Time: 7.893411159515381, Loss: 1.488595805814504\n",
      "Epoch 2, Time: 7.603149175643921, Loss: 1.1620328722097684\n",
      "Epoch 3, Time: 7.510899066925049, Loss: 1.0224151668493704\n",
      "Epoch 4, Time: 7.623315095901489, Loss: 0.9204385534424306\n",
      "Epoch 5, Time: 7.522058010101318, Loss: 0.8376246039824717\n",
      "Epoch 6, Time: 7.600987911224365, Loss: 0.7652542689038665\n",
      "Epoch 7, Time: 7.4972100257873535, Loss: 0.6914785497481256\n",
      "Epoch 8, Time: 7.633450984954834, Loss: 0.6211631467275303\n",
      "Epoch 9, Time: 7.808513879776001, Loss: 0.5632011526838288\n",
      "Epoch 10, Time: 7.382105827331543, Loss: 0.49721130631540134\n",
      "\n",
      " Average epoch time: 7.607510113716126\n",
      "Accuracy on test set: 59.35%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "59.35"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CIFAR10 results \n",
    "cnn.to('mps')\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(cnn.parameters(), lr=0.001)\n",
    "num_epochs = 10 \n",
    "train_model(cnn, cifar10.train_loader, criterion, optimizer, num_epochs)\n",
    "evaluate_accuracy(cnn, cifar10.test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### v. CNN Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 30, 30]           1,792\n",
      "         MaxPool2d-2           [-1, 64, 15, 15]               0\n",
      "              ReLU-3           [-1, 64, 15, 15]               0\n",
      "            Conv2d-4          [-1, 128, 13, 13]          73,856\n",
      "         MaxPool2d-5            [-1, 128, 6, 6]               0\n",
      "              ReLU-6            [-1, 128, 6, 6]               0\n",
      "           Flatten-7                 [-1, 4608]               0\n",
      "            Linear-8                  [-1, 200]         921,800\n",
      "              ReLU-9                  [-1, 200]               0\n",
      "           Linear-10                   [-1, 10]           2,010\n",
      "================================================================\n",
      "Total params: 999,458\n",
      "Trainable params: 999,458\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.93\n",
      "Params size (MB): 3.81\n",
      "Estimated Total Size (MB): 4.76\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "cnn2 = nn.Sequential(\n",
    "   nn.Conv2d(3, 64, 3), \n",
    "   nn.MaxPool2d(2),\n",
    "   nn.ReLU(),\n",
    "   nn.Conv2d(64, 128, 3),\n",
    "   nn.MaxPool2d(2),\n",
    "   nn.ReLU(),\n",
    "   nn.Flatten(), \n",
    "   nn.Linear(4608, 200), \n",
    "   nn.ReLU(), \n",
    "   nn.Linear(200, 10)\n",
    ").to('cpu')\n",
    "\n",
    "summary(cnn2, (3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Time: 9.252714157104492, Loss: 1.2492953814813852\n",
      "Epoch 2, Time: 9.178469896316528, Loss: 0.871120593774959\n",
      "Epoch 3, Time: 9.245590686798096, Loss: 0.6975760346712054\n",
      "Epoch 4, Time: 11.987773895263672, Loss: 0.567608935296383\n",
      "Epoch 5, Time: 12.873844861984253, Loss: 0.43401709511456893\n",
      "Epoch 6, Time: 12.868252038955688, Loss: 0.3262893112990862\n",
      "Epoch 7, Time: 13.034137725830078, Loss: 0.23908620621637464\n",
      "Epoch 8, Time: 12.75081491470337, Loss: 0.17379018553363546\n",
      "Epoch 9, Time: 12.755888938903809, Loss: 0.1341477809902614\n",
      "Epoch 10, Time: 13.506570816040039, Loss: 0.1152960468414704\n",
      "\n",
      " Average epoch time: 11.745405793190002\n",
      "Accuracy on test set: 71.4%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "71.4"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CIFAR10 results \n",
    "cnn2.to('mps')\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(cnn2.parameters(), lr=0.001)\n",
    "num_epochs = 10 \n",
    "train_model(cnn2, cifar10.train_loader, criterion, optimizer, num_epochs)\n",
    "evaluate_accuracy(cnn2, cifar10.test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MK",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
