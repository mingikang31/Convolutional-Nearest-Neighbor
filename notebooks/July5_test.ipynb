{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conv2d + Conv1d Modified tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 32, 40])\n"
     ]
    }
   ],
   "source": [
    "import sys \n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from torchsummary import summary\n",
    "\n",
    "# from Conv1d_NN import Conv1d_NN\n",
    "from Conv2d_NN import Conv2d_NN\n",
    "\n",
    "from models import * \n",
    "from train import * \n",
    "from dataset import * \n",
    "from pixelshuffle import * \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Conv2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28]) torch.Size([60000])\n"
     ]
    }
   ],
   "source": [
    "# Data \n",
    "# Import necessary libraries\n",
    "from torchvision import datasets\n",
    "data_folder = '~/data/MNIST'\n",
    "mnist_train = datasets.MNIST(data_folder, download=True, train=True)\n",
    "x_train, y_train = mnist_train.data, mnist_train.targets\n",
    "print(x_train.shape, y_train.shape)\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "class MNISTDataset(Dataset):\n",
    "   def __init__(self, x, y):\n",
    "      x = x.float()/255 # Data rescaling\n",
    "      self.x, self.y = x, y\n",
    "   def __len__(self):\n",
    "      return len(self.x)\n",
    "   def __getitem__(self, ix):\n",
    "      x, y = self.x[ix], self.y[ix]\n",
    "      return x.to('cpu'), y.to('cpu')\n",
    "\n",
    "train_dataset = MNISTDataset(x_train, y_train)\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "train_dl = DataLoader(train_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "           Flatten-1               [-1, 4, 196]               0\n",
      "            Conv1d-2              [-1, 20, 196]             260\n",
      "              ReLU-3              [-1, 20, 196]               0\n",
      "         Conv1d_NN-4              [-1, 20, 196]               0\n",
      "         Conv2d_NN-5            [-1, 5, 28, 28]               0\n",
      "              ReLU-6            [-1, 5, 28, 28]               0\n",
      "           Flatten-7              [-1, 20, 196]               0\n",
      "            Conv1d-8              [-1, 40, 196]           2,440\n",
      "              ReLU-9              [-1, 40, 196]               0\n",
      "        Conv1d_NN-10              [-1, 40, 196]               0\n",
      "        Conv2d_NN-11           [-1, 10, 28, 28]               0\n",
      "             ReLU-12           [-1, 10, 28, 28]               0\n",
      "          Flatten-13              [-1, 40, 196]               0\n",
      "           Conv1d-14              [-1, 80, 196]           9,680\n",
      "             ReLU-15              [-1, 80, 196]               0\n",
      "        Conv1d_NN-16              [-1, 80, 196]               0\n",
      "        Conv2d_NN-17           [-1, 20, 28, 28]               0\n",
      "          Flatten-18                [-1, 15680]               0\n",
      "           Linear-19                   [-1, 10]         156,810\n",
      "================================================================\n",
      "Total params: 169,190\n",
      "Trainable params: 169,190\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 1.14\n",
      "Params size (MB): 0.65\n",
      "Estimated Total Size (MB): 1.79\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Model \n",
    "conv2d_nn = nn.Sequential(\n",
    "   Conv2d_NN(\n",
    "      in_channels=1,\n",
    "      out_channels=5,\n",
    "      K=3,\n",
    "      stride=3,\n",
    "      padding=0,\n",
    "      shuffle_scale=2\n",
    "   ), \n",
    "   nn.ReLU(),\n",
    "   Conv2d_NN(\n",
    "      in_channels=5,\n",
    "      out_channels=10,\n",
    "      K=3,\n",
    "      stride=3,\n",
    "      padding=0,\n",
    "      shuffle_scale=2\n",
    "   ),\n",
    "   nn.ReLU(),\n",
    "   Conv2d_NN(\n",
    "      in_channels=10,\n",
    "      out_channels=20,\n",
    "      K=3,\n",
    "      stride=3,\n",
    "      padding=0,\n",
    "      shuffle_scale=2\n",
    "   ),\n",
    "   nn.Flatten(), \n",
    "   nn.Linear(15680, 10)\n",
    "   \n",
    ").to('cpu')\n",
    "   \n",
    "\n",
    "from torchsummary import summary\n",
    "summary(conv2d_nn, (1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.31437504275648326\n",
      "Epoch 2, Loss: 0.16612954330898677\n",
      "Epoch 3, Loss: 0.12960919333613916\n",
      "Epoch 4, Loss: 0.10548594566846468\n",
      "Epoch 5, Loss: 0.0941099752860664\n",
      "Epoch 6, Loss: 0.07940264251457949\n",
      "Epoch 7, Loss: 0.06897804607798073\n",
      "Epoch 8, Loss: 0.06303184081652342\n",
      "Epoch 9, Loss: 0.05436393609473994\n",
      "Epoch 10, Loss: 0.04747006030659428\n",
      "Accuracy on test set: 95.87%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "95.87"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Assuming Conv2d_NN is defined elsewhere in your code\n",
    "# Define your model here as per the provided structure\n",
    "\n",
    "# Load and preprocess data\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Training function\n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "        print(f'Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}')\n",
    "\n",
    "# Accuracy evaluation function\n",
    "def evaluate_accuracy(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Accuracy on test set: {accuracy}%')\n",
    "    return accuracy\n",
    "\n",
    "# Initialize model, loss, and optimizer\n",
    "model = conv2d_nn\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "# Train the model\n",
    "train_model(model, train_loader, criterion, optimizer, num_epochs=10)\n",
    "\n",
    "# Evaluate accuracy\n",
    "evaluate_accuracy(model, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 5, 26, 26]              50\n",
      "              ReLU-2            [-1, 5, 26, 26]               0\n",
      "            Conv2d-3           [-1, 10, 24, 24]             460\n",
      "              ReLU-4           [-1, 10, 24, 24]               0\n",
      "            Conv2d-5           [-1, 20, 22, 22]           1,820\n",
      "              ReLU-6           [-1, 20, 22, 22]               0\n",
      "           Flatten-7                 [-1, 9680]               0\n",
      "            Linear-8                   [-1, 10]          96,810\n",
      "================================================================\n",
      "Total params: 99,140\n",
      "Trainable params: 99,140\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.36\n",
      "Params size (MB): 0.38\n",
      "Estimated Total Size (MB): 0.74\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "## Do a sample regular CNN \n",
    "\n",
    "cnn = nn.Sequential(\n",
    "   nn.Conv2d(\n",
    "      in_channels=1,\n",
    "      out_channels=5,\n",
    "      kernel_size=3\n",
    "   ), \n",
    "   nn.ReLU(),\n",
    "   nn.Conv2d(\n",
    "      in_channels=5,\n",
    "      out_channels=10,\n",
    "      kernel_size=3\n",
    "   ), \n",
    "   nn.ReLU(),\n",
    "   nn.Conv2d(\n",
    "      in_channels=10,\n",
    "      out_channels=20,\n",
    "      kernel_size=3\n",
    "   ), \n",
    "   nn.ReLU(),\n",
    "   nn.Flatten(), \n",
    "   nn.Linear(9680, 10)\n",
    "   \n",
    ").to('cpu')\n",
    "   \n",
    "\n",
    "from torchsummary import summary\n",
    "summary(cnn, (1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.305797335181409\n",
      "Epoch 2, Loss: 2.305781441965083\n",
      "Epoch 3, Loss: 2.3057882788338895\n",
      "Epoch 4, Loss: 2.305787814451433\n",
      "Epoch 5, Loss: 2.3057871871411417\n",
      "Epoch 6, Loss: 2.3057813685077595\n",
      "Epoch 7, Loss: 2.305788746774832\n",
      "Epoch 8, Loss: 2.30578144018584\n",
      "Epoch 9, Loss: 2.3057826767598133\n",
      "Epoch 10, Loss: 2.305790897879773\n",
      "Accuracy on test set: 8.51%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8.51"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "train_model(cnn, train_loader, criterion, optimizer, num_epochs=10)\n",
    "\n",
    "# Evaluate accuracy\n",
    "evaluate_accuracy(cnn, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 26, 26]             640\n",
      "         MaxPool2d-2           [-1, 64, 13, 13]               0\n",
      "              ReLU-3           [-1, 64, 13, 13]               0\n",
      "            Conv2d-4          [-1, 128, 11, 11]          73,856\n",
      "         MaxPool2d-5            [-1, 128, 5, 5]               0\n",
      "              ReLU-6            [-1, 128, 5, 5]               0\n",
      "           Flatten-7                 [-1, 3200]               0\n",
      "            Linear-8                  [-1, 200]         640,200\n",
      "              ReLU-9                  [-1, 200]               0\n",
      "           Linear-10                   [-1, 10]           2,010\n",
      "================================================================\n",
      "Total params: 716,706\n",
      "Trainable params: 716,706\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.69\n",
      "Params size (MB): 2.73\n",
      "Estimated Total Size (MB): 3.43\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "cnn2 = nn.Sequential(\n",
    "   nn.Conv2d(1, 64, 3), \n",
    "   nn.MaxPool2d(2),\n",
    "   nn.ReLU(),\n",
    "   nn.Conv2d(64, 128, 3),\n",
    "   nn.MaxPool2d(2),\n",
    "   nn.ReLU(),\n",
    "   nn.Flatten(), \n",
    "   nn.Linear(3200, 200), \n",
    "   nn.ReLU(), \n",
    "   nn.Linear(200, 10)\n",
    ").to('cpu')\n",
    "\n",
    "summary(cnn2, (1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.3038571015604017\n",
      "Epoch 2, Loss: 2.3038535082518163\n",
      "Epoch 3, Loss: 2.303859902851617\n",
      "Epoch 4, Loss: 2.3038589189301675\n",
      "Epoch 5, Loss: 2.3038686541860294\n",
      "Epoch 6, Loss: 2.303862106825497\n",
      "Epoch 7, Loss: 2.3038635040397075\n",
      "Epoch 8, Loss: 2.3038639770642018\n",
      "Epoch 9, Loss: 2.30386119432795\n",
      "Epoch 10, Loss: 2.3038573717511794\n",
      "Accuracy on test set: 6.79%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6.79"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "train_model(cnn2, train_loader, criterion, optimizer, num_epochs=10)\n",
    "\n",
    "# Evaluate accuracy\n",
    "evaluate_accuracy(cnn2, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MK",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
