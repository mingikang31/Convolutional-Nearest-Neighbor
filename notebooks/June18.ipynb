{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# June 18 Neural Network Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torch \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# MNIST1D \n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "from scipy.ndimage import gaussian_filter\n",
    "from scipy.interpolate import interp1d \n",
    "from mnist1d.data import make_dataset, get_dataset_args\n",
    "\n",
    "# Custom Modules \n",
    "import sys \n",
    "sys.path.append('../')\n",
    "from NNT import NNT\n",
    "from Conv1d_NN import Conv1d_NN\n",
    "\n",
    "from models import * \n",
    "from train import *\n",
    "\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1               [-1, 25, 40]             100\n",
      "         Conv1d_NN-2               [-1, 25, 40]               0\n",
      "              ReLU-3               [-1, 25, 40]               0\n",
      "            Conv1d-4               [-1, 25, 40]           1,900\n",
      "         Conv1d_NN-5               [-1, 25, 40]               0\n",
      "              ReLU-6               [-1, 25, 40]               0\n",
      "            Conv1d-7               [-1, 25, 40]           1,900\n",
      "         Conv1d_NN-8               [-1, 25, 40]               0\n",
      "              ReLU-9               [-1, 25, 40]               0\n",
      "          Flatten-10                 [-1, 1000]               0\n",
      "           Linear-11                   [-1, 10]          10,010\n",
      "================================================================\n",
      "Total params: 13,910\n",
      "Trainable params: 13,910\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.08\n",
      "Params size (MB): 0.05\n",
      "Estimated Total Size (MB): 0.13\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Conv1d_NN\n",
    "model = nn.Sequential(\n",
    "    Conv1d_NN(in_channels=1, out_channels =25, K = 3),  # Change the number of input channels to 1\n",
    "    nn.ReLU(), \n",
    "    Conv1d_NN(in_channels=25, out_channels=25, K = 3),\n",
    "    nn.ReLU(),\n",
    "    Conv1d_NN(in_channels=25, out_channels=25, K = 3),\n",
    "    nn.ReLU(),\n",
    "    nn.Flatten(), \n",
    "    nn.Linear(1000, 10)\n",
    ")\n",
    "\n",
    "# Get summary \n",
    "from torchsummary import summary\n",
    "summary(model, (1, 40), device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Module.parameters at 0x33833b920>\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1               [-1, 25, 19]             150\n",
      "              ReLU-2               [-1, 25, 19]               0\n",
      "            Conv1d-3               [-1, 25, 10]           1,900\n",
      "              ReLU-4               [-1, 25, 10]               0\n",
      "            Conv1d-5                [-1, 25, 5]           1,900\n",
      "              ReLU-6                [-1, 25, 5]               0\n",
      "           Flatten-7                  [-1, 125]               0\n",
      "            Linear-8                   [-1, 10]           1,260\n",
      "================================================================\n",
      "Total params: 5,210\n",
      "Trainable params: 5,210\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.01\n",
      "Params size (MB): 0.02\n",
      "Estimated Total Size (MB): 0.03\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Sequential version of MNIST model \n",
    "model1 = nn.Sequential(\n",
    "   nn.Conv1d(1, 25, 5, 2, 1), \n",
    "   nn.ReLU(),\n",
    "   nn.Conv1d(25, 25, 3, 2, 1),\n",
    "   nn.ReLU(),\n",
    "   nn.Conv1d(25, 25, 3, 2, 1),\n",
    "   nn.ReLU(),\n",
    "   nn.Flatten(),\n",
    "   nn.Linear(125, 10)\n",
    ")\n",
    "print(model1.parameters())\n",
    "# Get summary \n",
    "from torchsummary import summary\n",
    "summary(model1, (1, 40))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized ConvBase model with 5210 parameters\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1               [-1, 25, 19]             150\n",
      "            Conv1d-2               [-1, 25, 10]           1,900\n",
      "            Conv1d-3                [-1, 25, 5]           1,900\n",
      "           Flatten-4                  [-1, 125]               0\n",
      "            Linear-5                   [-1, 10]           1,260\n",
      "================================================================\n",
      "Total params: 5,210\n",
      "Trainable params: 5,210\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.01\n",
      "Params size (MB): 0.02\n",
      "Estimated Total Size (MB): 0.03\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# NN.Module version of MNIST model\n",
    "model2 = ConvBase_v2(10)\n",
    "\n",
    "summary(model2, (1, 40), device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized ConvBase model with 5210 parameters\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1               [-1, 25, 19]             150\n",
      "            Conv1d-2               [-1, 25, 10]           1,900\n",
      "            Conv1d-3                [-1, 25, 5]           1,900\n",
      "           Flatten-4                  [-1, 125]               0\n",
      "            Linear-5                   [-1, 10]           1,260\n",
      "================================================================\n",
      "Total params: 5,210\n",
      "Trainable params: 5,210\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.01\n",
      "Params size (MB): 0.02\n",
      "Estimated Total Size (MB): 0.03\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Model from MNIST1D repository \n",
    "model3 = ConvBase(10)\n",
    "\n",
    "# Get summary\n",
    "from torchsummary import summary\n",
    "summary(model2, (1, 40), device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gather data MNIST1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4000, 1, 40]) (4000,) (40,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from mnist1d.data import make_dataset, get_dataset_args\n",
    "\n",
    "args = get_dataset_args(as_dict=False)\n",
    "\n",
    "\n",
    "set_seed(args.seed)\n",
    "args.shuffle_seq = False\n",
    "data = make_dataset(args = args) # Make the dataset \n",
    "data['x'] = torch.Tensor(data['x']).unsqueeze(1)\n",
    "data['x_test'] = torch.Tensor(data['x_test']).unsqueeze(1)\n",
    "\n",
    "print(data['x'].shape, data['y'].shape, data['t'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom Conv1d_NN\n",
      "step 1000, dt 18.10s, train_loss 8.415e-01, test_loss 1.386e+00, train_acc 66.3, test_acc 49.8\n",
      "step 2000, dt 17.93s, train_loss 6.837e-01, test_loss 1.592e+00, train_acc 70.5, test_acc 47.0\n",
      "step 3000, dt 18.16s, train_loss 7.353e-01, test_loss 1.764e+00, train_acc 71.3, test_acc 46.8\n",
      "step 4000, dt 18.50s, train_loss 5.915e-01, test_loss 1.924e+00, train_acc 72.8, test_acc 46.5\n",
      "step 5000, dt 18.22s, train_loss 6.823e-01, test_loss 2.022e+00, train_acc 72.1, test_acc 44.5\n",
      "step 6000, dt 18.54s, train_loss 6.318e-01, test_loss 2.227e+00, train_acc 75.5, test_acc 44.0\n",
      "\n",
      "Sequential MNIST Model\n",
      "step 1000, dt 3.06s, train_loss 9.888e-02, test_loss 4.618e-01, train_acc 95.6, test_acc 88.3\n",
      "step 2000, dt 3.02s, train_loss 1.470e-02, test_loss 5.179e-01, train_acc 99.0, test_acc 90.0\n",
      "step 3000, dt 3.14s, train_loss 1.894e-03, test_loss 5.507e-01, train_acc 99.9, test_acc 91.5\n",
      "step 4000, dt 2.90s, train_loss 5.249e-05, test_loss 6.365e-01, train_acc 100.0, test_acc 91.9\n",
      "step 5000, dt 2.87s, train_loss 2.748e-05, test_loss 6.603e-01, train_acc 100.0, test_acc 92.1\n",
      "step 6000, dt 3.00s, train_loss 1.812e-05, test_loss 6.794e-01, train_acc 100.0, test_acc 92.0\n",
      "\n",
      "NN.Module MNIST Model\n",
      "step 1000, dt 3.02s, train_loss 1.288e-01, test_loss 5.332e-01, train_acc 93.9, test_acc 87.8\n",
      "step 2000, dt 2.92s, train_loss 4.081e-02, test_loss 4.687e-01, train_acc 99.3, test_acc 90.3\n",
      "step 3000, dt 2.96s, train_loss 1.867e-02, test_loss 4.756e-01, train_acc 98.9, test_acc 92.6\n",
      "step 4000, dt 2.85s, train_loss 3.355e-03, test_loss 6.369e-01, train_acc 97.4, test_acc 89.1\n",
      "step 5000, dt 2.82s, train_loss 1.658e-04, test_loss 6.411e-01, train_acc 99.6, test_acc 92.1\n",
      "step 6000, dt 2.88s, train_loss 7.536e-05, test_loss 6.445e-01, train_acc 100.0, test_acc 92.6\n",
      "\n",
      "MNIST1D Model\n",
      "step 1000, dt 2.87s, train_loss 5.025e-02, test_loss 4.180e-01, train_acc 97.0, test_acc 88.9\n",
      "step 2000, dt 2.87s, train_loss 5.092e-03, test_loss 3.974e-01, train_acc 99.5, test_acc 91.9\n",
      "step 3000, dt 2.99s, train_loss 2.469e-02, test_loss 5.403e-01, train_acc 98.9, test_acc 91.5\n",
      "step 4000, dt 2.89s, train_loss 6.097e-05, test_loss 4.927e-01, train_acc 100.0, test_acc 92.1\n",
      "step 5000, dt 2.92s, train_loss 3.353e-05, test_loss 5.063e-01, train_acc 100.0, test_acc 91.9\n",
      "step 6000, dt 2.90s, train_loss 2.080e-05, test_loss 5.174e-01, train_acc 100.0, test_acc 92.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "args = get_model_args()\n",
    "args.device = 'mps'\n",
    "args.total_steps = 6000\n",
    "\n",
    "set_seed(args.seed)\n",
    "\n",
    "print(\"Custom Conv1d_NN\")\n",
    "results =train_model(data, model, args)\n",
    "print()\n",
    "\n",
    "print(\"Sequential MNIST Model\")\n",
    "results1 = train_model(data, model1, args)\n",
    "print() \n",
    "\n",
    "print(\"NN.Module MNIST Model\")\n",
    "results2 = train_model(data, model2, args)\n",
    "print()\n",
    "\n",
    "print(\"MNIST1D Model\")\n",
    "results3 = train_model(data, model3, args)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try with less noise data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.0\n",
      "torch.Size([4000, 1, 40]) (4000,) (40,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from mnist1d.data import make_dataset, get_dataset_args\n",
    "\n",
    "less_noise_args = get_dataset_args(as_dict=False)\n",
    "# {'num_samples': 5000, 'train_split': 0.8, 'template_len': 12, \n",
    "# 'padding': [36, 60], 'scale_coeff': 0.4, 'max_translation': 48, \n",
    "# 'corr_noise_scale': 0.25, 'iid_noise_scale': 0.02, 'shear_scale': 0.75, \n",
    "# 'shuffle_seq': False, 'final_seq_length': 40, 'seed': 42, \n",
    "# 'url': 'https://github.com/greydanus/mnist1d/raw/master/mnist1d_data.pkl'}\n",
    "\n",
    "set_seed(less_noise_args.seed)\n",
    "less_noise_args.shuffle_seq = False\n",
    "less_noise_args.corr_noise_scale = 0.00\n",
    "less_noise_args.iid_noise_scale = 0.000\n",
    "\n",
    "\n",
    "\n",
    "less_noise_data = make_dataset(args = less_noise_args) # Make the dataset \n",
    "less_noise_data['x'] = torch.Tensor(less_noise_data['x']).unsqueeze(1)\n",
    "less_noise_data['x_test'] = torch.Tensor(less_noise_data['x_test']).unsqueeze(1)\n",
    "\n",
    "print(less_noise_args.corr_noise_scale, less_noise_args.iid_noise_scale)\n",
    "print(less_noise_data['x'].shape, less_noise_data['y'].shape, less_noise_data['t'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom Conv1d_NN\n",
      "step 1000, dt 19.09s, train_loss 1.524e-01, test_loss 9.383e-01, train_acc 93.7, test_acc 78.8\n",
      "step 2000, dt 17.91s, train_loss 2.067e-01, test_loss 1.003e+00, train_acc 93.7, test_acc 78.8\n",
      "step 3000, dt 16.00s, train_loss 1.329e-01, test_loss 9.897e-01, train_acc 93.8, test_acc 78.1\n",
      "step 4000, dt 14.84s, train_loss 3.595e-01, test_loss 1.260e+00, train_acc 89.7, test_acc 75.8\n",
      "step 5000, dt 14.80s, train_loss 1.304e-01, test_loss 1.101e+00, train_acc 94.7, test_acc 77.9\n",
      "step 6000, dt 14.67s, train_loss 1.431e-01, test_loss 1.130e+00, train_acc 92.5, test_acc 75.4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "less_noise_model = get_model_args(as_dict=False)\n",
    "less_noise_model.device = 'mps'\n",
    "less_noise_model.total_steps = 6000\n",
    "\n",
    "print(\"Custom Conv1d_NN\")\n",
    "results =train_model(less_noise_data, model, less_noise_model)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try with more neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST1D Model\n",
      "step 1000, dt 10.11s, train_loss 4.812e-01, test_loss 7.754e-01, train_acc 79.9, test_acc 70.1\n",
      "step 2000, dt 10.08s, train_loss 5.505e-01, test_loss 7.263e-01, train_acc 82.7, test_acc 70.8\n",
      "step 3000, dt 10.05s, train_loss 4.057e-01, test_loss 6.673e-01, train_acc 85.5, test_acc 74.8\n",
      "step 4000, dt 9.92s, train_loss 4.472e-01, test_loss 7.298e-01, train_acc 83.9, test_acc 74.7\n",
      "step 5000, dt 9.87s, train_loss 2.862e-01, test_loss 7.652e-01, train_acc 85.0, test_acc 73.2\n",
      "step 6000, dt 9.94s, train_loss 2.822e-01, test_loss 7.194e-01, train_acc 87.4, test_acc 75.7\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1 Nearest Neighbour \n",
    "LN_1_NN_model = nn.Sequential(\n",
    "    Conv1d_NN(in_channels=1, out_channels = 25, K = 1, stride=1),  # Change the number of input channels to 1\n",
    "    nn.ReLU(), \n",
    "    Conv1d_NN(in_channels=25, out_channels=25, K = 1, stride=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Flatten(), \n",
    "    nn.Linear(1000, 10)\n",
    ").to('mps')\n",
    "\n",
    "# Get summary \n",
    "# from torchsummary import summary\n",
    "# summary(model, (1, 40), device=device)\n",
    "\n",
    "print(\"MNIST1D Model\")\n",
    "LN_1_NN_results = train_model(less_noise_data, LN_1_NN_model, less_noise_model)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST1D Model\n",
      "step 1000, dt 10.79s, train_loss 4.427e-01, test_loss 7.210e-01, train_acc 79.7, test_acc 72.1\n",
      "step 2000, dt 10.30s, train_loss 3.461e-01, test_loss 6.056e-01, train_acc 87.7, test_acc 76.2\n",
      "step 3000, dt 12.37s, train_loss 3.298e-01, test_loss 7.743e-01, train_acc 86.5, test_acc 75.4\n",
      "step 4000, dt 12.03s, train_loss 2.559e-01, test_loss 7.977e-01, train_acc 87.4, test_acc 75.3\n",
      "step 5000, dt 11.71s, train_loss 2.611e-01, test_loss 1.015e+00, train_acc 87.2, test_acc 73.8\n",
      "step 6000, dt 11.69s, train_loss 1.979e-01, test_loss 8.741e-01, train_acc 88.5, test_acc 77.2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2 Nearby Neighbors\n",
    "LN_2_NN_model = nn.Sequential(\n",
    "    Conv1d_NN(in_channels=1, out_channels = 25, K = 2, stride=2),  # Change the number of input channels to 1\n",
    "    nn.ReLU(), \n",
    "    Conv1d_NN(in_channels=25, out_channels=25, K = 2, stride=2),\n",
    "    nn.ReLU(),\n",
    "    nn.Flatten(), \n",
    "    nn.Linear(1000, 10)\n",
    ").to('mps')\n",
    "\n",
    "# Get summary \n",
    "# from torchsummary import summary\n",
    "# summary(model, (1, 40), device=device)\n",
    "\n",
    "print(\"MNIST1D Model\")\n",
    "LN_2_NN_results = train_model(less_noise_data, LN_2_NN_model, less_noise_model)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST1D Model\n",
      "step 1000, dt 12.18s, train_loss 4.683e-01, test_loss 7.493e-01, train_acc 83.3, test_acc 71.8\n",
      "step 2000, dt 11.87s, train_loss 4.484e-01, test_loss 7.710e-01, train_acc 89.6, test_acc 76.8\n",
      "step 3000, dt 11.88s, train_loss 2.257e-01, test_loss 8.600e-01, train_acc 89.1, test_acc 75.6\n",
      "step 4000, dt 11.62s, train_loss 1.723e-01, test_loss 1.102e+00, train_acc 89.8, test_acc 74.7\n",
      "step 5000, dt 11.28s, train_loss 2.229e-01, test_loss 1.097e+00, train_acc 92.9, test_acc 73.7\n",
      "step 6000, dt 11.83s, train_loss 4.147e-01, test_loss 1.155e+00, train_acc 90.0, test_acc 73.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3 Nearest Neighbors\n",
    "LN_3_NN_model = nn.Sequential(\n",
    "    Conv1d_NN(in_channels=1, out_channels = 25, K = 3, stride=3),  # Change the number of input channels to 1\n",
    "    nn.ReLU(), \n",
    "    Conv1d_NN(in_channels=25, out_channels=25, K = 3, stride=3),\n",
    "    nn.ReLU(),\n",
    "    nn.Flatten(), \n",
    "    nn.Linear(1000, 10)\n",
    ").to('mps')\n",
    "\n",
    "# Get summary \n",
    "# from torchsummary import summary\n",
    "# summary(model, (1, 40), device=device)\n",
    "\n",
    "print(\"MNIST1D Model\")\n",
    "LN_3_NN_results = train_model(less_noise_data, LN_3_NN_model, less_noise_model)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST1D Model\n",
      "step 1000, dt 12.75s, train_loss 2.171e-01, test_loss 7.544e-01, train_acc 91.4, test_acc 76.3\n",
      "step 2000, dt 14.10s, train_loss 1.650e-01, test_loss 1.170e+00, train_acc 87.1, test_acc 72.3\n",
      "step 3000, dt 13.79s, train_loss 1.364e-01, test_loss 1.230e+00, train_acc 93.1, test_acc 75.7\n",
      "step 4000, dt 13.32s, train_loss 1.175e-01, test_loss 1.314e+00, train_acc 93.5, test_acc 76.5\n",
      "step 5000, dt 12.65s, train_loss 2.360e-02, test_loss 1.293e+00, train_acc 93.9, test_acc 74.1\n",
      "step 6000, dt 13.15s, train_loss 3.606e-02, test_loss 1.446e+00, train_acc 97.4, test_acc 76.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5 Nearest Neighbors\n",
    "LN_5_NN_model = nn.Sequential(\n",
    "    Conv1d_NN(in_channels=1, out_channels = 25, K = 5, stride=5),  # Change the number of input channels to 1\n",
    "    nn.ReLU(), \n",
    "    Conv1d_NN(in_channels=25, out_channels=25, K = 5, stride=5),\n",
    "    nn.ReLU(),\n",
    "    nn.Flatten(), \n",
    "    nn.Linear(1000, 10)\n",
    ").to('mps')\n",
    "\n",
    "# Get summary \n",
    "# from torchsummary import summary\n",
    "# summary(model, (1, 40), device=device)\n",
    "\n",
    "print(\"MNIST1D Model\")\n",
    "LN_5_NN_results = train_model(less_noise_data, LN_5_NN_model, less_noise_model)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST1D Model\n",
      "step 1000, dt 15.92s, train_loss 4.293e-01, test_loss 7.491e-01, train_acc 87.2, test_acc 75.6\n",
      "step 2000, dt 14.69s, train_loss 4.173e-01, test_loss 8.819e-01, train_acc 89.0, test_acc 76.8\n",
      "step 3000, dt 14.83s, train_loss 1.481e-01, test_loss 9.435e-01, train_acc 90.7, test_acc 77.3\n",
      "step 4000, dt 13.39s, train_loss 1.105e-01, test_loss 8.807e-01, train_acc 93.0, test_acc 80.3\n",
      "step 5000, dt 12.55s, train_loss 2.224e-01, test_loss 1.037e+00, train_acc 93.5, test_acc 79.5\n",
      "step 6000, dt 13.06s, train_loss 2.355e-01, test_loss 1.296e+00, train_acc 92.8, test_acc 78.4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# More Neighbors Conv1d_NN\n",
    "LN_8_NN_model = nn.Sequential(\n",
    "    Conv1d_NN(in_channels=1, out_channels =25, K = 8, stride=8),  # Change the number of input channels to 1\n",
    "    nn.ReLU(), \n",
    "    Conv1d_NN(in_channels=25, out_channels=25, K = 8, stride=8),\n",
    "    nn.ReLU(),\n",
    "    nn.Flatten(), \n",
    "    nn.Linear(1000, 10)\n",
    ").to('mps')\n",
    "\n",
    "# Get summary \n",
    "# from torchsummary import summary\n",
    "# summary(model, (1, 40), device=device)\n",
    "\n",
    "print(\"MNIST1D Model\")\n",
    "LN_8_NN_results = train_model(less_noise_data, LN_8_NN_model, less_noise_model)\n",
    "print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST1D Model\n",
      "step 1000, dt 14.91s, train_loss 4.443e-01, test_loss 7.140e-01, train_acc 85.0, test_acc 74.3\n",
      "step 2000, dt 14.72s, train_loss 2.362e-01, test_loss 7.076e-01, train_acc 90.1, test_acc 79.0\n",
      "step 3000, dt 15.57s, train_loss 2.307e-01, test_loss 5.805e-01, train_acc 93.4, test_acc 82.7\n",
      "step 4000, dt 13.64s, train_loss 2.049e-01, test_loss 8.018e-01, train_acc 90.3, test_acc 78.9\n",
      "step 5000, dt 13.15s, train_loss 2.288e-01, test_loss 1.021e+00, train_acc 93.6, test_acc 78.9\n",
      "step 6000, dt 13.01s, train_loss 1.341e-01, test_loss 1.170e+00, train_acc 92.2, test_acc 77.4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# More Neighbors Conv1d_NN\n",
    "LN_12_NN_model = nn.Sequential(\n",
    "    Conv1d_NN(in_channels=1, out_channels =25, K = 12, stride=12),  # Change the number of input channels to 1\n",
    "    nn.ReLU(), \n",
    "    Conv1d_NN(in_channels=25, out_channels=25, K = 12, stride=12),\n",
    "    nn.ReLU(),\n",
    "    nn.Flatten(), \n",
    "    nn.Linear(1000, 10)\n",
    ").to('mps')\n",
    "\n",
    "# Get summary \n",
    "# from torchsummary import summary\n",
    "# summary(model, (1, 40), device=device)\n",
    "\n",
    "print(\"MNIST1D Model\")\n",
    "LN_12_NN_results= train_model(less_noise_data, LN_12_NN_model, less_noise_model)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ** more neighbors doesnt mean better results (), but there is a middle ground that is better than others. More neighbors -> lower train_acc, but test_acc stays relatively same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Conv1d_NN same number of parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "slow_conv2d_forward_mps: input(device='cpu') and weight(device=mps:0')  must be on the same device",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Get summary \u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchsummary\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m summary\n\u001b[0;32m---> 13\u001b[0m \u001b[43msummary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m40\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/MK/lib/python3.12/site-packages/torchsummary/torchsummary.py:72\u001b[0m, in \u001b[0;36msummary\u001b[0;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[1;32m     68\u001b[0m model\u001b[38;5;241m.\u001b[39mapply(register_hook)\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# make a forward pass\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# print(x.shape)\u001b[39;00m\n\u001b[0;32m---> 72\u001b[0m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# remove these hooks\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m hooks:\n",
      "File \u001b[0;32m~/miniforge3/envs/MK/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/MK/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/MK/lib/python3.12/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/miniforge3/envs/MK/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/MK/lib/python3.12/site-packages/torch/nn/modules/module.py:1561\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1558\u001b[0m     bw_hook \u001b[38;5;241m=\u001b[39m hooks\u001b[38;5;241m.\u001b[39mBackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[1;32m   1559\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1561\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1562\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1563\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[1;32m   1564\u001b[0m         \u001b[38;5;241m*\u001b[39m_global_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1565\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1566\u001b[0m     ):\n\u001b[1;32m   1567\u001b[0m         \u001b[38;5;66;03m# mark that always called hook is run\u001b[39;00m\n",
      "File \u001b[0;32m~/Developer/Nearest-Neighbor-Convolution/notebooks/../Conv1d_NN.py:33\u001b[0m, in \u001b[0;36mConv1d_NN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     30\u001b[0m prime \u001b[38;5;241m=\u001b[39m nnt\u001b[38;5;241m.\u001b[39mprime_vmap_2d\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Calculate the convolution 1d         \u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1d_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprime\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/MK/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/MK/lib/python3.12/site-packages/torch/nn/modules/module.py:1561\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1558\u001b[0m     bw_hook \u001b[38;5;241m=\u001b[39m hooks\u001b[38;5;241m.\u001b[39mBackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[1;32m   1559\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1561\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1562\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1563\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[1;32m   1564\u001b[0m         \u001b[38;5;241m*\u001b[39m_global_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1565\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1566\u001b[0m     ):\n\u001b[1;32m   1567\u001b[0m         \u001b[38;5;66;03m# mark that always called hook is run\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/MK/lib/python3.12/site-packages/torch/nn/modules/conv.py:310\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/MK/lib/python3.12/site-packages/torch/nn/modules/conv.py:306\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv1d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    304\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    305\u001b[0m                     _single(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 306\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: slow_conv2d_forward_mps: input(device='cpu') and weight(device=mps:0')  must be on the same device"
     ]
    }
   ],
   "source": [
    "# Adjusted Conv1d_NN\n",
    "adjusted_model = nn.Sequential(\n",
    "    Conv1d_NN(in_channels=1, out_channels =25, K = 3),  # Change the number of input channels to 1\n",
    "    nn.ReLU(), \n",
    "    Conv1d_NN(in_channels=25, out_channels=25, K = 3),\n",
    "    nn.ReLU(),\n",
    "    nn.Flatten(), \n",
    "    nn.Linear(1000, 10)\n",
    ").to(device)\n",
    "\n",
    "# Get summary \n",
    "from torchsummary import summary\n",
    "summary(model, (1, 40), device=device)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Module.parameters at 0x31796fd80>\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1               [-1, 25, 19]             150\n",
      "              ReLU-2               [-1, 25, 19]               0\n",
      "            Conv1d-3               [-1, 25, 10]           1,900\n",
      "              ReLU-4               [-1, 25, 10]               0\n",
      "            Conv1d-5                [-1, 25, 5]           1,900\n",
      "              ReLU-6                [-1, 25, 5]               0\n",
      "           Flatten-7                  [-1, 125]               0\n",
      "            Linear-8                   [-1, 10]           1,260\n",
      "================================================================\n",
      "Total params: 5,210\n",
      "Trainable params: 5,210\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.01\n",
      "Params size (MB): 0.02\n",
      "Estimated Total Size (MB): 0.03\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Sequential version of MNIST model \n",
    "model1 = nn.Sequential(\n",
    "   nn.Conv1d(1, 25, 5, 2, 1), \n",
    "   nn.ReLU(),\n",
    "   nn.Conv1d(25, 25, 3, 2, 1),\n",
    "   nn.ReLU(),\n",
    "   nn.Conv1d(25, 25, 3, 2, 1),\n",
    "   nn.ReLU(),\n",
    "   nn.Flatten(),\n",
    "   nn.Linear(125, 10)\n",
    ")\n",
    "print(model1.parameters())\n",
    "# Get summary \n",
    "from torchsummary import summary\n",
    "summary(model1, (1, 40))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MK",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
