{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# June 18 Neural Network Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torch \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# MNIST1D \n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "from scipy.ndimage import gaussian_filter\n",
    "from scipy.interpolate import interp1d \n",
    "from mnist1d.data import make_dataset, get_dataset_args\n",
    "\n",
    "# Custom Modules \n",
    "import sys \n",
    "sys.path.append('../')\n",
    "from Conv1d_NN import Conv1d_NN\n",
    "\n",
    "from models import * \n",
    "from train import *\n",
    "\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1               [-1, 25, 40]             100\n",
      "         Conv1d_NN-2               [-1, 25, 40]               0\n",
      "              ReLU-3               [-1, 25, 40]               0\n",
      "            Conv1d-4               [-1, 25, 40]           1,900\n",
      "         Conv1d_NN-5               [-1, 25, 40]               0\n",
      "              ReLU-6               [-1, 25, 40]               0\n",
      "            Conv1d-7               [-1, 25, 40]           1,900\n",
      "         Conv1d_NN-8               [-1, 25, 40]               0\n",
      "              ReLU-9               [-1, 25, 40]               0\n",
      "          Flatten-10                 [-1, 1000]               0\n",
      "           Linear-11                   [-1, 10]          10,010\n",
      "================================================================\n",
      "Total params: 13,910\n",
      "Trainable params: 13,910\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.08\n",
      "Params size (MB): 0.05\n",
      "Estimated Total Size (MB): 0.13\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Conv1d_NN\n",
    "model = nn.Sequential(\n",
    "    Conv1d_NN(in_channels=1, out_channels =25, K = 3),  # Change the number of input channels to 1\n",
    "    nn.ReLU(), \n",
    "    Conv1d_NN(in_channels=25, out_channels=25, K = 3),\n",
    "    nn.ReLU(),\n",
    "    Conv1d_NN(in_channels=25, out_channels=25, K = 3),\n",
    "    nn.ReLU(),\n",
    "    nn.Flatten(), \n",
    "    nn.Linear(1000, 10)\n",
    ")\n",
    "\n",
    "# Get summary \n",
    "from torchsummary import summary\n",
    "summary(model, (1, 40), device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Module.parameters at 0x14f8f3140>\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1               [-1, 25, 40]             150\n",
      "              ReLU-2               [-1, 25, 40]               0\n",
      "            Conv1d-3               [-1, 25, 40]           3,150\n",
      "              ReLU-4               [-1, 25, 40]               0\n",
      "            Conv1d-5                [-1, 1, 40]             126\n",
      "              ReLU-6                [-1, 1, 40]               0\n",
      "================================================================\n",
      "Total params: 3,426\n",
      "Trainable params: 3,426\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.03\n",
      "Params size (MB): 0.01\n",
      "Estimated Total Size (MB): 0.04\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "# Sequential version of MNIST model \n",
    "model1 = nn.Sequential(\n",
    "   nn.Conv1d(1, 25, 5, 1, 2), \n",
    "   nn.ReLU(),\n",
    "   nn.Conv1d(25, 25, 5, 1, 2),\n",
    "   nn.ReLU(),\n",
    "   nn.Conv1d(25, 1, 5, 1, 2),\n",
    "   nn.ReLU()\n",
    ")\n",
    "print(model1.parameters())\n",
    "# Get summary \n",
    "from torchsummary import summary\n",
    "summary(model1, (1, 40))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized ConvBase model with 5210 parameters\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1               [-1, 25, 19]             150\n",
      "            Conv1d-2               [-1, 25, 10]           1,900\n",
      "            Conv1d-3                [-1, 25, 5]           1,900\n",
      "           Flatten-4                  [-1, 125]               0\n",
      "            Linear-5                   [-1, 10]           1,260\n",
      "================================================================\n",
      "Total params: 5,210\n",
      "Trainable params: 5,210\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.01\n",
      "Params size (MB): 0.02\n",
      "Estimated Total Size (MB): 0.03\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# NN.Module version of MNIST model\n",
    "model2 = ConvBase_v2(10)\n",
    "\n",
    "summary(model2, (1, 40), device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized ConvBase model with 5210 parameters\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1               [-1, 25, 19]             150\n",
      "            Conv1d-2               [-1, 25, 10]           1,900\n",
      "            Conv1d-3                [-1, 25, 5]           1,900\n",
      "           Flatten-4                  [-1, 125]               0\n",
      "            Linear-5                   [-1, 10]           1,260\n",
      "================================================================\n",
      "Total params: 5,210\n",
      "Trainable params: 5,210\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.01\n",
      "Params size (MB): 0.02\n",
      "Estimated Total Size (MB): 0.03\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Model from MNIST1D repository \n",
    "model3 = ConvBase(10)\n",
    "\n",
    "# Get summary\n",
    "from torchsummary import summary\n",
    "summary(model2, (1, 40), device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gather data MNIST1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4000, 1, 40]) (4000,) (40,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from mnist1d.data import make_dataset, get_dataset_args\n",
    "\n",
    "args = get_dataset_args(as_dict=False)\n",
    "\n",
    "\n",
    "set_seed(args.seed)\n",
    "args.shuffle_seq = False\n",
    "data = make_dataset(args = args) # Make the dataset \n",
    "data['x'] = torch.Tensor(data['x']).unsqueeze(1)\n",
    "data['x_test'] = torch.Tensor(data['x_test']).unsqueeze(1)\n",
    "\n",
    "print(data['x'].shape, data['y'].shape, data['t'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom Conv1d_NN\n",
      "step 1000, dt 18.46s, train_loss 9.205e-01, test_loss 1.460e+00, train_acc 66.3, test_acc 48.1\n",
      "step 2000, dt 16.45s, train_loss 6.508e-01, test_loss 1.710e+00, train_acc 69.9, test_acc 47.8\n",
      "step 3000, dt 17.22s, train_loss 6.880e-01, test_loss 1.804e+00, train_acc 72.7, test_acc 47.2\n",
      "step 4000, dt 16.87s, train_loss 6.980e-01, test_loss 2.088e+00, train_acc 71.5, test_acc 44.8\n",
      "step 5000, dt 15.42s, train_loss 6.172e-01, test_loss 2.145e+00, train_acc 71.4, test_acc 45.1\n",
      "step 6000, dt 15.12s, train_loss 5.760e-01, test_loss 2.034e+00, train_acc 72.0, test_acc 44.2\n",
      "\n",
      "Sequential MNIST Model\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected target size [100, 40], got [100]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSequential MNIST Model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m results1 \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m() \n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNN.Module MNIST Model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Developer/Nearest-Neighbor-Convolution/notebooks/../train.py:71\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(dataset, model, args)\u001b[0m\n\u001b[1;32m     68\u001b[0m bix \u001b[38;5;241m=\u001b[39m (step\u001b[38;5;241m*\u001b[39margs\u001b[38;5;241m.\u001b[39mbatch_size)\u001b[38;5;241m%\u001b[39m\u001b[38;5;28mlen\u001b[39m(x_train) \u001b[38;5;66;03m# batch index\u001b[39;00m\n\u001b[1;32m     69\u001b[0m x, y \u001b[38;5;241m=\u001b[39m x_train[bix:bix\u001b[38;5;241m+\u001b[39margs\u001b[38;5;241m.\u001b[39mbatch_size], y_train[bix:bix\u001b[38;5;241m+\u001b[39margs\u001b[38;5;241m.\u001b[39mbatch_size]\n\u001b[0;32m---> 71\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_losses\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m     73\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward() ; optimizer\u001b[38;5;241m.\u001b[39mstep() ; optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/miniforge3/envs/MK/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/MK/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/MK/lib/python3.12/site-packages/torch/nn/modules/loss.py:1179\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m-> 1179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1180\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1181\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/MK/lib/python3.12/site-packages/torch/nn/functional.py:3059\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3057\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3058\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3059\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected target size [100, 40], got [100]"
     ]
    }
   ],
   "source": [
    "\n",
    "args = get_model_args()\n",
    "args.device = 'mps'\n",
    "args.total_steps = 6000\n",
    "\n",
    "set_seed(args.seed)\n",
    "\n",
    "print(\"Custom Conv1d_NN\")\n",
    "results =train_model(data, model, args)\n",
    "print()\n",
    "\n",
    "print(\"Sequential MNIST Model\")\n",
    "results1 = train_model(data, model1, args)\n",
    "print() \n",
    "\n",
    "print(\"NN.Module MNIST Model\")\n",
    "results2 = train_model(data, model2, args)\n",
    "print()\n",
    "\n",
    "print(\"MNIST1D Model\")\n",
    "results3 = train_model(data, model3, args)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try with less noise data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.0\n",
      "torch.Size([4000, 1, 40]) (4000,) (40,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from mnist1d.data import make_dataset, get_dataset_args\n",
    "\n",
    "less_noise_args = get_dataset_args(as_dict=False)\n",
    "# {'num_samples': 5000, 'train_split': 0.8, 'template_len': 12, \n",
    "# 'padding': [36, 60], 'scale_coeff': 0.4, 'max_translation': 48, \n",
    "# 'corr_noise_scale': 0.25, 'iid_noise_scale': 0.02, 'shear_scale': 0.75, \n",
    "# 'shuffle_seq': False, 'final_seq_length': 40, 'seed': 42, \n",
    "# 'url': 'https://github.com/greydanus/mnist1d/raw/master/mnist1d_data.pkl'}\n",
    "\n",
    "set_seed(less_noise_args.seed)\n",
    "less_noise_args.shuffle_seq = False\n",
    "less_noise_args.corr_noise_scale = 0.00w\n",
    "less_noise_args.iid_noise_scale = 0.000\n",
    "\n",
    "\n",
    "\n",
    "less_noise_data = make_dataset(args = less_noise_args) # Make the dataset \n",
    "less_noise_data['x'] = torch.Tensor(less_noise_data['x']).unsqueeze(1)\n",
    "less_noise_data['x_test'] = torch.Tensor(less_noise_data['x_test']).unsqueeze(1)\n",
    "\n",
    "print(less_noise_args.corr_noise_scale, less_noise_args.iid_noise_scale)\n",
    "print(less_noise_data['x'].shape, less_noise_data['y'].shape, less_noise_data['t'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom Conv1d_NN\n",
      "step 1000, dt 20.48s, train_loss 4.620e-01, test_loss 9.579e-01, train_acc 88.5, test_acc 72.1\n",
      "step 2000, dt 16.90s, train_loss 2.041e-01, test_loss 9.293e-01, train_acc 91.5, test_acc 77.4\n",
      "step 3000, dt 16.07s, train_loss 3.565e-01, test_loss 1.039e+00, train_acc 88.0, test_acc 73.5\n",
      "step 4000, dt 16.19s, train_loss 2.824e-01, test_loss 9.296e-01, train_acc 90.7, test_acc 75.4\n",
      "step 5000, dt 16.32s, train_loss 1.998e-01, test_loss 9.712e-01, train_acc 93.3, test_acc 75.2\n",
      "step 6000, dt 16.26s, train_loss 1.677e-01, test_loss 8.623e-01, train_acc 92.8, test_acc 76.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "less_noise_model = get_model_args(as_dict=False)\n",
    "less_noise_model.device = 'mps'\n",
    "less_noise_model.total_steps = 6000\n",
    "\n",
    "print(\"Custom Conv1d_NN\")\n",
    "results =train_model(less_noise_data, model, less_noise_model)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try with more neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST1D Model\n",
      "step 1000, dt 15.95s, train_loss 7.050e-01, test_loss 8.853e-01, train_acc 71.7, test_acc 62.7\n",
      "step 2000, dt 14.73s, train_loss 6.554e-01, test_loss 7.885e-01, train_acc 76.4, test_acc 68.4\n",
      "step 3000, dt 14.88s, train_loss 6.499e-01, test_loss 7.803e-01, train_acc 78.2, test_acc 67.4\n",
      "step 4000, dt 15.09s, train_loss 5.422e-01, test_loss 7.817e-01, train_acc 80.4, test_acc 68.5\n",
      "step 5000, dt 14.92s, train_loss 6.419e-01, test_loss 8.007e-01, train_acc 78.7, test_acc 68.5\n",
      "step 6000, dt 14.75s, train_loss 5.104e-01, test_loss 7.938e-01, train_acc 81.2, test_acc 68.2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1 Nearest Neighbour \n",
    "LN_1_NN_model = nn.Sequential(\n",
    "    Conv1d_NN(in_channels=1, out_channels = 25, K = 1, stride=1),  # Change the number of input channels to 1\n",
    "    nn.ReLU(), \n",
    "    Conv1d_NN(in_channels=25, out_channels=25, K = 1, stride=1),\n",
    "    nn.ReLU(),\n",
    "    Conv1d_NN(in_channels=25, out_channels=25, K = 1, stride=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Flatten(), \n",
    "    nn.Linear(1000, 10)\n",
    ").to('mps')\n",
    "\n",
    "# Get summary \n",
    "# from torchsummary import summary\n",
    "# summary(model, (1, 40), device=device)\n",
    "\n",
    "print(\"MNIST1D Model\")\n",
    "LN_1_NN_results = train_model(less_noise_data, LN_1_NN_model, less_noise_model)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST1D Model\n",
      "step 1000, dt 16.18s, train_loss 6.143e-01, test_loss 6.880e-01, train_acc 82.2, test_acc 75.4\n",
      "step 2000, dt 15.13s, train_loss 4.802e-01, test_loss 6.682e-01, train_acc 84.4, test_acc 76.2\n",
      "step 3000, dt 15.00s, train_loss 5.199e-01, test_loss 6.288e-01, train_acc 87.6, test_acc 78.1\n",
      "step 4000, dt 15.09s, train_loss 3.524e-01, test_loss 6.767e-01, train_acc 88.5, test_acc 76.8\n",
      "step 5000, dt 15.08s, train_loss 4.712e-01, test_loss 7.476e-01, train_acc 88.6, test_acc 75.3\n",
      "step 6000, dt 14.89s, train_loss 3.783e-01, test_loss 7.438e-01, train_acc 88.3, test_acc 75.9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2 Nearby Neighbors\n",
    "LN_2_NN_model = nn.Sequential(\n",
    "    Conv1d_NN(in_channels=1, out_channels = 25, K = 2, stride=2),  # Change the number of input channels to 1\n",
    "    nn.ReLU(), \n",
    "    Conv1d_NN(in_channels=25, out_channels=25, K = 2, stride=2),\n",
    "    nn.ReLU(),\n",
    "    Conv1d_NN(in_channels=25, out_channels=25, K = 2, stride=2),\n",
    "    nn.ReLU(),\n",
    "    nn.Flatten(), \n",
    "    nn.Linear(1000, 10)\n",
    ").to('mps')\n",
    "\n",
    "# Get summary \n",
    "# from torchsummary import summary\n",
    "# summary(model, (1, 40), device=device)\n",
    "\n",
    "print(\"MNIST1D Model\")\n",
    "LN_2_NN_results = train_model(less_noise_data, LN_2_NN_model, less_noise_model)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST1D Model\n",
      "step 1000, dt 15.93s, train_loss 5.379e-01, test_loss 5.674e-01, train_acc 86.8, test_acc 77.6\n",
      "step 2000, dt 15.16s, train_loss 4.409e-01, test_loss 6.636e-01, train_acc 87.2, test_acc 76.7\n",
      "step 3000, dt 15.21s, train_loss 4.676e-01, test_loss 7.538e-01, train_acc 89.3, test_acc 78.1\n",
      "step 4000, dt 15.31s, train_loss 2.744e-01, test_loss 7.043e-01, train_acc 91.6, test_acc 80.6\n",
      "step 5000, dt 15.41s, train_loss 4.585e-01, test_loss 9.683e-01, train_acc 86.8, test_acc 75.5\n",
      "step 6000, dt 15.45s, train_loss 3.838e-01, test_loss 7.532e-01, train_acc 92.6, test_acc 79.3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3 Nearest Neighbors\n",
    "LN_3_NN_model = nn.Sequential(\n",
    "    Conv1d_NN(in_channels=1, out_channels = 25, K = 3, stride=3),  # Change the number of input channels to 1\n",
    "    nn.ReLU(), \n",
    "    Conv1d_NN(in_channels=25, out_channels=25, K = 3, stride=3),\n",
    "    nn.ReLU(),\n",
    "    Conv1d_NN(in_channels=25, out_channels=25, K = 3, stride=3),\n",
    "    nn.ReLU(),\n",
    "    nn.Flatten(), \n",
    "    nn.Linear(1000, 10)\n",
    ").to('mps')\n",
    "\n",
    "# Get summary \n",
    "# from torchsummary import summary\n",
    "# summary(model, (1, 40), device=device)\n",
    "\n",
    "print(\"MNIST1D Model\")\n",
    "LN_3_NN_results = train_model(less_noise_data, LN_3_NN_model, less_noise_model)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST1D Model\n",
      "step 1000, dt 16.62s, train_loss 3.737e-01, test_loss 7.674e-01, train_acc 82.7, test_acc 72.8\n",
      "step 2000, dt 16.15s, train_loss 1.245e-01, test_loss 6.153e-01, train_acc 92.9, test_acc 78.9\n",
      "step 3000, dt 19.37s, train_loss 3.034e-01, test_loss 7.824e-01, train_acc 88.6, test_acc 76.5\n",
      "step 4000, dt 18.17s, train_loss 3.574e-01, test_loss 6.591e-01, train_acc 93.4, test_acc 82.1\n",
      "step 5000, dt 18.98s, train_loss 1.621e-01, test_loss 7.076e-01, train_acc 93.5, test_acc 79.8\n",
      "step 6000, dt 19.38s, train_loss 7.951e-02, test_loss 7.962e-01, train_acc 93.2, test_acc 81.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5 Nearest Neighbors\n",
    "LN_5_NN_model = nn.Sequential(\n",
    "    Conv1d_NN(in_channels=1, out_channels = 25, K = 5, stride=5),  # Change the number of input channels to 1\n",
    "    nn.ReLU(), \n",
    "    Conv1d_NN(in_channels=25, out_channels=25, K = 5, stride=5),\n",
    "    nn.ReLU(),\n",
    "    Conv1d_NN(in_channels=25, out_channels=25, K = 5, stride=5),\n",
    "    nn.ReLU(),\n",
    "    nn.Flatten(), \n",
    "    nn.Linear(1000, 10)\n",
    ").to('mps')\n",
    "\n",
    "# Get summary \n",
    "# from torchsummary import summary\n",
    "# summary(model, (1, 40), device=device)\n",
    "\n",
    "print(\"MNIST1D Model\")\n",
    "LN_5_NN_results = train_model(less_noise_data, LN_5_NN_model, less_noise_model)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST1D Model\n",
      "step 1000, dt 21.66s, train_loss 5.106e-01, test_loss 7.181e-01, train_acc 84.2, test_acc 74.2\n",
      "step 2000, dt 20.24s, train_loss 3.568e-01, test_loss 7.086e-01, train_acc 87.7, test_acc 76.8\n",
      "step 3000, dt 21.14s, train_loss 3.166e-01, test_loss 7.056e-01, train_acc 89.4, test_acc 79.3\n",
      "step 4000, dt 21.14s, train_loss 3.055e-01, test_loss 8.528e-01, train_acc 87.8, test_acc 78.4\n",
      "step 5000, dt 20.21s, train_loss 2.606e-01, test_loss 8.664e-01, train_acc 90.3, test_acc 78.5\n",
      "step 6000, dt 22.14s, train_loss 1.691e-01, test_loss 8.443e-01, train_acc 90.3, test_acc 80.2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 8 Neighbors Conv1d_NN\n",
    "LN_8_NN_model = nn.Sequential(\n",
    "    Conv1d_NN(in_channels=1, out_channels =25, K = 8, stride=8),  # Change the number of input channels to 1\n",
    "    nn.ReLU(), \n",
    "    Conv1d_NN(in_channels=25, out_channels=25, K = 8, stride=8),\n",
    "    nn.ReLU(),\n",
    "    Conv1d_NN(in_channels=25, out_channels=25, K = 8, stride=8),\n",
    "    nn.ReLU(),\n",
    "    nn.Flatten(), \n",
    "    nn.Linear(1000, 10)\n",
    ").to('mps')\n",
    "\n",
    "# Get summary \n",
    "# from torchsummary import summary\n",
    "# summary(model, (1, 40), device=device)\n",
    "\n",
    "print(\"MNIST1D Model\")\n",
    "LN_8_NN_results = train_model(less_noise_data, LN_8_NN_model, less_noise_model)\n",
    "print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST1D Model\n",
      "step 1000, dt 20.18s, train_loss 4.412e-01, test_loss 8.427e-01, train_acc 78.1, test_acc 71.2\n",
      "step 2000, dt 19.42s, train_loss 4.779e-01, test_loss 8.643e-01, train_acc 81.6, test_acc 73.0\n",
      "step 3000, dt 19.22s, train_loss 3.097e-01, test_loss 6.307e-01, train_acc 87.3, test_acc 77.6\n",
      "step 4000, dt 19.27s, train_loss 3.508e-01, test_loss 8.706e-01, train_acc 86.4, test_acc 73.7\n",
      "step 5000, dt 19.31s, train_loss 3.286e-01, test_loss 7.269e-01, train_acc 90.7, test_acc 78.0\n",
      "step 6000, dt 20.55s, train_loss 3.014e-01, test_loss 7.669e-01, train_acc 89.8, test_acc 77.2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 12 Neighbors Conv1d_NN\n",
    "LN_12_NN_model = nn.Sequential(\n",
    "    Conv1d_NN(in_channels=1, out_channels =25, K = 12, stride=12),  # Change the number of input channels to 1\n",
    "    nn.ReLU(), \n",
    "    Conv1d_NN(in_channels=25, out_channels=25, K = 12, stride=12),\n",
    "    nn.ReLU(),\n",
    "    Conv1d_NN(in_channels=25, out_channels=25, K = 12, stride=12),\n",
    "    nn.ReLU(),\n",
    "    nn.Flatten(), \n",
    "    nn.Linear(1000, 10)\n",
    ").to('mps')\n",
    "\n",
    "# Get summary \n",
    "# from torchsummary import summary\n",
    "# summary(model, (1, 40), device=device)\n",
    "\n",
    "print(\"MNIST1D Model\")\n",
    "LN_12_NN_results= train_model(less_noise_data, LN_12_NN_model, less_noise_model)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Model with noise data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST1D Model with 3 Neighbors\n",
      "step 1000, dt 16.50s, train_loss 7.808e-01, test_loss 1.410e+00, train_acc 65.9, test_acc 45.8\n",
      "step 2000, dt 15.55s, train_loss 7.897e-01, test_loss 1.592e+00, train_acc 70.2, test_acc 47.9\n",
      "step 3000, dt 15.64s, train_loss 6.783e-01, test_loss 1.953e+00, train_acc 72.7, test_acc 44.4\n",
      "step 4000, dt 15.89s, train_loss 5.978e-01, test_loss 1.821e+00, train_acc 74.3, test_acc 45.8\n",
      "step 5000, dt 15.63s, train_loss 5.238e-01, test_loss 2.059e+00, train_acc 76.1, test_acc 45.7\n",
      "step 6000, dt 17.66s, train_loss 5.332e-01, test_loss 2.220e+00, train_acc 71.5, test_acc 44.1\n"
     ]
    }
   ],
   "source": [
    "print(\"MNIST1D Model with 3 Neighbors\")\n",
    "best_model_noise_results = train_model(data, LN_3_NN_model, args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST1D Model with 5 Neighbors\n",
      "step 1000, dt 20.61s, train_loss 1.026e+00, test_loss 1.385e+00, train_acc 64.0, test_acc 48.2\n",
      "step 2000, dt 20.93s, train_loss 7.435e-01, test_loss 1.552e+00, train_acc 69.5, test_acc 48.1\n",
      "step 3000, dt 19.56s, train_loss 7.189e-01, test_loss 1.584e+00, train_acc 70.8, test_acc 47.6\n",
      "step 4000, dt 19.58s, train_loss 8.023e-01, test_loss 1.707e+00, train_acc 72.2, test_acc 49.5\n",
      "step 5000, dt 19.53s, train_loss 6.887e-01, test_loss 1.971e+00, train_acc 72.9, test_acc 48.2\n",
      "step 6000, dt 20.85s, train_loss 5.770e-01, test_loss 1.872e+00, train_acc 73.9, test_acc 46.9\n"
     ]
    }
   ],
   "source": [
    "print(\"MNIST1D Model with 5 Neighbors\")\n",
    "best_model_noise_results = train_model(data, LN_5_NN_model, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST1D Model with 8 Neighbors\n",
      "step 1000, dt 24.13s, train_loss 1.020e+00, test_loss 1.287e+00, train_acc 59.8, test_acc 50.9\n",
      "step 2000, dt 22.37s, train_loss 9.920e-01, test_loss 1.409e+00, train_acc 60.8, test_acc 49.3\n",
      "step 3000, dt 22.20s, train_loss 1.011e+00, test_loss 1.480e+00, train_acc 60.5, test_acc 48.1\n",
      "step 4000, dt 22.94s, train_loss 9.850e-01, test_loss 1.473e+00, train_acc 63.7, test_acc 48.8\n",
      "step 5000, dt 23.42s, train_loss 9.235e-01, test_loss 1.589e+00, train_acc 65.0, test_acc 46.3\n",
      "step 6000, dt 22.75s, train_loss 8.793e-01, test_loss 1.634e+00, train_acc 64.1, test_acc 46.8\n"
     ]
    }
   ],
   "source": [
    "print(\"MNIST1D Model with 8 Neighbors\")\n",
    "best_model_noise_results = train_model(data, LN_8_NN_model, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST1D Model with 12 Neighbors\n",
      "step 1000, dt 20.13s, train_loss 1.023e+00, test_loss 1.425e+00, train_acc 60.8, test_acc 48.3\n",
      "step 2000, dt 22.45s, train_loss 1.041e+00, test_loss 1.410e+00, train_acc 62.5, test_acc 47.5\n",
      "step 3000, dt 21.10s, train_loss 9.421e-01, test_loss 1.537e+00, train_acc 63.3, test_acc 47.3\n",
      "step 4000, dt 20.32s, train_loss 9.160e-01, test_loss 1.480e+00, train_acc 65.8, test_acc 48.3\n",
      "step 5000, dt 20.85s, train_loss 9.226e-01, test_loss 1.564e+00, train_acc 65.2, test_acc 47.6\n",
      "step 6000, dt 20.21s, train_loss 9.036e-01, test_loss 1.783e+00, train_acc 64.3, test_acc 47.9\n"
     ]
    }
   ],
   "source": [
    "print(\"MNIST1D Model with 12 Neighbors\")\n",
    "best_model_noise_results = train_model(data, LN_12_NN_model, args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ** more neighbors doesnt mean better results (), but there is a middle ground that is better than others. More neighbors -> lower train_acc, but test_acc stays relatively same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Conv1d_NN same number of parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1               [-1, 25, 40]             100\n",
      "         Conv1d_NN-2               [-1, 25, 40]               0\n",
      "              ReLU-3               [-1, 25, 40]               0\n",
      "            Conv1d-4               [-1, 25, 40]           1,900\n",
      "         Conv1d_NN-5               [-1, 25, 40]               0\n",
      "              ReLU-6               [-1, 25, 40]               0\n",
      "            Conv1d-7               [-1, 25, 40]           1,900\n",
      "         Conv1d_NN-8               [-1, 25, 40]               0\n",
      "              ReLU-9               [-1, 25, 40]               0\n",
      "          Flatten-10                 [-1, 1000]               0\n",
      "           Linear-11                   [-1, 10]          10,010\n",
      "================================================================\n",
      "Total params: 13,910\n",
      "Trainable params: 13,910\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.08\n",
      "Params size (MB): 0.05\n",
      "Estimated Total Size (MB): 0.13\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Adjusted Conv1d_NN\n",
    "adjusted_model = nn.Sequential(\n",
    "    Conv1d_NN(in_channels=1, out_channels =25, K = 3),  # Change the number of input channels to 1\n",
    "    nn.ReLU(), \n",
    "    Conv1d_NN(in_channels=25, out_channels=25, K = 3),\n",
    "    nn.ReLU(),\n",
    "    Conv1d_NN(in_channels=25, out_channels=25, K = 3),\n",
    "    nn.ReLU(),\n",
    "    nn.Flatten(), \n",
    "    nn.Linear(1000, 10)\n",
    ").to('cpu')\n",
    "\n",
    "# Get summary \n",
    "from torchsummary import summary\n",
    "summary(adjusted_model, (1, 40))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Module.parameters at 0x30774f920>\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1               [-1, 25, 19]             150\n",
      "              ReLU-2               [-1, 25, 19]               0\n",
      "            Conv1d-3               [-1, 25, 10]           1,900\n",
      "              ReLU-4               [-1, 25, 10]               0\n",
      "            Conv1d-5                [-1, 25, 5]           1,900\n",
      "              ReLU-6                [-1, 25, 5]               0\n",
      "           Flatten-7                  [-1, 125]               0\n",
      "            Linear-8                   [-1, 10]           1,260\n",
      "================================================================\n",
      "Total params: 5,210\n",
      "Trainable params: 5,210\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.01\n",
      "Params size (MB): 0.02\n",
      "Estimated Total Size (MB): 0.03\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Sequential version of MNIST model \n",
    "model1 = nn.Sequential(\n",
    "   nn.Conv1d(1, 25, 5, 2, 1), \n",
    "   nn.ReLU(),\n",
    "   nn.Conv1d(25, 25, 3, 2, 1),\n",
    "   nn.ReLU(),\n",
    "   nn.Conv1d(25, 25, 3, 2, 1),\n",
    "   nn.ReLU(),\n",
    "   nn.Flatten(),\n",
    "   nn.Linear(125, 10)\n",
    ")\n",
    "print(model1.parameters())\n",
    "# Get summary \n",
    "from torchsummary import summary\n",
    "summary(model1, (1, 40))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MK",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
