{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96f8eef9",
   "metadata": {},
   "source": [
    "## Main Parsing Function for train_eval_results.txt Files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab46901f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "\n",
    "def parse_training_results(file_path):\n",
    "    \"\"\"Parse training results from text file into a pandas DataFrame\"\"\"\n",
    "    \n",
    "    # Read the file\n",
    "    with open(file_path, 'r') as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    # Initialize lists to store data\n",
    "    epochs = []\n",
    "    times = []\n",
    "    train_losses = []\n",
    "    train_acc_top1 = []\n",
    "    train_acc_top5 = []\n",
    "    test_losses = []\n",
    "    test_acc_top1 = []\n",
    "    test_acc_top5 = []\n",
    "    \n",
    "    # Regular expression to match each epoch line\n",
    "    pattern = r'\\[Epoch (\\d+)\\] Time: ([\\d.]+)s.*?Train.*?Loss: ([\\d.]+).*?Top1: ([\\d.]+)%.*?Top5: ([\\d.]+)%.*?Test.*?Loss: ([\\d.]+).*?Top1: ([\\d.]+)%.*?Top5: ([\\d.]+)%'\n",
    "    \n",
    "    # Find all matches\n",
    "    matches = re.findall(pattern, content)\n",
    "    \n",
    "    for match in matches:\n",
    "        epochs.append(int(match[0]))\n",
    "        times.append(float(match[1]))\n",
    "        train_losses.append(float(match[2]))\n",
    "        train_acc_top1.append(float(match[3]))\n",
    "        train_acc_top5.append(float(match[4]))\n",
    "        test_losses.append(float(match[5]))\n",
    "        test_acc_top1.append(float(match[6]))\n",
    "        test_acc_top5.append(float(match[7]))\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'epoch': epochs,\n",
    "        'time': times,\n",
    "        'train_loss': train_losses,\n",
    "        'train_accuracy_top1': train_acc_top1,\n",
    "        'train_accuracy_top5': train_acc_top5,\n",
    "        'test_loss': test_losses,\n",
    "        'test_accuracy_top1': test_acc_top1,\n",
    "        'test_accuracy_top5': test_acc_top5\n",
    "    })\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecda0619",
   "metadata": {},
   "source": [
    "### I. Loss Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e263ce1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Conv2d_Path = \"/Users/mingikang/Developer/Convolutional-Nearest-Neighbor/Output/Sep_24_Branching_NoSplit/vgg_1e-5_cos/CIFAR10/Col_Col_Branch/ConvBranch_K9_r000_s42/train_eval_results.txt\"\n",
    "ConvNN_Path = \"/Users/mingikang/Developer/Convolutional-Nearest-Neighbor/Output/Sep_24_Branching_NoSplit/vgg_1e-5_cos/CIFAR10/Col_Col_Branch/ConvBranch_K9_r050_s42/train_eval_results.txt\"\n",
    "\n",
    "df_Conv2d = parse_training_results(Conv2d_Path)\n",
    "df_ConvNN = parse_training_results(ConvNN_Path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6537ec96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    epoch     time  train_loss  train_accuracy_top1  train_accuracy_top5  \\\n",
      "55     56  13.5602    0.005601              99.8022                100.0   \n",
      "56     57  13.5844    0.004974              99.8342                100.0   \n",
      "57     58  13.5464    0.002998              99.8961                100.0   \n",
      "58     59  13.5725    0.004239              99.8561                100.0   \n",
      "59     60  13.5960    0.005837              99.8182                100.0   \n",
      "\n",
      "    test_loss  test_accuracy_top1  test_accuracy_top5  \n",
      "55   2.620213             69.3173             96.5565  \n",
      "56   2.633557             69.9642             96.7755  \n",
      "57   2.653949             70.1632             96.6063  \n",
      "58   2.629530             70.0438             96.7158  \n",
      "59   2.578960             69.7850             96.9347  \n"
     ]
    }
   ],
   "source": [
    "print(df_Conv2d.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39c1057f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    epoch     time  train_loss  train_accuracy_top1  train_accuracy_top5  \\\n",
      "55     56  23.6237    0.131086              95.2925               99.948   \n",
      "56     57  23.6186    0.119373              95.7361               99.970   \n",
      "57     58  23.6360    0.120541              95.7101               99.962   \n",
      "58     59  23.6289    0.118510              95.8520               99.968   \n",
      "59     60  23.6361    0.109851              96.2096               99.966   \n",
      "\n",
      "    test_loss  test_accuracy_top1  test_accuracy_top5  \n",
      "55   1.195560             73.5768             98.3181  \n",
      "56   1.223960             73.4076             98.1091  \n",
      "57   1.218058             74.0048             98.2783  \n",
      "58   1.199236             74.1441             98.1688  \n",
      "59   1.233663             73.6166             98.0792  \n"
     ]
    }
   ],
   "source": [
    "print(df_ConvNN.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4afa312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    epoch  Conv2d_Train_Loss  Conv2d_Test_Loss  ConvNN_Train_Loss  \\\n",
      "55     56           0.005601          2.620213           0.131086   \n",
      "56     57           0.004974          2.633557           0.119373   \n",
      "57     58           0.002998          2.653949           0.120541   \n",
      "58     59           0.004239          2.629530           0.118510   \n",
      "59     60           0.005837          2.578960           0.109851   \n",
      "\n",
      "    ConvNN_Test_Loss  \n",
      "55          1.195560  \n",
      "56          1.223960  \n",
      "57          1.218058  \n",
      "58          1.199236  \n",
      "59          1.233663  \n"
     ]
    }
   ],
   "source": [
    "Loss_df = pd.DataFrame({\n",
    "    'epoch': df_Conv2d['epoch'],\n",
    "    'Conv2d_Train_Loss': df_Conv2d['train_loss'],\n",
    "    'Conv2d_Test_Loss': df_Conv2d['test_loss'],\n",
    "    'ConvNN_Train_Loss': df_ConvNN['train_loss'],\n",
    "    'ConvNN_Test_Loss': df_ConvNN['test_loss']\n",
    "})\n",
    "\n",
    "print(Loss_df.tail())\n",
    "Loss_df.to_csv(\"csv/Loss_Comparison.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4138aa",
   "metadata": {},
   "source": [
    "### II. Ks Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cbca6991",
   "metadata": {},
   "outputs": [],
   "source": [
    "path1 = \"/Users/mingikang/Developer/Convolutional-Nearest-Neighbor/Output/Sep_25_Branching_NoSplit_KTest/vgg_1e-5_cos/CIFAR10/LocCol_LocCol_Branch/ConvBranch_\"\n",
    "path2 = \"_s42/train_eval_results.txt\"\n",
    "\n",
    "\n",
    "Ks = list(range(1, 13))\n",
    "Ks1_Ks = {}\n",
    "Ks2_Ks = {}\n",
    "Ks3_Ks = {}\n",
    "KS = {}\n",
    "\n",
    "ks1 = [\"KS1_K1_r025\", \"KS1_K2_r025\", \"KS1_K3_r025\", \"KS1_K4_r025\", \"KS1_K5_r025\", \"KS1_K6_r025\", \"KS1_K7_r025\", \"KS1_K8_r025\", \"KS1_K9_r025\", \"KS1_K10_r025\", \"KS1_K11_r025\", \"KS1_K12_r025\"]\n",
    "ks2 = [\"KS2_K1_r025\", \"KS2_K2_r025\", \"KS2_K3_r025\", \"KS2_K4_r025\", \"KS2_K5_r025\", \"KS2_K6_r025\", \"KS2_K7_r025\", \"KS2_K8_r025\", \"KS2_K9_r025\", \"KS2_K10_r025\", \"KS2_K11_r025\", \"KS2_K12_r025\"]\n",
    "ks3 = [\"KS3_K1_r025\", \"KS3_K2_r025\", \"KS3_K3_r025\", \"KS3_K4_r025\", \"KS3_K5_r025\", \"KS3_K6_r025\", \"KS3_K7_r025\", \"KS3_K8_r025\", \"KS3_K9_r025\", \"KS3_K10_r025\", \"KS3_K11_r025\", \"KS3_K12_r025\"]\n",
    "\n",
    "ks = [\"KS1_r000\", \"KS2_r000\", \"KS3_r000\"]\n",
    "\n",
    "for k in ks1:\n",
    "    full_path = path1 + k + path2\n",
    "    Ks1_Ks[k] = parse_training_results(full_path)\n",
    "\n",
    "for k in ks2:\n",
    "    full_path = path1 + k + path2\n",
    "    Ks2_Ks[k] = parse_training_results(full_path)\n",
    "\n",
    "for k in ks3:\n",
    "    full_path = path1 + k + path2\n",
    "    Ks3_Ks[k] = parse_training_results(full_path)\n",
    "\n",
    "for k in ks:\n",
    "    full_path = path1 + k + path2\n",
    "    KS[k] = parse_training_results(full_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fe1c667a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "print(len(Ks))\n",
    "print(len(Ks1_Ks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d78dcdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dict = {\n",
    "    \"K\": Ks, \n",
    "    \"Ks1_K\": [], \n",
    "    \"Ks2_K\": [],\n",
    "    \"Ks3_K\": [],\n",
    "    \"Ks1\": [],\n",
    "    \"Ks2\": [],\n",
    "    \"Ks3\": []\n",
    "}\n",
    "\n",
    "\n",
    "for k, df in Ks1_Ks.items():\n",
    "    final_dict[\"Ks1_K\"].append(df['test_accuracy_top1'].iloc[-1])\n",
    "\n",
    "for k, df in Ks2_Ks.items():\n",
    "    final_dict[\"Ks2_K\"].append(df['test_accuracy_top1'].iloc[-1])\n",
    "\n",
    "for k, df in Ks3_Ks.items():\n",
    "    final_dict[\"Ks3_K\"].append(df['test_accuracy_top1'].iloc[-1])\n",
    "\n",
    "for i in range(1, 13):\n",
    "    ks3 = KS[\"KS3_r000\"]\n",
    "    ks2 = KS[\"KS2_r000\"]\n",
    "    ks1 = KS[\"KS1_r000\"]\n",
    "    final_dict[\"Ks3\"].append(ks3['test_accuracy_top1'].iloc[-1])\n",
    "    final_dict[\"Ks2\"].append(ks2['test_accuracy_top1'].iloc[-1])\n",
    "    final_dict[\"Ks1\"].append(ks1['test_accuracy_top1'].iloc[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9653505c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'K': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], 'Ks1_K': [np.float64(57.1557), np.float64(57.8921), np.float64(59.2556), np.float64(60.211), np.float64(60.7385), np.float64(61.246), np.float64(62.4005), np.float64(61.9825), np.float64(61.9029), np.float64(62.4701), np.float64(62.5597), np.float64(61.3654)], 'Ks2_K': [np.float64(66.1027), np.float64(67.5159), np.float64(66.9686), np.float64(69.3173), np.float64(69.8547), np.float64(71.2082), np.float64(72.0243), np.float64(70.9494), np.float64(72.492), np.float64(72.1039), np.float64(72.8006), np.float64(71.5565)], 'Ks3_K': [np.float64(68.6803), np.float64(69.7154), np.float64(71.2082), np.float64(71.9347), np.float64(73.338), np.float64(74.1242), np.float64(74.0744), np.float64(74.2635), np.float64(75.4976), np.float64(74.9701), np.float64(74.9602), np.float64(75.5971)], 'Ks1': [np.float64(50.7663), np.float64(50.7663), np.float64(50.7663), np.float64(50.7663), np.float64(50.7663), np.float64(50.7663), np.float64(50.7663), np.float64(50.7663), np.float64(50.7663), np.float64(50.7663), np.float64(50.7663), np.float64(50.7663)], 'Ks2': [np.float64(65.3065), np.float64(65.3065), np.float64(65.3065), np.float64(65.3065), np.float64(65.3065), np.float64(65.3065), np.float64(65.3065), np.float64(65.3065), np.float64(65.3065), np.float64(65.3065), np.float64(65.3065), np.float64(65.3065)], 'Ks3': [np.float64(69.8945), np.float64(69.8945), np.float64(69.8945), np.float64(69.8945), np.float64(69.8945), np.float64(69.8945), np.float64(69.8945), np.float64(69.8945), np.float64(69.8945), np.float64(69.8945), np.float64(69.8945), np.float64(69.8945)]}\n"
     ]
    }
   ],
   "source": [
    "print(final_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0eb9982e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_df = pd.DataFrame(final_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a201580e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     K    Ks1_K    Ks2_K    Ks3_K      Ks1      Ks2      Ks3\n",
      "0    1  57.1557  66.1027  68.6803  50.7663  65.3065  69.8945\n",
      "1    2  57.8921  67.5159  69.7154  50.7663  65.3065  69.8945\n",
      "2    3  59.2556  66.9686  71.2082  50.7663  65.3065  69.8945\n",
      "3    4  60.2110  69.3173  71.9347  50.7663  65.3065  69.8945\n",
      "4    5  60.7385  69.8547  73.3380  50.7663  65.3065  69.8945\n",
      "5    6  61.2460  71.2082  74.1242  50.7663  65.3065  69.8945\n",
      "6    7  62.4005  72.0243  74.0744  50.7663  65.3065  69.8945\n",
      "7    8  61.9825  70.9494  74.2635  50.7663  65.3065  69.8945\n",
      "8    9  61.9029  72.4920  75.4976  50.7663  65.3065  69.8945\n",
      "9   10  62.4701  72.1039  74.9701  50.7663  65.3065  69.8945\n",
      "10  11  62.5597  72.8006  74.9602  50.7663  65.3065  69.8945\n",
      "11  12  61.3654  71.5565  75.5971  50.7663  65.3065  69.8945\n"
     ]
    }
   ],
   "source": [
    "print(ks_df)\n",
    "ks_df.to_csv(\"csv/Ks_Comparison.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b98f511",
   "metadata": {},
   "source": [
    "### III. Random + Spatial Sampling Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3d17985",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def parse_params_gflops(file_dir):\n",
    "    \"\"\"Parse training results from text file into a pandas DataFrame\"\"\"\n",
    "\n",
    "    train_path = os.path.join(file_dir, \"train_eval_results.txt\")\n",
    "    args_path = os.path.join(file_dir, \"args.txt\")\n",
    "    \n",
    "    # Read the file\n",
    "    with open(train_path, 'r') as f:\n",
    "        train_content = f.readline()\n",
    "\n",
    "    with open(args_path, 'r') as f:\n",
    "        args_content = f.readlines()\n",
    "\n",
    "    total_params = args_content[-2].strip().split(\": \")[1]\n",
    "    trainable_params = args_content[-1].strip().split(\": \")[1]\n",
    "\n",
    "    gflops = re.search(r'GFLOPs: ([\\d.]+)', train_content).group(1)\n",
    "\n",
    "    return {\n",
    "        \"total_params\": int(total_params),\n",
    "        \"trainable_params\": int(trainable_params),\n",
    "        \"gflops\": float(gflops)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1809bcfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'16_acc': np.float64(69.9244), '64_acc': np.float64(69.9244), '144_acc': np.float64(69.9244), '256_acc': np.float64(69.9244), '400_acc': np.float64(69.9244), '576_acc': np.float64(69.9244), '784_acc': np.float64(69.9244)}\n",
      "{'16_conv': 0.2936832, '64_conv': 0.2936832, '144_conv': 0.2936832, '256_conv': 0.2936832, '400_conv': 0.2936832, '576_conv': 0.2936832, '784_conv': 0.2936832}\n"
     ]
    }
   ],
   "source": [
    "N_test_path = test_path = \"/Users/mingikang/Developer/Convolutional-Nearest-Neighbor/Output/Sep_29_Branching_NTest/vgg_1e-5_cos/CIFAR10/LocCol_LocCol_Branch/ConvBranch_KS3_K9_r025_\"\n",
    "\n",
    "rand_nums = [16, 64, 144, 256, 400, 576, 784]\n",
    "spat_nums = [4, 8, 12, 16, 20, 24, 28]\n",
    "rand_nums = [str(num) for num in rand_nums]\n",
    "spat_nums = [str(num) for num in spat_nums]\n",
    "\n",
    "# Random First\n",
    "rand_N_dict = {}\n",
    "rand_acc_dict = {}\n",
    "for n in rand_nums:\n",
    "    full_path = N_test_path + \"rand\" + n + \"_s42\"\n",
    "    rand_N_dict[n] = parse_params_gflops(full_path)[\"gflops\"]\n",
    "\n",
    "    # Get Top-1 Accuracy\n",
    "    df = parse_training_results(full_path + \"/train_eval_results.txt\")\n",
    "    rand_acc_dict[n+\"_acc\"] = df['test_accuracy_top1'].iloc[-1]\n",
    "    \n",
    "\n",
    "# Spatial Sampling\n",
    "spat_N_dict = {}\n",
    "spat_acc_dict = {}\n",
    "for n in spat_nums:\n",
    "    full_path = N_test_path + \"spat\" + n + \"_s42\"\n",
    "    spat_N_dict[n] = parse_params_gflops(full_path)[\"gflops\"]\n",
    "\n",
    "    # Get Top-1 Accuracy\n",
    "    df = parse_training_results(full_path + \"/train_eval_results.txt\")\n",
    "    spat_acc_dict[n+\"_acc\"] = df['test_accuracy_top1'].iloc[-1]\n",
    "\n",
    "# All Sampling\n",
    "all_N_dict = {}\n",
    "all_acc_dict = {}\n",
    "for n in rand_nums:\n",
    "    all_path = \"/Users/mingikang/Developer/Convolutional-Nearest-Neighbor/Output/Sep_25_Branching_NoSplit_KTest/vgg_1e-5_cos/CIFAR10/LocCol_LocCol_Branch/ConvBranch_KS3_K9_r025_s42\"\n",
    "    all_N_dict[n] = parse_params_gflops(all_path)[\"gflops\"]\n",
    "\n",
    "    # Get Top-1 Accuracy\n",
    "    df = parse_training_results(all_path + \"/train_eval_results.txt\")\n",
    "    all_acc_dict[n+\"_acc\"] = df['test_accuracy_top1'].iloc[-1]\n",
    "\n",
    "\n",
    "\n",
    "conv_N_dict = {}\n",
    "conv_acc_dict = {}\n",
    "for n in rand_nums:\n",
    "    conv_path = \"/Users/mingikang/Developer/Convolutional-Nearest-Neighbor/Output/Sep_24_Branching_NoSplit/vgg_1e-5_cos/CIFAR10/LocCol_LocCol_Branch/ConvBranch_K9_r000_s42\"\n",
    "    conv_N_dict[n + \"_conv\"] = parse_params_gflops(conv_path)[\"gflops\"]\n",
    "\n",
    "    # Get Top-1 Accuracy\n",
    "    df = parse_training_results(conv_path + \"/train_eval_results.txt\")\n",
    "    conv_acc_dict[n+ \"_acc\"] = df['test_accuracy_top1'].iloc[-1]\n",
    "\n",
    "print(conv_acc_dict)\n",
    "print(conv_N_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96efa887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   N^2   N  Rand_GFlops  Rand_Top1  Spat_GFlops  Spat_Top1  All_GFlops  \\\n",
      "0   16   4     0.297320    74.3531     0.297320    69.1580    0.331301   \n",
      "1   64   8     0.304764    75.3284     0.304765    72.8105    0.331301   \n",
      "2  144  12     0.311904    75.7564     0.311905    73.9451    0.331301   \n",
      "3  256  16     0.317989    75.0597     0.317990    74.3929    0.331301   \n",
      "4  400  20     0.322562    75.9554     0.322562    74.5123    0.331301   \n",
      "5  576  24     0.324596    75.5374     0.324597    74.7711    0.331301   \n",
      "6  784  28     0.327001    75.1592     0.327002    74.3332    0.331301   \n",
      "\n",
      "   All_Top1  Conv_Top1  Conv_GFlops  \n",
      "0   75.4976    69.9244     0.293683  \n",
      "1   75.4976    69.9244     0.293683  \n",
      "2   75.4976    69.9244     0.293683  \n",
      "3   75.4976    69.9244     0.293683  \n",
      "4   75.4976    69.9244     0.293683  \n",
      "5   75.4976    69.9244     0.293683  \n",
      "6   75.4976    69.9244     0.293683  \n"
     ]
    }
   ],
   "source": [
    "gflops_df = pd.DataFrame({\n",
    "    \"N^2\": list(rand_N_dict.keys()),\n",
    "    \"N\": list(spat_N_dict.keys()),\n",
    "    \"Rand_GFlops\": list(rand_N_dict.values()),\n",
    "    \"Rand_Top1\": list(rand_acc_dict.values()),\n",
    "    \"Spat_GFlops\": list(spat_N_dict.values()),\n",
    "    \"Spat_Top1\": list(spat_acc_dict.values()),\n",
    "    \"All_GFlops\": list(all_N_dict.values()),\n",
    "    \"All_Top1\": list(all_acc_dict.values()), \n",
    "    \"Conv_Top1\": list(conv_acc_dict.values()),\n",
    "    \"Conv_GFlops\": list(conv_N_dict.values())\n",
    "    \n",
    "})\n",
    "print(gflops_df)\n",
    "gflops_df.to_csv(\"csv/N_Samples_Comparison-Oct6.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189e8a9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15183c76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
