training: False
_parameters: OrderedDict()
_buffers: OrderedDict()
_non_persistent_buffers_set: set()
_backward_pre_hooks: OrderedDict()
_backward_hooks: OrderedDict()
_is_full_backward_hook: None
_forward_hooks: OrderedDict()
_forward_hooks_with_kwargs: OrderedDict()
_forward_hooks_always_called: OrderedDict()
_forward_pre_hooks: OrderedDict()
_forward_pre_hooks_with_kwargs: OrderedDict()
_state_dict_hooks: OrderedDict()
_state_dict_pre_hooks: OrderedDict()
_load_state_dict_pre_hooks: OrderedDict()
_load_state_dict_post_hooks: OrderedDict()
_modules: OrderedDict({'features': Sequential(
  (0): InstanceNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
  (1): Conv2d_NN_Attn(
    (shuffle_layer): PixelShuffle(upscale_factor=2)
    (unshuffle_layer): PixelUnshuffle(downscale_factor=2)
    (conv1d_layer): Conv1d(20, 72, kernel_size=(3,), stride=(3,))
    (flatten): Flatten(start_dim=2, end_dim=-1)
    (w_q): Linear(in_features=256, out_features=256, bias=False)
    (w_k): Linear(in_features=256, out_features=256, bias=False)
    (w_v): Linear(in_features=256, out_features=256, bias=False)
    (w_o): Linear(in_features=256, out_features=256, bias=False)
    (pointwise_conv): Conv2d(18, 16, kernel_size=(1, 1), stride=(1, 1))
  )
  (2): ReLU(inplace=True)
  (3): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
  (4): Conv2d_NN_Attn(
    (shuffle_layer): PixelShuffle(upscale_factor=2)
    (unshuffle_layer): PixelUnshuffle(downscale_factor=2)
    (conv1d_layer): Conv1d(72, 136, kernel_size=(3,), stride=(3,))
    (flatten): Flatten(start_dim=2, end_dim=-1)
    (w_q): Linear(in_features=256, out_features=256, bias=False)
    (w_k): Linear(in_features=256, out_features=256, bias=False)
    (w_v): Linear(in_features=256, out_features=256, bias=False)
    (w_o): Linear(in_features=256, out_features=256, bias=False)
    (pointwise_conv): Conv2d(34, 32, kernel_size=(1, 1), stride=(1, 1))
  )
  (5): ReLU(inplace=True)
  (6): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
  (7): Conv2d_NN_Attn(
    (shuffle_layer): PixelShuffle(upscale_factor=2)
    (unshuffle_layer): PixelUnshuffle(downscale_factor=2)
    (conv1d_layer): Conv1d(136, 264, kernel_size=(3,), stride=(3,))
    (flatten): Flatten(start_dim=2, end_dim=-1)
    (w_q): Linear(in_features=256, out_features=256, bias=False)
    (w_k): Linear(in_features=256, out_features=256, bias=False)
    (w_v): Linear(in_features=256, out_features=256, bias=False)
    (w_o): Linear(in_features=256, out_features=256, bias=False)
    (pointwise_conv): Conv2d(66, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (8): ReLU(inplace=True)
), 'pool': AdaptiveAvgPool2d(output_size=(1, 1)), 'flatten': Flatten(start_dim=1, end_dim=-1), 'classifier': Sequential(
  (0): Dropout(p=0.1, inplace=False)
  (1): Linear(in_features=64, out_features=10, bias=True)
)})
args: Namespace(layer='ConvNN_Attn', num_layers=3, channels=[16, 32, 64], K=3, kernel_size=3, sampling_type='all', num_samples=-1, sample_padding=0, num_heads=4, shuffle_pattern='BA', shuffle_scale=2, magnitude_type='similarity', coordinate_encoding=True, dataset='cifar10', data_path='./Data', batch_size=64, num_epochs=50, use_amp=False, clip_grad_norm=None, criterion='CrossEntropy', optimizer='adamw', momentum=0.9, weight_decay=1e-06, lr=0.001, lr_step=20, lr_gamma=0.1, scheduler='step', device='cuda', seed=0, output_dir='./Output/Final_results/ACM/K_Test/ConvNN_Attn_All_Coord_K3', resize=False, num_classes=10, img_size=(3, 32, 32), total_params=934674, trainable_params=934674)
model: All Convolutional Network
name: All Convolutional Network ConvNN_Attn
