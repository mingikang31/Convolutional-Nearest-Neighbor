training: False
_parameters: {}
_buffers: {}
_non_persistent_buffers_set: set()
_backward_pre_hooks: OrderedDict()
_backward_hooks: OrderedDict()
_is_full_backward_hook: None
_forward_hooks: OrderedDict()
_forward_hooks_with_kwargs: OrderedDict()
_forward_hooks_always_called: OrderedDict()
_forward_pre_hooks: OrderedDict()
_forward_pre_hooks_with_kwargs: OrderedDict()
_state_dict_hooks: OrderedDict()
_state_dict_pre_hooks: OrderedDict()
_load_state_dict_pre_hooks: OrderedDict()
_load_state_dict_post_hooks: OrderedDict()
_modules: {'features': Sequential(
  (0): Conv2d_Attn_Branching(
    (branch1): Conv2d_NN_Attn(
      (shuffle_layer): PixelShuffle(upscale_factor=0)
      (unshuffle_layer): PixelUnshuffle(downscale_factor=0)
      (conv1d_layer): Conv1d(3, 3, kernel_size=(9,), stride=(9,), groups=3)
      (pointwise_conv): Conv1d(3, 64, kernel_size=(1,), stride=(1,))
      (flatten): Flatten(start_dim=2, end_dim=-1)
      (dropout): Dropout(p=0.1, inplace=False)
      (w_q): Conv1d(3, 3, kernel_size=(1,), stride=(1,), bias=False)
      (w_k): Conv1d(3, 3, kernel_size=(1,), stride=(1,), bias=False)
      (w_v): Conv1d(3, 3, kernel_size=(1,), stride=(1,), bias=False)
      (w_o): Conv1d(64, 64, kernel_size=(1,), stride=(1,), bias=False)
      (unflatten): Unflatten(dim=2, unflattened_size=torch.Size([32, 32]))
    )
    (pointwise_conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (2): ReLU(inplace=True)
  (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (4): Conv2d_Attn_Branching(
    (branch1): Conv2d_NN_Attn(
      (shuffle_layer): PixelShuffle(upscale_factor=0)
      (unshuffle_layer): PixelUnshuffle(downscale_factor=0)
      (conv1d_layer): Conv1d(64, 64, kernel_size=(9,), stride=(9,), groups=64)
      (pointwise_conv): Conv1d(64, 128, kernel_size=(1,), stride=(1,))
      (flatten): Flatten(start_dim=2, end_dim=-1)
      (dropout): Dropout(p=0.1, inplace=False)
      (w_q): Conv1d(64, 64, kernel_size=(1,), stride=(1,), bias=False)
      (w_k): Conv1d(64, 64, kernel_size=(1,), stride=(1,), bias=False)
      (w_v): Conv1d(64, 64, kernel_size=(1,), stride=(1,), bias=False)
      (w_o): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)
      (unflatten): Unflatten(dim=2, unflattened_size=torch.Size([16, 16]))
    )
    (pointwise_conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
  )
  (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (6): ReLU(inplace=True)
  (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (8): Conv2d_Attn_Branching(
    (branch1): Conv2d_NN_Attn(
      (shuffle_layer): PixelShuffle(upscale_factor=0)
      (unshuffle_layer): PixelUnshuffle(downscale_factor=0)
      (conv1d_layer): Conv1d(128, 128, kernel_size=(9,), stride=(9,), groups=128)
      (pointwise_conv): Conv1d(128, 256, kernel_size=(1,), stride=(1,))
      (flatten): Flatten(start_dim=2, end_dim=-1)
      (dropout): Dropout(p=0.1, inplace=False)
      (w_q): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)
      (w_k): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)
      (w_v): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)
      (w_o): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)
      (unflatten): Unflatten(dim=2, unflattened_size=torch.Size([8, 8]))
    )
    (pointwise_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
  )
  (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (10): ReLU(inplace=True)
  (11): Conv2d_Attn_Branching(
    (branch1): Conv2d_NN_Attn(
      (shuffle_layer): PixelShuffle(upscale_factor=0)
      (unshuffle_layer): PixelUnshuffle(downscale_factor=0)
      (conv1d_layer): Conv1d(256, 256, kernel_size=(9,), stride=(9,), groups=256)
      (pointwise_conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
      (flatten): Flatten(start_dim=2, end_dim=-1)
      (dropout): Dropout(p=0.1, inplace=False)
      (w_q): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)
      (w_k): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)
      (w_v): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)
      (w_o): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)
      (unflatten): Unflatten(dim=2, unflattened_size=torch.Size([8, 8]))
    )
    (pointwise_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
  )
  (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (13): ReLU(inplace=True)
  (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (15): Conv2d_Attn_Branching(
    (branch1): Conv2d_NN_Attn(
      (shuffle_layer): PixelShuffle(upscale_factor=0)
      (unshuffle_layer): PixelUnshuffle(downscale_factor=0)
      (conv1d_layer): Conv1d(256, 256, kernel_size=(9,), stride=(9,), groups=256)
      (pointwise_conv): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
      (flatten): Flatten(start_dim=2, end_dim=-1)
      (dropout): Dropout(p=0.1, inplace=False)
      (w_q): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)
      (w_k): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)
      (w_v): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)
      (w_o): Conv1d(512, 512, kernel_size=(1,), stride=(1,), bias=False)
      (unflatten): Unflatten(dim=2, unflattened_size=torch.Size([4, 4]))
    )
    (pointwise_conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
  )
  (16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (17): ReLU(inplace=True)
  (18): Conv2d_Attn_Branching(
    (branch1): Conv2d_NN_Attn(
      (shuffle_layer): PixelShuffle(upscale_factor=0)
      (unshuffle_layer): PixelUnshuffle(downscale_factor=0)
      (conv1d_layer): Conv1d(512, 512, kernel_size=(9,), stride=(9,), groups=512)
      (pointwise_conv): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
      (flatten): Flatten(start_dim=2, end_dim=-1)
      (dropout): Dropout(p=0.1, inplace=False)
      (w_q): Conv1d(512, 512, kernel_size=(1,), stride=(1,), bias=False)
      (w_k): Conv1d(512, 512, kernel_size=(1,), stride=(1,), bias=False)
      (w_v): Conv1d(512, 512, kernel_size=(1,), stride=(1,), bias=False)
      (w_o): Conv1d(512, 512, kernel_size=(1,), stride=(1,), bias=False)
      (unflatten): Unflatten(dim=2, unflattened_size=torch.Size([4, 4]))
    )
    (pointwise_conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
  )
  (19): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (20): ReLU(inplace=True)
  (21): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (22): Conv2d_Attn_Branching(
    (branch1): Conv2d_NN_Attn(
      (shuffle_layer): PixelShuffle(upscale_factor=0)
      (unshuffle_layer): PixelUnshuffle(downscale_factor=0)
      (conv1d_layer): Conv1d(512, 512, kernel_size=(9,), stride=(9,), groups=512)
      (pointwise_conv): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
      (flatten): Flatten(start_dim=2, end_dim=-1)
      (dropout): Dropout(p=0.1, inplace=False)
      (w_q): Conv1d(512, 512, kernel_size=(1,), stride=(1,), bias=False)
      (w_k): Conv1d(512, 512, kernel_size=(1,), stride=(1,), bias=False)
      (w_v): Conv1d(512, 512, kernel_size=(1,), stride=(1,), bias=False)
      (w_o): Conv1d(512, 512, kernel_size=(1,), stride=(1,), bias=False)
      (unflatten): Unflatten(dim=2, unflattened_size=torch.Size([2, 2]))
    )
    (pointwise_conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
  )
  (23): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (24): ReLU(inplace=True)
  (25): Conv2d_Attn_Branching(
    (branch1): Conv2d_NN_Attn(
      (shuffle_layer): PixelShuffle(upscale_factor=0)
      (unshuffle_layer): PixelUnshuffle(downscale_factor=0)
      (conv1d_layer): Conv1d(512, 512, kernel_size=(9,), stride=(9,), groups=512)
      (pointwise_conv): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
      (flatten): Flatten(start_dim=2, end_dim=-1)
      (dropout): Dropout(p=0.1, inplace=False)
      (w_q): Conv1d(512, 512, kernel_size=(1,), stride=(1,), bias=False)
      (w_k): Conv1d(512, 512, kernel_size=(1,), stride=(1,), bias=False)
      (w_v): Conv1d(512, 512, kernel_size=(1,), stride=(1,), bias=False)
      (w_o): Conv1d(512, 512, kernel_size=(1,), stride=(1,), bias=False)
      (unflatten): Unflatten(dim=2, unflattened_size=torch.Size([2, 2]))
    )
    (pointwise_conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
  )
  (26): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (27): ReLU(inplace=True)
  (28): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
), 'avgpool': AdaptiveAvgPool2d(output_size=(7, 7)), 'classifier': Sequential(
  (0): Linear(in_features=25088, out_features=4096, bias=True)
  (1): ReLU(inplace=True)
  (2): Dropout(p=0.5, inplace=False)
  (3): Linear(in_features=4096, out_features=4096, bias=True)
  (4): ReLU(inplace=True)
  (5): Dropout(p=0.5, inplace=False)
  (6): Linear(in_features=4096, out_features=100, bias=True)
)}
args: Namespace(model='vgg11', layer='Branching_Attn', K=9, kernel_size=3, padding=1, sampling_type='all', num_samples=-1, sample_padding=0, attention_dropout=0.1, shuffle_pattern='NA', shuffle_scale=0, magnitude_type='cosine', similarity_type='Col', aggregation_type='Col', lambda_param=0.5, branch_ratio=1.0, dataset='cifar100', resize=False, augment=False, noise=0.0, data_path='./Data', batch_size=128, num_epochs=100, use_amp=False, clip_grad_norm=1.0, criterion='CrossEntropy', optimizer='sgd', momentum=0.9, weight_decay=0.0005, lr=0.05, lr_step=20, lr_gamma=0.1, scheduler='cosine', device='cuda', seed=42, output_dir='./Output/TEST-Oct25-Jupyter/VGG11/BranchingConvNNAttn_K9_col_col_br1000_s42', test_only=False, num_classes=100, img_size=(3, 32, 32), total_params=126227421, trainable_params=126227421)
name: vgg11 - Branching_Attn
