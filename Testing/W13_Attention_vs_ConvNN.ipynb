{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ef95d79",
   "metadata": {},
   "source": [
    "# Testing With Attention vs ConvnN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a4f8612",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "import torchvision.transforms as T \n",
    "from torch.optim import AdamW\n",
    "from torchvision.datasets.mnist import MNIST \n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62346bb6",
   "metadata": {},
   "source": [
    "### i. Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a467ab41",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module): \n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.d_k = d_model // num_heads # dimension of each head\n",
    "        \n",
    "        self.W_q = nn.Linear(d_model, d_model)\n",
    "        self.W_k = nn.Linear(d_model, d_model)\n",
    "        self.W_v = nn.Linear(d_model, d_model)\n",
    "        self.W_o = nn.Linear(d_model, d_model)        \n",
    "    \n",
    "    def scaled_dot_product_attention(self, Q, K, V, mask=None):\n",
    "        attn_scores = torch.matmul(Q, K.transpose(-2, -1)) / np.sqrt(self.d_k)\n",
    "        \n",
    "        if mask is not None:\n",
    "            attn_scores = attn_scores.masked_fill(mask == 0, -1e9)\n",
    "        \n",
    "        attn_probs = torch.softmax(attn_scores, dim=-1)\n",
    "        output = torch.matmul(attn_probs, V)\n",
    "        return output, attn_probs\n",
    "    \n",
    "    def split_head(self, x): \n",
    "        batch_size, seq_length, d_model = x.size()\n",
    "        return x.view(batch_size, seq_length, self.num_heads, self.d_k).transpose(1, 2) # (B, num_heads, seq_length, d_k)\n",
    "        \n",
    "    def combine_heads(self, x): \n",
    "        batch_size, _, seq_length, d_k = x.size()\n",
    "        return x.transpose(1, 2).contiguous().view(batch_size, seq_length, self.d_model) \n",
    "    \n",
    "    def forward(self, x, mask=None):\n",
    "        q = self.split_head(self.W_q(x)) # (B, num_heads, seq_length, d_k)\n",
    "        k = self.split_head(self.W_k(x))\n",
    "        v = self.split_head(self.W_v(x))\n",
    "        \n",
    "        attn_output, _ = self.scaled_dot_product_attention(q, k, v, mask) # (B, num_heads, seq_length, d_k)\n",
    "        output = self.W_o(self.combine_heads(attn_output)) # (B, seq_length, d_model)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7cd08d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 32, 3])\n"
     ]
    }
   ],
   "source": [
    "ex = torch.randn(64, 32, 3) # (B, seq_length, d_model)\n",
    "mha = MultiHeadAttention(d_model=3, num_heads=3)\n",
    "print(mha(ex).shape) # (B, seq_length, d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f15620b",
   "metadata": {},
   "source": [
    "### ii. ConvNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "987940b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Conv1d\n",
    "class Conv1d_NN(nn.Module): \n",
    "    \"\"\"\n",
    "    Convolution 1D Nearest Neighbor Layer\n",
    "    \n",
    "    Attributes:\n",
    "        in_channels (int): Number of input channels.\n",
    "        out_channels (int): Number of output channels.\n",
    "        K (int): Number of Nearest Neighbors for consideration.\n",
    "        stride (int): Stride size.\n",
    "        padding (int): Padding size.\n",
    "        shuffle_pattern (str): Shuffle pattern.\n",
    "        shuffle_scale (int): Shuffle scale factor.\n",
    "        samples (int/str): Number of samples to consider.\n",
    "        magnitude_type (str): Distance or Similarity.\n",
    "        \n",
    "    Notes:\n",
    "        - K must be same as stride. K == stride.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 in_channels, \n",
    "                 out_channels, \n",
    "                 K=3, \n",
    "                 stride=3, \n",
    "                 padding=0, \n",
    "                 shuffle_pattern='N/A', \n",
    "                 shuffle_scale=2, \n",
    "                 samples='all', \n",
    "                 magnitude_type='similarity'\n",
    "                 ): \n",
    "        \n",
    "        \"\"\"\n",
    "        Initializes the Conv1d_NN module.\n",
    "        \n",
    "        Parameters:\n",
    "            in_channels (int): Number of input channels.\n",
    "            out_channels (int): Number of output channels.\n",
    "            K (int): Number of Nearest Neighbors for consideration.\n",
    "            stride (int): Stride size.\n",
    "            padding (int): Padding size.\n",
    "            shuffle_pattern (str): Shuffle pattern: \"B\", \"A\", \"BA\".\n",
    "            shuffle_scale (int): Shuffle scale factor.\n",
    "            samples (int/str): Number of samples to consider.\n",
    "            magnitude_type (str): Distance or Similarity.\n",
    "        \"\"\"\n",
    "        \n",
    "        super(Conv1d_NN, self).__init__()\n",
    "        \n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.K = K\n",
    "        self.stride = stride \n",
    "        self.padding = padding\n",
    "        self.shuffle_pattern = shuffle_pattern \n",
    "        self.shuffle_scale = shuffle_scale\n",
    "        self.samples = int(samples) if samples != 'all' else samples \n",
    "        self.magnitude_type = magnitude_type \n",
    "        self.maximum = True if self.magnitude_type == 'similarity' else False\n",
    "        \n",
    "        # Unshuffle layer \n",
    "        self.unshuffle_layer = PixelUnshuffle1D(downscale_factor=self.shuffle_scale)\n",
    "        \n",
    "        # Shuffle Layer \n",
    "        self.shuffle_layer = PixelShuffle1D(upscale_factor=self.shuffle_scale)\n",
    "        \n",
    "        # Channels for Conv1d Layer\n",
    "        self.in_channels = in_channels * shuffle_scale if self.shuffle_pattern in [\"BA\", \"B\"] else in_channels\n",
    "        self.out_channels = out_channels * shuffle_scale if self.shuffle_pattern in [\"BA\", \"A\"] else out_channels\n",
    "\n",
    "        # Conv1d Layer \n",
    "        self.conv1d_layer = Conv1d(in_channels=self.in_channels, \n",
    "                                    out_channels=self.out_channels, \n",
    "                                    kernel_size=self.K, \n",
    "                                    stride=self.stride, \n",
    "                                    padding=self.padding)\n",
    "\n",
    "    def forward(self, x): \n",
    "        # Consider all samples \n",
    "        if self.samples == 'all': \n",
    "            # Unshuffle Layer \n",
    "            if self.shuffle_pattern in [\"B\", \"BA\"]:\n",
    "                x1 = self.unshuffle_layer(x)\n",
    "            else:\n",
    "                x1 = x\n",
    "            \n",
    "            # Calculate Distance/Similarity Matrix + Prime Vmap 2D\n",
    "            if self.magnitude_type == 'distance': \n",
    "                matrix_magnitude = self._calculate_distance_matrix(x1)\n",
    "            elif self.magnitude_type == 'similarity':\n",
    "                matrix_magnitude = self._calculate_similarity_matrix(x1)\n",
    "                \n",
    "            prime_2d = self._prime(x1, matrix_magnitude, self.K, self.maximum) \n",
    "            \n",
    "            # Conv1d Layer\n",
    "            x2 = self.conv1d_layer(prime_2d)\n",
    "            \n",
    "            \n",
    "            # Shuffle Layer \n",
    "            if self.shuffle_pattern in [\"A\", \"BA\"]:\n",
    "                x3 = self.shuffle_layer(x2)\n",
    "            else:\n",
    "                x3 = x2\n",
    "            \n",
    "            return x3\n",
    "        \n",
    "        # Consider N samples\n",
    "        else: \n",
    "            # Unshuffle Layer \n",
    "            if self.shuffle_pattern in [\"B\", \"BA\"]:\n",
    "                x1 = self.unshuffle_layer(x)\n",
    "            else:\n",
    "                x1 = x\n",
    "                \n",
    "            # Calculate Distance/Similarity Matrix + Prime       \n",
    "            rand_idx = torch.randperm(x1.shape[2], device=x1.device)[:self.samples]\n",
    "            \n",
    "            x1_sample = x1[:, :, rand_idx]\n",
    "            \n",
    "            if self.magnitude_type == 'distance':\n",
    "                matrix_magnitude = self._calculate_distance_matrix_N(x1, x1_sample)\n",
    "            elif self.magnitude_type == 'similarity':\n",
    "                matrix_magnitude = self._calculate_similarity_matrix_N(x1, x1_sample)\n",
    "                \n",
    "            range_idx = torch.arange(len(rand_idx), device=x1.device)\n",
    "                \n",
    "        \n",
    "            if self.magnitude_type == 'distance':\n",
    "                matrix_magnitude[:, rand_idx, range_idx] = float('inf') \n",
    "            elif self.magnitude_type == 'similarity':\n",
    "                matrix_magnitude[:, rand_idx, range_idx] = float('-inf')\n",
    "                \n",
    "            \n",
    "            prime = self._prime_N(x1, matrix_magnitude, self.K, rand_idx, self.maximum)\n",
    "            \n",
    "            # Conv1d Layer\n",
    "            x2 = self.conv1d_layer(prime)\n",
    "            \n",
    "            # Shuffle Layer\n",
    "            if self.shuffle_pattern in [\"A\", \"BA\"]:\n",
    "                x3 = self.shuffle_layer(x2)\n",
    "            else:\n",
    "                x3 = x2\n",
    "            \n",
    "            return x3\n",
    "    \n",
    "    \n",
    "    def _calculate_distance_matrix(self, matrix, sqrt=False):\n",
    "        norm_squared = torch.sum(matrix ** 2, dim=1, keepdim=True)\n",
    "        dot_product = torch.bmm(matrix.transpose(2, 1), matrix)\n",
    "        dist_matrix = norm_squared + norm_squared.transpose(2, 1) - 2 * dot_product\n",
    "        \n",
    "        dist_matrix = torch.clamp(dist_matrix, min=0) # remove negative values\n",
    "        \n",
    "        if sqrt:\n",
    "            dist_matrix = torch.sqrt(dist_matrix)\n",
    "        return dist_matrix\n",
    "    \n",
    "    def _calculate_distance_matrix_N(self, matrix, matrix_sample, sqrt=False):\n",
    "        norm_squared = torch.sum(matrix ** 2, dim=1, keepdim=True).permute(0, 2, 1)\n",
    "        norm_squared_sample = torch.sum(matrix_sample ** 2, dim=1, keepdim=True).transpose(2, 1).permute(0, 2, 1)\n",
    "        \n",
    "        dot_product = torch.bmm(matrix.transpose(2, 1), matrix_sample)\n",
    "        \n",
    "        dist_matrix = norm_squared + norm_squared_sample - 2 * dot_product\n",
    "        \n",
    "        dist_matrix = torch.clamp(dist_matrix, min=0) # remove negative values\n",
    "        \n",
    "        if sqrt:\n",
    "            dist_matrix = torch.sqrt(dist_matrix)\n",
    "        return dist_matrix\n",
    "    \n",
    "    \n",
    "    def _calculate_similarity_matrix(self, matrix):\n",
    "        norm_matrix = F.normalize(matrix, p=2, dim=1) # p=2 (L2 Norm - Euclidean Distance), dim=1 (across the channels)\n",
    "        similarity_matrix = torch.bmm(norm_matrix.transpose(2, 1), norm_matrix)\n",
    "        return similarity_matrix\n",
    "    \n",
    "    def _calculate_similarity_matrix_N(self, matrix, matrix_sample):\n",
    "        norm_matrix = F.normalize(matrix, p=2, dim=1) # p=2 (L2 Norm - Euclidean Distance), dim=1 (across the channels)\n",
    "        norm_sample = F.normalize(matrix_sample, p=2, dim=1)\n",
    "        similarity_matrix = torch.bmm(norm_matrix.transpose(2, 1), norm_sample)\n",
    "        return similarity_matrix\n",
    "\n",
    "    def _prime(self, matrix, magnitude_matrix, K, maximum):\n",
    "        b, c, t = matrix.shape\n",
    "        # Get top-K indices: shape [b, t, K]\n",
    "        _, topk_indices = torch.topk(magnitude_matrix, k=K, dim=2, largest=maximum)\n",
    "        \n",
    "        # Expand indices to add channel dimension: [b, 1, t, K] then expand to [b, c, t, K]\n",
    "        topk_indices_exp = topk_indices.unsqueeze(1).expand(b, c, t, K)\n",
    "        \n",
    "        # Unsqueeze matrix and expand so that the gathered dimension has size K.\n",
    "        # matrix.unsqueeze(-1) yields shape [b, c, t, 1]\n",
    "        # Then expand to [b, c, t, K] and force contiguous memory.\n",
    "        matrix_expanded = matrix.unsqueeze(-1).expand(b, c, t, K).contiguous()\n",
    "        \n",
    "        # Gather along the token dimension (dim=2) using the expanded indices.\n",
    "        prime = torch.gather(matrix_expanded, dim=2, index=topk_indices_exp)\n",
    "        \n",
    "        # Flatten the token and neighbor dimensions: [b, c, t*K]\n",
    "        prime = prime.view(b, c, -1)\n",
    "        return prime\n",
    "    \n",
    "    def _prime_N(self, matrix, magnitude_matrix, K, rand_idx, maximum):\n",
    "        b, c, t = matrix.shape\n",
    "\n",
    "        # Get top-(K-1) indices from the magnitude matrix; shape: [b, t, K-1]\n",
    "        _, topk_indices = torch.topk(magnitude_matrix, k=K - 1, dim=2, largest=maximum)\n",
    "        tk = topk_indices.shape[-1]\n",
    "        assert K == tk + 1, \"Error: K must be same as tk + 1. K == tk + 1.\"\n",
    "\n",
    "        # Map indices from the sampled space to the full token indices using rand_idx.\n",
    "        # mapped_tensor will have shape: [b, t, K-1]\n",
    "        mapped_tensor = rand_idx[topk_indices]\n",
    "\n",
    "        # Create self indices for each token; shape: [1, t, 1] then expand to [b, t, 1]\n",
    "        token_indices = torch.arange(t, device=matrix.device).view(1, t, 1).expand(b, t, 1)\n",
    "\n",
    "        # Concatenate self index with neighbor indices to form final indices; shape: [b, t, K]\n",
    "        final_indices = torch.cat([token_indices, mapped_tensor], dim=2)\n",
    "\n",
    "        # Expand final_indices to include the channel dimension; result shape: [b, c, t, K]\n",
    "        indices_expanded = final_indices.unsqueeze(1).expand(b, c, t, K)\n",
    "\n",
    "        # Expand matrix to shape [b, c, t, 1] and then to [b, c, t, K] (ensuring contiguous memory)\n",
    "        matrix_expanded = matrix.unsqueeze(-1).expand(b, c, t, K).contiguous()\n",
    "\n",
    "        # Gather neighbor features along the token dimension (dim=2)\n",
    "        prime = torch.gather(matrix_expanded, dim=2, index=indices_expanded)  # shape: [b, c, t, K]\n",
    "\n",
    "        # Flatten the token and neighbor dimensions into one: [b, c, t*K]\n",
    "        prime = prime.view(b, c, -1)\n",
    "        return prime\n",
    "    \n",
    "class PixelShuffle1D(nn.Module): \n",
    "    \"\"\"\n",
    "    1D Pixel Shuffle Layer for Convolutional Neural Networks.\n",
    "    \n",
    "    Attributes: \n",
    "        upscale_factor (int): Upscale factor for pixel shuffle. \n",
    "        \n",
    "    Notes:\n",
    "        Input's channel size must be divisible by the upscale factor. \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, upscale_factor):\n",
    "        \"\"\" \n",
    "        Initializes the PixelShuffle1D module.\n",
    "        \n",
    "        Parameters:\n",
    "            upscale_factor (int): Upscale factor for pixel shuffle.\n",
    "        \"\"\"\n",
    "        super(PixelShuffle1D, self).__init__()\n",
    "        \n",
    "        self.upscale_factor = upscale_factor\n",
    "\n",
    "    def forward(self, x): \n",
    "        batch_size, channel_len, token_len = x.shape[0], x.shape[1], x.shape[2]\n",
    "        \n",
    "        output_channel_len = channel_len / self.upscale_factor \n",
    "        if output_channel_len.is_integer() == False: \n",
    "            raise ValueError('Input channel length must be divisible by upscale factor')\n",
    "        output_channel_len = int(output_channel_len)\n",
    "        \n",
    "        output_token_len = int(token_len * self.upscale_factor)\n",
    "        \n",
    "        x = torch.reshape(x, (batch_size, output_channel_len, output_token_len)).contiguous()\n",
    "        \n",
    "        return x \n",
    "   \n",
    "class PixelUnshuffle1D(nn.Module):  \n",
    "    \"\"\"\n",
    "    1D Pixel Unshuffle Layer for Convolutional Neural Networks.\n",
    "    \n",
    "    Attributes:\n",
    "        downscale_factor (int): Downscale factor for pixel unshuffle.\n",
    "        \n",
    "    Note:\n",
    "        Input's token size must be divisible by the downscale factor\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, downscale_factor):\n",
    "        \"\"\"\n",
    "        Intializes the PixelUnshuffle1D module.\n",
    "        \n",
    "        Parameters:\n",
    "            downscale_factor (int): Downscale factor for pixel unshuffle.\n",
    "        \"\"\"\n",
    "        super(PixelUnshuffle1D, self).__init__()\n",
    "        \n",
    "        self.downscale_factor = downscale_factor\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        channel_len = x.shape[1]\n",
    "        token_len = x.shape[2]\n",
    "\n",
    "        output_channel_len = int(channel_len * self.downscale_factor)\n",
    "        output_token_len = token_len / self.downscale_factor\n",
    "        \n",
    "        if output_token_len.is_integer() == False:\n",
    "            raise ValueError('Input token length must be divisible by downscale factor')\n",
    "        output_token_len = int(output_token_len)\n",
    "        \n",
    "        x = torch.reshape(x, (batch_size, output_channel_len, output_token_len)).contiguous()\n",
    "        \n",
    "        return x \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170c1a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 32])\n",
      "reshaped:  torch.Size([64, 32, 3])\n"
     ]
    }
   ],
   "source": [
    "ex = torch.randn(64, 32, 3) # (B, seq_length, d_model)\n",
    "ex = ex.permute(0, 2, 1) # (B, d_model, seq_length) = (B, C, T)\n",
    "convnn = Conv1d_NN(in_channels=3, out_channels=3, K=3, stride=3, padding=0, shuffle_pattern='N/A', shuffle_scale=1, samples='all', magnitude_type='similarity')\n",
    "print(convnn(ex).shape) # (B, seq_length, d_model)\n",
    "print(\"reshaped: \", convnn(ex).permute(0, 2, 1).shape) # (B, d_model, seq_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f8fbc1",
   "metadata": {},
   "source": [
    "### Final Comparison "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bd228fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 32, 3])\n"
     ]
    }
   ],
   "source": [
    "ex = torch.randn(64, 32, 3) # (B, seq_length, d_model)\n",
    "mha = MultiHeadAttention(d_model=3, num_heads=3)\n",
    "print(mha(ex).shape) # (B, seq_length, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ba3da3dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 32])\n",
      "reshaped:  torch.Size([64, 32, 3])\n"
     ]
    }
   ],
   "source": [
    "ex = torch.randn(64, 32, 3) # (B, seq_length, d_model)\n",
    "ex = ex.permute(0, 2, 1) # (B, d_model, seq_length) = (B, C, T)\n",
    "convnn = Conv1d_NN(in_channels=3, out_channels=3, K=3, stride=3, padding=0, shuffle_pattern='N/A', shuffle_scale=1, samples='all', magnitude_type='similarity')\n",
    "print(convnn(ex).shape) # (B, seq_length, d_model)\n",
    "print(\"reshaped: \", convnn(ex).permute(0, 2, 1).shape) # (B, d_model, seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e50c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention vs CNN\n",
    "# B = B \n",
    "# seq_length = H * W\n",
    "# d_model = C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc8ee4f",
   "metadata": {},
   "source": [
    "# Experiment \n",
    "- Vision Transformer with Attention, ConvNN, Conv2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e423a943",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
