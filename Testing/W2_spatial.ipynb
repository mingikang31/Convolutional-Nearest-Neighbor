{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ConvNN Spatial Sampling Performance Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Spatial Sampling method's performance is drastically poor, need to figure out why and what is going on. \n",
    "- Try to use the same random seed for all tests \n",
    "- Try n = n for sample, this should be same as doing all samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mingikang/miniforge3/envs/ML/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Torch\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim \n",
    "\n",
    "\n",
    "\n",
    "# Train + Data \n",
    "import sys \n",
    "sys.path.append('../2D_Modules')\n",
    "from data import MNIST, FashionMNIST, CIFAR10\n",
    "from train import train_model, evaluate_accuracy \n",
    "from pixelshuffle import * \n",
    "from Conv1d_NN_spatial import *\n",
    "from Conv1d_NN import * \n",
    "from utils import * \n",
    "\n",
    "\n",
    "# other\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. 2D Testing - Performance Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i. Conv2d_NN_spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2d_NN_spatial(nn.Module): \n",
    "   def __init__(self, in_channels, out_channels, K=3, stride=3, padding=0, shuffle_pattern=\"N/A\", shuffle_scale=2, samples=3, sample_padding=0, magnitude_type=\"distance\"): \n",
    "      super().__init__()\n",
    "      ### in_channels + out_channels must be shuffle_scale**2\n",
    "      self.in_channels = in_channels\n",
    "      self.out_channels = out_channels\n",
    "      self.K = K\n",
    "      self.stride = stride\n",
    "      self.padding = padding\n",
    "      self.shuffle_pattern = shuffle_pattern\n",
    "      self.shuffle_scale = shuffle_scale\n",
    "      self.samples = int(samples)\n",
    "      self.sample_padding = sample_padding\n",
    "      self.magnitude_type = magnitude_type\n",
    "      \n",
    "      self.upscale = PixelShuffle1D(upscale_factor=self.shuffle_scale)\n",
    "      \n",
    "      self.downscale = PixelUnshuffle1D(downscale_factor=self.shuffle_scale)\n",
    "      \n",
    "      self.Conv1d_NN_spatial = Conv1d_NN_spatial(in_channels=self.in_channels,\n",
    "                                 out_channels=self.out_channels,\n",
    "                                 K=self.K,\n",
    "                                 stride=self.stride,\n",
    "                                 padding=self.padding,\n",
    "                                 shuffle_pattern=self.shuffle_pattern,\n",
    "                                 shuffle_scale=self.shuffle_scale, \n",
    "                                 samples=self.samples, \n",
    "                                 magnitude_type=self.magnitude_type\n",
    "                                 )\n",
    "                                 \n",
    "      \n",
    "      \n",
    "      self.flatten = nn.Flatten(start_dim=2)\n",
    "      \n",
    "      \n",
    "   def forward(self, x): \n",
    "      # Ex. Original Size (32, 1, 28, 28) \n",
    "      first_time = time.time()\n",
    "      \n",
    "      start_time = time.time()\n",
    "\n",
    "      x_ind = torch.round(torch.linspace(0 + self.sample_padding, x.shape[2] - self.sample_padding - 1, self.samples)).to(torch.int)\n",
    "      y_ind = torch.round(torch.linspace(0 + self.sample_padding, x.shape[3] - self.sample_padding - 1, self.samples)).to(torch.int)\n",
    "      x_grid, y_grid = torch.meshgrid(x_ind, y_ind, indexing='ij')\n",
    "      x_sample = torch.flatten(x[:, :, x_grid, y_grid], 2) # shape [32, 1, 25] if sample == 5 \n",
    "      \n",
    "      end_time = time.time()\n",
    "      print(f\"x_sample grid : {end_time - start_time}\")\n",
    "      \n",
    "      \n",
    "      # Flatten Layer : size (32, 1, 784)\n",
    "      x1 = self.flatten(x)\n",
    "      \n",
    "      start_time = time.time()\n",
    "      # Conv1d_NN Layer\n",
    "      x2 = self.Conv1d_NN_spatial(x1, x_sample)\n",
    "      end_time = time.time()\n",
    "      print(f\"Conv1d_NN_spatial : {end_time - start_time}\")\n",
    "      \n",
    "      # Unflatten Layer \n",
    "      unflatten = nn.Unflatten(dim=2, unflattened_size=x.shape[2:])\n",
    "      x3 = unflatten(x2)\n",
    "\n",
    "      final_time = time.time()\n",
    "      print(f\"Final Time : {final_time - first_time}\")\n",
    "      return x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  torch.Size([32, 1, 28, 28])\n",
      "x_sample grid : 0.0007679462432861328\n",
      "Conv1d_NN_spatial : 0.0058858394622802734\n",
      "Final Time : 0.006787776947021484\n",
      "Output:  torch.Size([32, 3, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "ex = torch.rand(32, 1, 28, 28) \n",
    "print(\"Input: \", ex.shape)\n",
    "\n",
    "conv2d_nn_spatial = Conv2d_NN_spatial(in_channels=1, out_channels=3, K=3, stride=3, padding=0, shuffle_pattern=\"N/A\", shuffle_scale=2, samples=5, sample_padding= 3, magnitude_type=\"similarity\")\n",
    "output = conv2d_nn_spatial(ex)\n",
    "print(\"Output: \", output.shape) # [32, 3, 784]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## i. Conv2d_NN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2d_NN(nn.Module): \n",
    "   def __init__(self, in_channels, out_channels, K=3, stride=3, padding=0, shuffle_pattern=\"N/A\", shuffle_scale=2, samples=\"all\", magnitude_type=\"distance\"): \n",
    "      super().__init__()\n",
    "      ### in_channels + out_channels must be shuffle_scale**2\n",
    "      self.in_channels = in_channels\n",
    "      self.out_channels = out_channels\n",
    "      self.K = K\n",
    "      self.stride = stride\n",
    "      self.padding = padding\n",
    "      self.shuffle_pattern = shuffle_pattern\n",
    "      self.shuffle_scale = shuffle_scale\n",
    "      self.samples = samples\n",
    "      self.magnitude_type = magnitude_type\n",
    "      \n",
    "      self.upscale = PixelShuffle1D(upscale_factor=self.shuffle_scale)\n",
    "      \n",
    "      self.downscale = PixelUnshuffle1D(downscale_factor=self.shuffle_scale)\n",
    "      \n",
    "      self.Conv1d_NN = Conv1d_NN(in_channels=self.in_channels * shuffle_scale **2,\n",
    "                                 out_channels=self.out_channels * shuffle_scale **2,\n",
    "                                 K=self.K,\n",
    "                                 stride=self.stride,\n",
    "                                 padding=self.padding,\n",
    "                                 shuffle_pattern=self.shuffle_pattern,\n",
    "                                 shuffle_scale=self.shuffle_scale, \n",
    "                                 samples=self.samples, \n",
    "                                 magnitude_type=self.magnitude_type\n",
    "                                 )\n",
    "                                 \n",
    "      \n",
    "      \n",
    "      self.flatten = nn.Flatten(start_dim=2)\n",
    "      \n",
    "      \n",
    "   def forward(self, x): \n",
    "      # Ex. Original Size (32, 1, 28, 28) \n",
    "      \n",
    "      first_time = time.time()\n",
    "      # Unshuffle Layer \n",
    "      # Ex. (32, 16, 7, 7) if upscale_factor = 4\n",
    "      x1 = nn.functional.pixel_unshuffle(x, self.shuffle_scale)\n",
    "\n",
    "      # print(\"Unshuffle: \", x1.shape)\n",
    "      \n",
    "      # Flatten Layer \n",
    "      # Ex. (32, 16, 49) \n",
    "      x2 = self.flatten(x1)\n",
    "      # print(\"Flatten: \", x2.shape)\n",
    "      \n",
    "      # Conv1d_NN Layer\n",
    "      # Ex. (32, 16, 49) \n",
    "      x3 = self.Conv1d_NN(x2)  \n",
    "      # print(\"Conv1d_NN: \", x3.shape)\n",
    "      \n",
    "      # Unflatten Layer \n",
    "      # Ex. (32, 16, 7, 7)\n",
    "      unflatten = nn.Unflatten(dim=2, unflattened_size=x1.shape[2:])\n",
    "      x4 = unflatten(x3)\n",
    "      # print(\"Unflatten: \", x4.shape)\n",
    "      \n",
    "      # Shuffle Layer \n",
    "      # Ex. (32, 16, 28, 28)\n",
    "      x5 = nn.functional.pixel_shuffle(x4, self.shuffle_scale)\n",
    "      # print(\"Shuffle: \", x5.shape)\n",
    "      \n",
    "      final_time = time.time()\n",
    "      print(f\"Final Time : {final_time - first_time}\")\n",
    "      return x5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  torch.Size([32, 1, 28, 28])\n",
      "Final Time : 0.011232137680053711\n",
      "Output:  torch.Size([32, 3, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "ex = torch.rand(32, 1, 28, 28) \n",
    "print(\"Input: \", ex.shape)\n",
    "\n",
    "conv2d_nn = Conv2d_NN(in_channels=1, out_channels=3, K=3, stride=3, padding=0, shuffle_pattern=\"N/A\", shuffle_scale=2, samples=5, magnitude_type=\"similarity\")\n",
    "output = conv2d_nn(ex)\n",
    "print(\"Output: \", output.shape) # [32, 3, 784]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Conv1d_NN_spatial(nn.Module): \n",
    "    def __init__(self, in_channels, out_channels, K=3, stride=3, padding=0, \n",
    "                 shuffle_pattern='N/A', shuffle_scale=2, \n",
    "                 samples='all', \n",
    "                 magnitude_type='distance'): \n",
    "        \n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.K = K\n",
    "        self.stride = stride \n",
    "        self.padding = padding\n",
    "        self.shuffle_pattern = shuffle_pattern \n",
    "        self.shuffle_scale = shuffle_scale\n",
    "        \n",
    "        self.samples = int(samples) if samples != 'all' else samples # Number of samples to consider\n",
    "        self.magnitude_type = magnitude_type # Nearest Neighbor based on Distance or Similarity \n",
    "        self.maximum = True if self.magnitude_type == 'similarity' else False # Minimum or Maximum for Distance or Similarity\n",
    "        \n",
    "        # Unshuffle layer \n",
    "        self.unshuffle_layer = PixelUnshuffle1D(downscale_factor=self.shuffle_scale)\n",
    "        \n",
    "        # Shuffle Layer \n",
    "        self.shuffle_layer = PixelShuffle1D(upscale_factor=self.shuffle_scale)\n",
    "                \n",
    "        # Conv1d Layer\n",
    "        self.in_channels = in_channels * shuffle_scale if self.shuffle_pattern in [\"BA\", \"B\"] else in_channels\n",
    "        self.out_channels = out_channels * shuffle_scale if self.shuffle_pattern in [\"BA\", \"A\"] else out_channels\n",
    "\n",
    "        # Conv1d Layer \n",
    "        self.conv1d_layer = nn.Conv1d(in_channels=self.in_channels, \n",
    "                                      out_channels=self.out_channels, \n",
    "                                      kernel_size=self.K, \n",
    "                                      stride=self.stride, \n",
    "                                      padding=self.padding)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x, y): \n",
    "\n",
    "        # Unshuffle Layer \n",
    "        if self.shuffle_pattern in [\"B\", \"BA\"]:\n",
    "            x1 = self.unshuffle_layer(x)\n",
    "        else:\n",
    "            x1 = x\n",
    "            \n",
    "        if self.magnitude_type == 'distance':\n",
    "            matrix_magnitude = self.calculate_distance_matrix_N(x1, y)\n",
    "        elif self.magnitude_type == 'similarity':\n",
    "            matrix_magnitude = self.calculate_similarity_matrix_N(x1, y)        \n",
    "        \n",
    "        prime = self.prime_vmap_2d_N(x1, matrix_magnitude, self.K, self.maximum)\n",
    "        \n",
    "        # Conv1d Layer\n",
    "        x2 = self.conv1d_layer(prime)\n",
    "        \n",
    "        # ReLU Activation\n",
    "        x3 = self.relu(x2)\n",
    "        \n",
    "        # Shuffle Layer\n",
    "        if self.shuffle_pattern in [\"A\", \"BA\"]:\n",
    "            x4 = self.shuffle_layer(x3)\n",
    "        else:\n",
    "            x4 = x3\n",
    "        \n",
    "        return x4\n",
    "        \n",
    "    ### N Samples ### \n",
    "    '''Distance Matrix Calculations for N Sample'''\n",
    "    @staticmethod \n",
    "    def calculate_distance_matrix_N(matrix, matrix_sample):\n",
    "        '''Calculate distance matrix between two input matrices''' \n",
    "        norm_squared = torch.sum(matrix ** 2, dim=1, keepdim=True).permute(0, 2, 1)\n",
    "        norm_squared_sample = torch.sum(matrix_sample ** 2, dim=1, keepdim=True).transpose(2, 1).permute(0, 2, 1)\n",
    "        dot_product = torch.bmm(matrix.transpose(2, 1), matrix_sample)\n",
    "        dist_matrix = norm_squared + norm_squared_sample - 2 * dot_product\n",
    "        return torch.sqrt(dist_matrix)\n",
    "        \n",
    "    '''Similarity Matrix Calculations for N Sample'''\n",
    "    @staticmethod\n",
    "    def calculate_similarity_matrix_N(matrix, matrix_sample): \n",
    "        normalized_matrix = F.normalize(matrix, p=2, dim=1) # p=2 (L2 Norm - Euclidean Distance), dim=1 (across the channels)\n",
    "        normalized_matrix_sample = F.normalize(matrix_sample, p=2, dim=1)\n",
    "        similarity_matrix = dot_product = torch.bmm(normalized_matrix.transpose(2, 1), normalized_matrix_sample)\n",
    "        return similarity_matrix\n",
    "\n",
    "    '''N Sample Methods'''\n",
    "    @staticmethod\n",
    "    def prime_vmap_2d_N(matrix, magnitude_matrix, num_nearest_neighbors, maximum): \n",
    "        '''Vectorization / Vmap Implementation for Nearest Neighbor Tensor 2D'''\n",
    "        batched_process = torch.vmap(Conv1d_NN_spatial.process_batch_N, in_dims=(0, 0, None), out_dims=0)\n",
    "        prime = batched_process(matrix, magnitude_matrix, num_nearest_neighbors, flatten=True, maximum=maximum)\n",
    "        return prime \n",
    "    \n",
    "    @staticmethod\n",
    "    def prime_vmap_3d_N(matrix, magnitude_matrix, num_nearest_neighbors, maximum): \n",
    "        '''Vectorization / Vmap Implementation for Nearest Neighbor Tensor 3D'''\n",
    "        batched_process = torch.vmap(Conv1d_NN_spatial.process_batch_N, in_dims=(0, 0, None), out_dims=0)\n",
    "        prime = batched_process(matrix, magnitude_matrix, num_nearest_neighbors, flatten=False, maximum=maximum)\n",
    "        return prime\n",
    "    \n",
    "    @staticmethod \n",
    "    def process_batch_N(matrix, magnitude_matrix, num_nearest_neighbors, flatten, maximum): \n",
    "        # Process the batch of matrices\n",
    "        ind = torch.topk(magnitude_matrix, num_nearest_neighbors, largest=maximum).indices \n",
    "        neigh = matrix[:, ind]\n",
    "        if flatten: \n",
    "            reshape = torch.flatten(neigh, start_dim=1)\n",
    "            return reshape\n",
    "        return neigh\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  torch.Size([32, 1, 28, 28])\n",
      "Output:  torch.Size([32, 3, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "# Example\n",
    "ex = torch.rand(32, 1, 28, 28) \n",
    "print(\"Input: \", ex.shape)\n",
    "\n",
    "conv2d_nn = Conv2d_NN(in_channels=1, out_channels=3, K=3, stride=3, padding=0, shuffle_pattern=\"N/A\", shuffle_scale=2, samples=5)\n",
    "output = conv2d_nn(ex)\n",
    "print(\"Output: \", output.shape)\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ii. Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "           Flatten-1               [-1, 4, 196]               0\n",
      "            Conv1d-2              [-1, 20, 196]             420\n",
      "              ReLU-3              [-1, 20, 196]               0\n",
      "         Conv1d_NN-4              [-1, 20, 196]               0\n",
      "         Conv2d_NN-5            [-1, 5, 28, 28]               0\n",
      "           Flatten-6              [-1, 20, 196]               0\n",
      "            Conv1d-7              [-1, 40, 196]           4,040\n",
      "              ReLU-8              [-1, 40, 196]               0\n",
      "         Conv1d_NN-9              [-1, 40, 196]               0\n",
      "        Conv2d_NN-10           [-1, 10, 28, 28]               0\n",
      "          Flatten-11              [-1, 40, 196]               0\n",
      "           Conv1d-12              [-1, 80, 196]          16,080\n",
      "             ReLU-13              [-1, 80, 196]               0\n",
      "        Conv1d_NN-14              [-1, 80, 196]               0\n",
      "        Conv2d_NN-15           [-1, 20, 28, 28]               0\n",
      "          Flatten-16                [-1, 15680]               0\n",
      "           Linear-17                   [-1, 10]         156,810\n",
      "================================================================\n",
      "Total params: 177,350\n",
      "Trainable params: 177,350\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 1.05\n",
      "Params size (MB): 0.68\n",
      "Estimated Total Size (MB): 1.73\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# all sample model\n",
    "conv2d_nn = nn.Sequential(\n",
    "   Conv2d_NN(\n",
    "      in_channels=1,\n",
    "      out_channels=5,\n",
    "      K=5,\n",
    "      stride=5,\n",
    "      padding=0,\n",
    "      samples=\"all\", \n",
    "      shuffle_scale=2\n",
    "   ), \n",
    "   Conv2d_NN(\n",
    "      in_channels=5,\n",
    "      out_channels=10,\n",
    "      K=5,\n",
    "      stride=5,\n",
    "      padding=0,\n",
    "      samples=\"all\", \n",
    "      shuffle_scale=2\n",
    "   ),\n",
    "   Conv2d_NN(\n",
    "      in_channels=10,\n",
    "      out_channels=20,\n",
    "      K=5,\n",
    "      stride=5,\n",
    "      padding=0,\n",
    "      samples=\"all\", \n",
    "      shuffle_scale=2\n",
    "   ),\n",
    "   nn.Flatten(), \n",
    "   nn.Linear(15680, 10)\n",
    "   \n",
    ").to('cpu')\n",
    "   \n",
    "\n",
    "from torchsummary import summary\n",
    "summary(conv2d_nn, (1, 28, 28))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "           Flatten-1               [-1, 1, 784]               0\n",
      "            Conv1d-2               [-1, 5, 784]              30\n",
      "              ReLU-3               [-1, 5, 784]               0\n",
      " Conv1d_NN_spatial-4               [-1, 5, 784]               0\n",
      " Conv2d_NN_spatial-5            [-1, 5, 28, 28]               0\n",
      "           Flatten-6               [-1, 5, 784]               0\n",
      "            Conv1d-7              [-1, 10, 784]             260\n",
      "              ReLU-8              [-1, 10, 784]               0\n",
      " Conv1d_NN_spatial-9              [-1, 10, 784]               0\n",
      "Conv2d_NN_spatial-10           [-1, 10, 28, 28]               0\n",
      "          Flatten-11              [-1, 10, 784]               0\n",
      "           Conv1d-12              [-1, 20, 784]           1,020\n",
      "             ReLU-13              [-1, 20, 784]               0\n",
      "Conv1d_NN_spatial-14              [-1, 20, 784]               0\n",
      "Conv2d_NN_spatial-15           [-1, 20, 28, 28]               0\n",
      "          Flatten-16                [-1, 15680]               0\n",
      "           Linear-17                   [-1, 10]         156,810\n",
      "================================================================\n",
      "Total params: 158,120\n",
      "Trainable params: 158,120\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 1.05\n",
      "Params size (MB): 0.60\n",
      "Estimated Total Size (MB): 1.66\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# spatial model with all samples\n",
    "conv2d_nn_spatial_all = nn.Sequential(\n",
    "   Conv2d_NN_spatial(\n",
    "      in_channels=1,\n",
    "      out_channels=5,\n",
    "      K=5,\n",
    "      stride=5,\n",
    "      padding=0,\n",
    "      shuffle_scale=2, \n",
    "      samples=28\n",
    "      \n",
    "   ), \n",
    "   Conv2d_NN_spatial(\n",
    "      in_channels=5,\n",
    "      out_channels=10,\n",
    "      K=5,\n",
    "      stride=5,\n",
    "      padding=0,\n",
    "      shuffle_scale=2, \n",
    "      samples=28\n",
    "   ),\n",
    "   Conv2d_NN_spatial(\n",
    "      in_channels=10,\n",
    "      out_channels=20,\n",
    "      K=5,\n",
    "      stride=5,\n",
    "      padding=0,\n",
    "      shuffle_scale=2, \n",
    "      samples=28\n",
    "   ),\n",
    "   nn.Flatten(), \n",
    "   nn.Linear(15680, 10)\n",
    "   \n",
    ").to('cpu')\n",
    "   \n",
    "\n",
    "from torchsummary import summary\n",
    "summary(conv2d_nn_spatial_all, (1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "           Flatten-1               [-1, 1, 784]               0\n",
      "            Conv1d-2               [-1, 5, 784]              30\n",
      "              ReLU-3               [-1, 5, 784]               0\n",
      " Conv1d_NN_spatial-4               [-1, 5, 784]               0\n",
      " Conv2d_NN_spatial-5            [-1, 5, 28, 28]               0\n",
      "           Flatten-6               [-1, 5, 784]               0\n",
      "            Conv1d-7              [-1, 10, 784]             260\n",
      "              ReLU-8              [-1, 10, 784]               0\n",
      " Conv1d_NN_spatial-9              [-1, 10, 784]               0\n",
      "Conv2d_NN_spatial-10           [-1, 10, 28, 28]               0\n",
      "          Flatten-11              [-1, 10, 784]               0\n",
      "           Conv1d-12              [-1, 20, 784]           1,020\n",
      "             ReLU-13              [-1, 20, 784]               0\n",
      "Conv1d_NN_spatial-14              [-1, 20, 784]               0\n",
      "Conv2d_NN_spatial-15           [-1, 20, 28, 28]               0\n",
      "          Flatten-16                [-1, 15680]               0\n",
      "           Linear-17                   [-1, 10]         156,810\n",
      "================================================================\n",
      "Total params: 158,120\n",
      "Trainable params: 158,120\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 1.05\n",
      "Params size (MB): 0.60\n",
      "Estimated Total Size (MB): 1.66\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# spatial model with 1 sample\n",
    "conv2d_nn_spatial_1 = nn.Sequential(\n",
    "   Conv2d_NN_spatial(\n",
    "      in_channels=1,\n",
    "      out_channels=5,\n",
    "      K=1,\n",
    "      stride=1,\n",
    "      padding=0,\n",
    "      shuffle_scale=2, \n",
    "      samples=1\n",
    "      \n",
    "   ), \n",
    "   Conv2d_NN_spatial(\n",
    "      in_channels=5,\n",
    "      out_channels=10,\n",
    "      K=1,\n",
    "      stride=1,\n",
    "      padding=0,\n",
    "      shuffle_scale=2, \n",
    "      samples=1\n",
    "   ),\n",
    "   Conv2d_NN_spatial(\n",
    "      in_channels=10,\n",
    "      out_channels=20,\n",
    "      K=1,\n",
    "      stride=1,\n",
    "      padding=0,\n",
    "      shuffle_scale=2, \n",
    "      samples=1\n",
    "   ),\n",
    "   nn.Flatten(), \n",
    "   nn.Linear(15680, 10)\n",
    "   \n",
    ").to('cpu')\n",
    "   \n",
    "\n",
    "from torchsummary import summary\n",
    "summary(conv2d_nn_spatial_all, (1, 28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i. Data + Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST\n",
    "mnist = MNIST()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Time: 42.84804010391235, Loss: 0.373313202230788\n",
      "Epoch 2, Time: 42.819385051727295, Loss: 0.22975348151410058\n",
      "Epoch 3, Time: 42.46953296661377, Loss: 0.19280044169925742\n",
      "Epoch 4, Time: 42.88373398780823, Loss: 0.16800292709600062\n",
      "Epoch 5, Time: 41.99836182594299, Loss: 0.15230869689682272\n",
      "Epoch 6, Time: 42.4278609752655, Loss: 0.14082590549159596\n",
      "Epoch 7, Time: 44.04428005218506, Loss: 0.1331104949942784\n",
      "Epoch 8, Time: 42.47032809257507, Loss: 0.11953459918669769\n",
      "Epoch 9, Time: 41.90473818778992, Loss: 0.11008217206288344\n",
      "Epoch 10, Time: 41.969505071640015, Loss: 0.10433385084901474\n",
      "\n",
      " Average epoch time: 42.58357663154602\n",
      "Accuracy on test set: 94.86%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "94.86"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ConvNN_2D\n",
    "conv2d_nn.to('mps')\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(conv2d_nn.parameters(), lr=0.001)\n",
    "num_epochs = 10 \n",
    "train_model(conv2d_nn, mnist.train_loader, criterion, optimizer, num_epochs)\n",
    "evaluate_accuracy(conv2d_nn, mnist.test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(conv2d_nn_spatial_all\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[1;32m      6\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m \n\u001b[0;32m----> 7\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconv2d_nn_spatial_all\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmnist\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m evaluate_accuracy(conv2d_nn_spatial_all, mnist\u001b[38;5;241m.\u001b[39mtest_loader)\n",
      "File \u001b[0;32m~/Developer/Convolutional-Nearest-Neighbor/Testing/../2D_Modules/train.py:18\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, criterion, optimizer, num_epochs)\u001b[0m\n\u001b[1;32m     16\u001b[0m images, labels \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmps\u001b[39m\u001b[38;5;124m'\u001b[39m), labels\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmps\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     17\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 18\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     20\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/miniforge3/envs/ML/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/ML/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/ML/lib/python3.12/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/miniforge3/envs/ML/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/ML/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[31], line 47\u001b[0m, in \u001b[0;36mConv2d_NN_spatial.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     44\u001b[0m x1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflatten(x)\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# Conv1d_NN Layer\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m x2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConv1d_NN_spatial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_sample\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# Unflatten Layer \u001b[39;00m\n\u001b[1;32m     50\u001b[0m unflatten \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mUnflatten(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, unflattened_size\u001b[38;5;241m=\u001b[39mx\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m:])\n",
      "File \u001b[0;32m~/miniforge3/envs/ML/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/ML/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[34], line 52\u001b[0m, in \u001b[0;36mConv1d_NN_spatial.forward\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmagnitude_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msimilarity\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     50\u001b[0m     matrix_magnitude \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcalculate_similarity_matrix_N(x1, y)        \n\u001b[0;32m---> 52\u001b[0m prime \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprime_vmap_2d_N\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmatrix_magnitude\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mK\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaximum\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# Conv1d Layer\u001b[39;00m\n\u001b[1;32m     55\u001b[0m x2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1d_layer(prime)\n",
      "Cell \u001b[0;32mIn[34], line 92\u001b[0m, in \u001b[0;36mConv1d_NN_spatial.prime_vmap_2d_N\u001b[0;34m(matrix, magnitude_matrix, num_nearest_neighbors, maximum)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''Vectorization / Vmap Implementation for Nearest Neighbor Tensor 2D'''\u001b[39;00m\n\u001b[1;32m     91\u001b[0m batched_process \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mvmap(Conv1d_NN_spatial\u001b[38;5;241m.\u001b[39mprocess_batch_N, in_dims\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m), out_dims\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 92\u001b[0m prime \u001b[38;5;241m=\u001b[39m \u001b[43mbatched_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmatrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmagnitude_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_nearest_neighbors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflatten\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaximum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximum\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m prime\n",
      "File \u001b[0;32m~/miniforge3/envs/ML/lib/python3.12/site-packages/torch/_functorch/apis.py:188\u001b[0m, in \u001b[0;36mvmap.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 188\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvmap_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandomness\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/ML/lib/python3.12/site-packages/torch/_functorch/vmap.py:278\u001b[0m, in \u001b[0;36mvmap_impl\u001b[0;34m(func, in_dims, out_dims, randomness, chunk_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _chunked_vmap(func, flat_in_dims, chunks_flat_args,\n\u001b[1;32m    275\u001b[0m                          args_spec, out_dims, randomness, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    277\u001b[0m \u001b[38;5;66;03m# If chunk_size is not specified.\u001b[39;00m\n\u001b[0;32m--> 278\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_flat_vmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflat_in_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs_spec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandomness\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/ML/lib/python3.12/site-packages/torch/_functorch/vmap.py:44\u001b[0m, in \u001b[0;36mdoesnt_support_saved_tensors_hooks.<locals>.fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfn\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mdisable_saved_tensors_hooks(message):\n\u001b[0;32m---> 44\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/ML/lib/python3.12/site-packages/torch/_functorch/vmap.py:391\u001b[0m, in \u001b[0;36m_flat_vmap\u001b[0;34m(func, batch_size, flat_in_dims, flat_args, args_spec, out_dims, randomness, **kwargs)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    390\u001b[0m     batched_inputs \u001b[38;5;241m=\u001b[39m _create_batched_inputs(flat_in_dims, flat_args, vmap_level, args_spec)\n\u001b[0;32m--> 391\u001b[0m     batched_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbatched_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unwrap_batched(batched_outputs, out_dims, vmap_level, batch_size, func)\n\u001b[1;32m    393\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[34], line 108\u001b[0m, in \u001b[0;36mConv1d_NN_spatial.process_batch_N\u001b[0;34m(matrix, magnitude_matrix, num_nearest_neighbors, flatten, maximum)\u001b[0m\n\u001b[1;32m    106\u001b[0m neigh \u001b[38;5;241m=\u001b[39m matrix[:, ind]\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m flatten: \n\u001b[0;32m--> 108\u001b[0m     reshape \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43mneigh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m reshape\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m neigh\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ConvNN_2D_Spatial all samples\n",
    "conv2d_nn_spatial_all.to('mps')\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(conv2d_nn_spatial_all.parameters(), lr=0.001)\n",
    "num_epochs = 10 \n",
    "train_model(conv2d_nn_spatial_all, mnist.train_loader, criterion, optimizer, num_epochs)\n",
    "evaluate_accuracy(conv2d_nn_spatial_all, mnist.test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Time: 601.8950850963593, Loss: 2.3103534903353466\n",
      "Epoch 2, Time: 3276.250557899475, Loss: 2.301367968892746\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(conv2d_nn_spatial_1\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[1;32m      6\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m \n\u001b[0;32m----> 7\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconv2d_nn_spatial_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmnist\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m evaluate_accuracy(conv2d_nn_spatial_1, mnist\u001b[38;5;241m.\u001b[39mtest_loader)\n",
      "File \u001b[0;32m~/Developer/Convolutional-Nearest-Neighbor/Testing/../2D_Modules/train.py:18\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, criterion, optimizer, num_epochs)\u001b[0m\n\u001b[1;32m     16\u001b[0m images, labels \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmps\u001b[39m\u001b[38;5;124m'\u001b[39m), labels\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmps\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     17\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 18\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     20\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/miniforge3/envs/ML/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/ML/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/ML/lib/python3.12/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/miniforge3/envs/ML/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/ML/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[31], line 47\u001b[0m, in \u001b[0;36mConv2d_NN_spatial.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     44\u001b[0m x1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflatten(x)\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# Conv1d_NN Layer\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m x2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConv1d_NN_spatial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_sample\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# Unflatten Layer \u001b[39;00m\n\u001b[1;32m     50\u001b[0m unflatten \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mUnflatten(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, unflattened_size\u001b[38;5;241m=\u001b[39mx\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m:])\n",
      "File \u001b[0;32m~/miniforge3/envs/ML/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/ML/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[34], line 52\u001b[0m, in \u001b[0;36mConv1d_NN_spatial.forward\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmagnitude_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msimilarity\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     50\u001b[0m     matrix_magnitude \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcalculate_similarity_matrix_N(x1, y)        \n\u001b[0;32m---> 52\u001b[0m prime \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprime_vmap_2d_N\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmatrix_magnitude\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mK\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaximum\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# Conv1d Layer\u001b[39;00m\n\u001b[1;32m     55\u001b[0m x2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1d_layer(prime)\n",
      "Cell \u001b[0;32mIn[34], line 92\u001b[0m, in \u001b[0;36mConv1d_NN_spatial.prime_vmap_2d_N\u001b[0;34m(matrix, magnitude_matrix, num_nearest_neighbors, maximum)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''Vectorization / Vmap Implementation for Nearest Neighbor Tensor 2D'''\u001b[39;00m\n\u001b[1;32m     91\u001b[0m batched_process \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mvmap(Conv1d_NN_spatial\u001b[38;5;241m.\u001b[39mprocess_batch_N, in_dims\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m), out_dims\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 92\u001b[0m prime \u001b[38;5;241m=\u001b[39m \u001b[43mbatched_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmatrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmagnitude_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_nearest_neighbors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflatten\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaximum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximum\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m prime\n",
      "File \u001b[0;32m~/miniforge3/envs/ML/lib/python3.12/site-packages/torch/_functorch/apis.py:188\u001b[0m, in \u001b[0;36mvmap.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 188\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvmap_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandomness\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/ML/lib/python3.12/site-packages/torch/_functorch/vmap.py:278\u001b[0m, in \u001b[0;36mvmap_impl\u001b[0;34m(func, in_dims, out_dims, randomness, chunk_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _chunked_vmap(func, flat_in_dims, chunks_flat_args,\n\u001b[1;32m    275\u001b[0m                          args_spec, out_dims, randomness, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    277\u001b[0m \u001b[38;5;66;03m# If chunk_size is not specified.\u001b[39;00m\n\u001b[0;32m--> 278\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_flat_vmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflat_in_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs_spec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandomness\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/ML/lib/python3.12/site-packages/torch/_functorch/vmap.py:44\u001b[0m, in \u001b[0;36mdoesnt_support_saved_tensors_hooks.<locals>.fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfn\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mdisable_saved_tensors_hooks(message):\n\u001b[0;32m---> 44\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/ML/lib/python3.12/site-packages/torch/_functorch/vmap.py:391\u001b[0m, in \u001b[0;36m_flat_vmap\u001b[0;34m(func, batch_size, flat_in_dims, flat_args, args_spec, out_dims, randomness, **kwargs)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    390\u001b[0m     batched_inputs \u001b[38;5;241m=\u001b[39m _create_batched_inputs(flat_in_dims, flat_args, vmap_level, args_spec)\n\u001b[0;32m--> 391\u001b[0m     batched_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbatched_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unwrap_batched(batched_outputs, out_dims, vmap_level, batch_size, func)\n\u001b[1;32m    393\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[34], line 108\u001b[0m, in \u001b[0;36mConv1d_NN_spatial.process_batch_N\u001b[0;34m(matrix, magnitude_matrix, num_nearest_neighbors, flatten, maximum)\u001b[0m\n\u001b[1;32m    106\u001b[0m neigh \u001b[38;5;241m=\u001b[39m matrix[:, ind]\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m flatten: \n\u001b[0;32m--> 108\u001b[0m     reshape \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43mneigh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m reshape\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m neigh\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ConvNN_2D_Spatial 1 sample\n",
    "conv2d_nn_spatial_1.to('mps')\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(conv2d_nn_spatial_1.parameters(), lr=0.001)\n",
    "num_epochs = 10 \n",
    "train_model(conv2d_nn_spatial_1, mnist.train_loader, criterion, optimizer, num_epochs)\n",
    "evaluate_accuracy(conv2d_nn_spatial_1, mnist.test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
