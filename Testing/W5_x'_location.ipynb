{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# X' (X Prime) Experiment \n",
    "- Adding the location channels in the beginning of the image, and not at each layer step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torch\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim \n",
    "\n",
    "\n",
    "# Train + Data \n",
    "import sys \n",
    "sys.path.append('../Layers')\n",
    "from Conv1d_NN_spatial import * \n",
    "from Conv2d_NN_spatial import * \n",
    "\n",
    "sys.path.append('../Data')\n",
    "from CIFAR10 import * \n",
    "\n",
    "\n",
    "sys.path.append('../Models')\n",
    "from models_2d import *\n",
    "\n",
    "sys.path.append('../Train')\n",
    "from train2d import * \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10 = CIFAR10()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CNN\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, in_ch=3, num_classes=10, kernel_size=3):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_ch+3, 16, kernel_size=kernel_size, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=kernel_size, stride=1, padding=1)\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        self.fc1 = nn.Linear(32768, 1024)\n",
    "        self.fc2 = nn.Linear(1024, num_classes)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.to(\"mps\")\n",
    "        self.name = \"CNN\"\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        \n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.flatten(x)\n",
    "\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def summary(self, input_size = (3, 32, 32)): \n",
    "        self.to(\"cpu\")\n",
    "        print(summary(self, input_size))\n",
    "        self.to(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNN_2D_K_All(nn.Module):\n",
    "    def __init__(self, in_ch=3, num_classes=10, K=9):\n",
    "        super(ConvNN_2D_K_All, self).__init__()\n",
    "        \n",
    "        self.conv1 = Conv2d_NN(in_ch+3, 16, K=K, stride=K, shuffle_pattern=\"BA\", shuffle_scale=2, samples=\"all\")\n",
    "        self.conv2 = Conv2d_NN(16, 32, K=K, stride=K, shuffle_pattern=\"BA\", shuffle_scale=2, samples=\"all\")\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        self.fc1 = nn.Linear(32768, 1024)\n",
    "        self.fc2 = nn.Linear(1024, num_classes)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.to(\"mps\")\n",
    "        self.name = \"ConvNN_2D_K_All\"\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.flatten(x)\n",
    "\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def summary(self, input_size = (3, 32, 32)): \n",
    "        self.to(\"cpu\")\n",
    "        print(summary(self, input_size))\n",
    "        self.to(\"mps\")\n",
    "        \n",
    "    def coordinate_channels(self, tensor_shape, device):\n",
    "        x_ind = torch.arange(0, tensor_shape[2])\n",
    "        y_ind = torch.arange(0, tensor_shape[3])\n",
    "        \n",
    "        x_grid, y_grid = torch.meshgrid(x_ind, y_ind, indexing='ij')\n",
    "        \n",
    "        x_grid = x_grid.float().unsqueeze(0).expand(tensor_shape[0], -1, -1).unsqueeze(1)\n",
    "        y_grid = y_grid.float().unsqueeze(0).expand(tensor_shape[0], -1, -1).unsqueeze(1)\n",
    "        \n",
    "        xy_grid = torch.cat((x_grid, y_grid), dim=1)\n",
    "        xy_grid_normalized = F.normalize(xy_grid, p=2, dim=1)\n",
    "        return xy_grid_normalized.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Branching_ConvNN_2D_Spatial_K_N(nn.Module):\n",
    "    def __init__(self, in_ch=3, channel_ratio=(16, 16), num_classes=10, kernel_size=3, K=9, N = 8, location_channels = False)\n",
    "        \n",
    "        super(Branching_ConvNN_2D_Spatial_K_N, self).__init__()\n",
    "        self.conv1 = ConvNN_CNN_Spatial_BranchingLayer(in_ch+3, 16, \n",
    "            channel_ratio=channel_ratio,kernel_size=kernel_size, K=K, samples=N, location_channels=location_channels)\n",
    "        self.conv2 = ConvNN_CNN_Spatial_BranchingLayer(16, 32, channel_ratio=(channel_ratio[0] *2, channel_ratio[1]*2),kernel_size=kernel_size, K=K, samples=N, location_channels=location_channels)\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        self.fc1 = nn.Linear(32768, 1024)\n",
    "        self.fc2 = nn.Linear(1024, num_classes)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.to(\"mps\")\n",
    "        self.name = \"Branching_ConvNN_2D_Spatial_K_N\"\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        \n",
    "        x = self.flatten(x)\n",
    "\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "    def summary(self, input_size = (3, 32, 32)): \n",
    "        self.to(\"cpu\")\n",
    "        print(summary(self, input_size))\n",
    "        self.to(\"mps\")\n",
    "        \n",
    "    def coordinate_channels(self, tensor_shape, device):\n",
    "        x_ind = torch.arange(0, tensor_shape[2])\n",
    "        y_ind = torch.arange(0, tensor_shape[3])\n",
    "        \n",
    "        x_grid, y_grid = torch.meshgrid(x_ind, y_ind, indexing='ij')\n",
    "        \n",
    "        x_grid = x_grid.float().unsqueeze(0).expand(tensor_shape[0], -1, -1).unsqueeze(1)\n",
    "        y_grid = y_grid.float().unsqueeze(0).expand(tensor_shape[0], -1, -1).unsqueeze(1)\n",
    "        \n",
    "        xy_grid = torch.cat((x_grid, y_grid), dim=1)\n",
    "        xy_grid_normalized = F.normalize(xy_grid, p=2, dim=1)\n",
    "        return xy_grid_normalized.to(device)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
