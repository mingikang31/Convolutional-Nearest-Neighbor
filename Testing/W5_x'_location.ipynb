{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# X' (X Prime) Experiment \n",
    "- Adding the location channels in the beginning of the image, and not at each layer step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mingikang/miniforge3/envs/ML/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Torch\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim \n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "# Train + Data \n",
    "import sys \n",
    "sys.path.append('../Layers')\n",
    "from Conv1d_NN import *\n",
    "from Conv2d_NN import *\n",
    "from Conv1d_NN_spatial import * \n",
    "from Conv2d_NN_spatial import * \n",
    "from ConvNN_CNN_Branching import *\n",
    "\n",
    "sys.path.append('../Data')\n",
    "from CIFAR10 import * \n",
    "\n",
    "\n",
    "sys.path.append('../Models')\n",
    "from models_2d import *\n",
    "\n",
    "sys.path.append('../Train')\n",
    "from train2d import * \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "cifar10 = CIFAR10()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CNN\n",
    "class CNN_Location_Before(nn.Module):\n",
    "    def __init__(self, in_ch=3, num_classes=10, kernel_size=3):\n",
    "        super(CNN_Location_Before, self).__init__()\n",
    "        \n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_ch+2, 16, kernel_size=kernel_size, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=kernel_size, stride=1, padding=1)\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        self.fc1 = nn.Linear(32768, 1024)\n",
    "        self.fc2 = nn.Linear(1024, num_classes)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.to(\"mps\")\n",
    "        self.name = \"CNN_Location_Before\"\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_coordinates = self.coordinate_channels(x.shape, x.device)\n",
    "        x = torch.cat((x, x_coordinates), dim=1)\n",
    "        \n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.flatten(x)\n",
    "\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def summary(self, input_size = (3, 32, 32)): \n",
    "        self.to(\"cpu\")\n",
    "        print(summary(self, input_size))\n",
    "        self.to(\"mps\")\n",
    "            \n",
    "    def coordinate_channels(self, tensor_shape, device):\n",
    "        x_ind = torch.arange(0, tensor_shape[2])\n",
    "        y_ind = torch.arange(0, tensor_shape[3])\n",
    "        \n",
    "        x_grid, y_grid = torch.meshgrid(x_ind, y_ind, indexing='ij')\n",
    "        \n",
    "        x_grid = x_grid.float().unsqueeze(0).expand(tensor_shape[0], -1, -1).unsqueeze(1)\n",
    "        y_grid = y_grid.float().unsqueeze(0).expand(tensor_shape[0], -1, -1).unsqueeze(1)\n",
    "        \n",
    "        xy_grid = torch.cat((x_grid, y_grid), dim=1)\n",
    "        xy_grid_normalized = F.normalize(xy_grid, p=2, dim=1)\n",
    "        return xy_grid_normalized.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNN_2D_K_All_Location_Before(nn.Module):\n",
    "    def __init__(self, in_ch=3, num_classes=10, K=9):\n",
    "        super(ConvNN_2D_K_All_Location_Before, self).__init__()\n",
    "        \n",
    "        self.conv1 = Conv2d_NN(in_ch+2, 16, K=K, stride=K, shuffle_pattern=\"BA\", shuffle_scale=2, samples=\"all\")\n",
    "        self.conv2 = Conv2d_NN(16, 32, K=K, stride=K, shuffle_pattern=\"BA\", shuffle_scale=2, samples=\"all\")\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        self.fc1 = nn.Linear(32768, 1024)\n",
    "        self.fc2 = nn.Linear(1024, num_classes)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.to(\"mps\")\n",
    "        self.name = \"ConvNN_2D_K_All_Location_Before\"\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_coordinates = self.coordinate_channels(x.shape, x.device)\n",
    "        x = torch.cat((x, x_coordinates), dim=1)\n",
    "        \n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.flatten(x)\n",
    "\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def summary(self, input_size = (3, 32, 32)): \n",
    "        self.to(\"cpu\")\n",
    "        print(summary(self, input_size))\n",
    "        self.to(\"mps\")\n",
    "        \n",
    "    def coordinate_channels(self, tensor_shape, device):\n",
    "        x_ind = torch.arange(0, tensor_shape[2])\n",
    "        y_ind = torch.arange(0, tensor_shape[3])\n",
    "        \n",
    "        x_grid, y_grid = torch.meshgrid(x_ind, y_ind, indexing='ij')\n",
    "        \n",
    "        x_grid = x_grid.float().unsqueeze(0).expand(tensor_shape[0], -1, -1).unsqueeze(1)\n",
    "        y_grid = y_grid.float().unsqueeze(0).expand(tensor_shape[0], -1, -1).unsqueeze(1)\n",
    "        \n",
    "        xy_grid = torch.cat((x_grid, y_grid), dim=1)\n",
    "        xy_grid_normalized = F.normalize(xy_grid, p=2, dim=1)\n",
    "        return xy_grid_normalized.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNN_2D_K_N_Location_Before(nn.Module):\n",
    "    def __init__(self, in_ch=3, num_classes=10, K=9, N = 64):\n",
    "        super(ConvNN_2D_K_N_Location_Before, self).__init__()\n",
    "        \n",
    "        self.conv1 = Conv2d_NN(in_ch+2, 16, K=K, stride=K, shuffle_pattern=\"BA\", shuffle_scale=2, samples=N)\n",
    "        self.conv2 = Conv2d_NN(16, 32, K=K, stride=K, shuffle_pattern=\"BA\", shuffle_scale=2, samples=N)\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        self.fc1 = nn.Linear(32768, 1024)\n",
    "        self.fc2 = nn.Linear(1024, num_classes)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.to(\"mps\")\n",
    "        self.name = \"ConvNN_2D_K_N_Location_Before\"\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_coordinates = self.coordinate_channels(x.shape, x.device)\n",
    "        x = torch.cat((x, x_coordinates), dim=1)\n",
    "        \n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.flatten(x)\n",
    "\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def summary(self, input_size = (3, 32, 32)): \n",
    "        self.to(\"cpu\")\n",
    "        print(summary(self, input_size))\n",
    "        self.to(\"mps\")\n",
    "        \n",
    "    def coordinate_channels(self, tensor_shape, device):\n",
    "        x_ind = torch.arange(0, tensor_shape[2])\n",
    "        y_ind = torch.arange(0, tensor_shape[3])\n",
    "        \n",
    "        x_grid, y_grid = torch.meshgrid(x_ind, y_ind, indexing='ij')\n",
    "        \n",
    "        x_grid = x_grid.float().unsqueeze(0).expand(tensor_shape[0], -1, -1).unsqueeze(1)\n",
    "        y_grid = y_grid.float().unsqueeze(0).expand(tensor_shape[0], -1, -1).unsqueeze(1)\n",
    "        \n",
    "        xy_grid = torch.cat((x_grid, y_grid), dim=1)\n",
    "        xy_grid_normalized = F.normalize(xy_grid, p=2, dim=1)\n",
    "        return xy_grid_normalized.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNN_2D_Spatial_K_N_Location_Before(nn.Module):\n",
    "    def __init__(self, in_ch=3, num_classes=10, K=9, N = 8):\n",
    "        super(ConvNN_2D_Spatial_K_N_Location_Before, self).__init__()\n",
    "        \n",
    "        self.conv1 = Conv2d_NN_spatial(in_ch+2, 16, K=K, stride=K, shuffle_pattern=\"BA\", shuffle_scale=2, samples=N)\n",
    "        self.conv2 = Conv2d_NN_spatial(16, 32, K=K, stride=K, shuffle_pattern=\"BA\", shuffle_scale=2, samples=N)\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        self.fc1 = nn.Linear(32768, 1024)\n",
    "        self.fc2 = nn.Linear(1024, num_classes)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.to(\"mps\")\n",
    "        self.name = \"ConvNN_2D_Spatial_K_N_Location_Before\"\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_coordinates = self.coordinate_channels(x.shape, x.device)\n",
    "        x = torch.cat((x, x_coordinates), dim=1)\n",
    "        \n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.flatten(x)\n",
    "\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def summary(self, input_size = (3, 32, 32)): \n",
    "        self.to(\"cpu\")\n",
    "        print(summary(self, input_size))\n",
    "        self.to(\"mps\")\n",
    "        \n",
    "    def coordinate_channels(self, tensor_shape, device):\n",
    "        x_ind = torch.arange(0, tensor_shape[2])\n",
    "        y_ind = torch.arange(0, tensor_shape[3])\n",
    "        \n",
    "        x_grid, y_grid = torch.meshgrid(x_ind, y_ind, indexing='ij')\n",
    "        \n",
    "        x_grid = x_grid.float().unsqueeze(0).expand(tensor_shape[0], -1, -1).unsqueeze(1)\n",
    "        y_grid = y_grid.float().unsqueeze(0).expand(tensor_shape[0], -1, -1).unsqueeze(1)\n",
    "        \n",
    "        xy_grid = torch.cat((x_grid, y_grid), dim=1)\n",
    "        xy_grid_normalized = F.normalize(xy_grid, p=2, dim=1)\n",
    "        return xy_grid_normalized.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Branching\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Branching_ConvNN_2D_K_All_Location_Before(nn.Module):\n",
    "    def __init__(self, in_ch=3, channel_ratio=(16, 16), num_classes=10, kernel_size=3, K=9, location_channels = False):\n",
    "        \n",
    "        super(Branching_ConvNN_2D_K_All_Location_Before, self).__init__()\n",
    "        self.conv1 = ConvNN_CNN_Random_BranchingLayer(in_ch+2, 16, \n",
    "            channel_ratio=channel_ratio,kernel_size=kernel_size, K=K, samples=\"all\", location_channels=location_channels)\n",
    "        self.conv2 = ConvNN_CNN_Random_BranchingLayer(16, 32, channel_ratio=(channel_ratio[0] *2, channel_ratio[1]*2),kernel_size=kernel_size, K=K, samples=\"all\", location_channels=location_channels)\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        self.fc1 = nn.Linear(32768, 1024)\n",
    "        self.fc2 = nn.Linear(1024, num_classes)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.to(\"mps\")\n",
    "        self.name = \"Branching_ConvNN_2D_K_All_Location_Before\"\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_coordinates = self.coordinate_channels(x.shape, x.device)\n",
    "        x = torch.cat((x, x_coordinates), dim=1)\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        \n",
    "        x = self.flatten(x)\n",
    "\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "    def summary(self, input_size = (3, 32, 32)): \n",
    "        self.to(\"cpu\")\n",
    "        print(summary(self, input_size))\n",
    "        self.to(\"mps\")\n",
    "        \n",
    "    def coordinate_channels(self, tensor_shape, device):\n",
    "        x_ind = torch.arange(0, tensor_shape[2])\n",
    "        y_ind = torch.arange(0, tensor_shape[3])\n",
    "        \n",
    "        x_grid, y_grid = torch.meshgrid(x_ind, y_ind, indexing='ij')\n",
    "        \n",
    "        x_grid = x_grid.float().unsqueeze(0).expand(tensor_shape[0], -1, -1).unsqueeze(1)\n",
    "        y_grid = y_grid.float().unsqueeze(0).expand(tensor_shape[0], -1, -1).unsqueeze(1)\n",
    "        \n",
    "        xy_grid = torch.cat((x_grid, y_grid), dim=1)\n",
    "        xy_grid_normalized = F.normalize(xy_grid, p=2, dim=1)\n",
    "        return xy_grid_normalized.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Branching_ConvNN_2D_K_N_Location_Before(nn.Module):\n",
    "    def __init__(self, in_ch=3, channel_ratio=(16, 16), num_classes=10, kernel_size=3, K=9, N = 64, location_channels = False):\n",
    "        \n",
    "        super(Branching_ConvNN_2D_K_N_Location_Before, self).__init__()\n",
    "        self.conv1 = ConvNN_CNN_Random_BranchingLayer(in_ch+2, 16, \n",
    "            channel_ratio=channel_ratio,kernel_size=kernel_size, K=K, samples=N, location_channels=location_channels)\n",
    "        self.conv2 = ConvNN_CNN_Random_BranchingLayer(16, 32, channel_ratio=(channel_ratio[0] *2, channel_ratio[1]*2),kernel_size=kernel_size, K=K, samples=N, location_channels=location_channels)\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        self.fc1 = nn.Linear(32768, 1024)\n",
    "        self.fc2 = nn.Linear(1024, num_classes)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.to(\"mps\")\n",
    "        self.name = \"Branching_ConvNN_2D_K_N_Location_Before\"\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_coordinates = self.coordinate_channels(x.shape, x.device)\n",
    "        x = torch.cat((x, x_coordinates), dim=1)\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        \n",
    "        x = self.flatten(x)\n",
    "\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "    def summary(self, input_size = (3, 32, 32)): \n",
    "        self.to(\"cpu\")\n",
    "        print(summary(self, input_size))\n",
    "        self.to(\"mps\")\n",
    "        \n",
    "    def coordinate_channels(self, tensor_shape, device):\n",
    "        x_ind = torch.arange(0, tensor_shape[2])\n",
    "        y_ind = torch.arange(0, tensor_shape[3])\n",
    "        \n",
    "        x_grid, y_grid = torch.meshgrid(x_ind, y_ind, indexing='ij')\n",
    "        \n",
    "        x_grid = x_grid.float().unsqueeze(0).expand(tensor_shape[0], -1, -1).unsqueeze(1)\n",
    "        y_grid = y_grid.float().unsqueeze(0).expand(tensor_shape[0], -1, -1).unsqueeze(1)\n",
    "        \n",
    "        xy_grid = torch.cat((x_grid, y_grid), dim=1)\n",
    "        xy_grid_normalized = F.normalize(xy_grid, p=2, dim=1)\n",
    "        return xy_grid_normalized.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Branching_ConvNN_2D_Spatial_K_N_Location_Before(nn.Module):\n",
    "    def __init__(self, in_ch=3, channel_ratio=(16, 16), num_classes=10, kernel_size=3, K=9, N = 8, location_channels = False):\n",
    "        \n",
    "        super(Branching_ConvNN_2D_Spatial_K_N_Location_Before, self).__init__()\n",
    "        self.conv1 = ConvNN_CNN_Spatial_BranchingLayer(in_ch+2, 16, \n",
    "            channel_ratio=channel_ratio,kernel_size=kernel_size, K=K, samples=N, location_channels=location_channels)\n",
    "        self.conv2 = ConvNN_CNN_Spatial_BranchingLayer(16, 32, channel_ratio=(channel_ratio[0] *2, channel_ratio[1]*2),kernel_size=kernel_size, K=K, samples=N, location_channels=location_channels)\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        self.fc1 = nn.Linear(32768, 1024)\n",
    "        self.fc2 = nn.Linear(1024, num_classes)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.to(\"mps\")\n",
    "        self.name = \"Branching_ConvNN_2D_Spatial_K_N\"\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_coordinates = self.coordinate_channels(x.shape, x.device)\n",
    "        x = torch.cat((x, x_coordinates), dim=1)\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        \n",
    "        x = self.flatten(x)\n",
    "\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "    def summary(self, input_size = (3, 32, 32)): \n",
    "        self.to(\"cpu\")\n",
    "        print(summary(self, input_size))\n",
    "        self.to(\"mps\")\n",
    "        \n",
    "    def coordinate_channels(self, tensor_shape, device):\n",
    "        x_ind = torch.arange(0, tensor_shape[2])\n",
    "        y_ind = torch.arange(0, tensor_shape[3])\n",
    "        \n",
    "        x_grid, y_grid = torch.meshgrid(x_ind, y_ind, indexing='ij')\n",
    "        \n",
    "        x_grid = x_grid.float().unsqueeze(0).expand(tensor_shape[0], -1, -1).unsqueeze(1)\n",
    "        y_grid = y_grid.float().unsqueeze(0).expand(tensor_shape[0], -1, -1).unsqueeze(1)\n",
    "        \n",
    "        xy_grid = torch.cat((x_grid, y_grid), dim=1)\n",
    "        xy_grid_normalized = F.normalize(xy_grid, p=2, dim=1)\n",
    "        return xy_grid_normalized.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN + ConvNN Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Time: 30.6076557636261, Loss: 1.320821599277389\n",
      "Epoch 2, Time: 34.71222472190857, Loss: 0.804229320124592\n",
      "Epoch 3, Time: 34.860244035720825, Loss: 0.42631748023316685\n",
      "Epoch 4, Time: 34.507848024368286, Loss: 0.14106527700915436\n",
      "Epoch 5, Time: 34.50970196723938, Loss: 0.06549997788513331\n",
      "Epoch 6, Time: 34.5172758102417, Loss: 0.049463629004452614\n",
      "Epoch 7, Time: 34.6102077960968, Loss: 0.05258563129365911\n",
      "Epoch 8, Time: 36.005460023880005, Loss: 0.0432165561500988\n",
      "Epoch 9, Time: 42.281323194503784, Loss: 0.04389226100365262\n",
      "Epoch 10, Time: 51.81594204902649, Loss: 0.03636969356222109\n",
      "\n",
      " Average epoch time: 36.842788338661194\n",
      "Accuracy on test set: 64.05%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "64.05"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CNN with Location Channels added before \n",
    "cnn_location_before = CNN_Location_Before()\n",
    "\n",
    "cnn_location_before.to('mps')\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(cnn_location_before.parameters(), lr=0.001)\n",
    "num_epochs = 10 \n",
    "train_model(cnn_location_before, cifar10.train_loader, criterion, optimizer, num_epochs)\n",
    "evaluate_accuracy(cnn_location_before, cifar10.test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Time: 88.54998207092285, Loss: 1.4418080857647655\n",
      "Epoch 2, Time: 102.55355286598206, Loss: 1.0979220754350238\n",
      "Epoch 3, Time: 105.41861128807068, Loss: 0.8576833204463925\n",
      "Epoch 4, Time: 107.13352918624878, Loss: 0.5801344805056482\n",
      "Epoch 5, Time: 104.16446471214294, Loss: 0.33415084219802066\n",
      "Epoch 6, Time: 99.26240801811218, Loss: 0.20348460427330584\n",
      "Epoch 7, Time: 101.254225730896, Loss: 0.15475174778467402\n",
      "Epoch 8, Time: 97.87570118904114, Loss: 0.12964877465625516\n",
      "Epoch 9, Time: 93.44150996208191, Loss: 0.1318924545585547\n",
      "Epoch 10, Time: 92.4614040851593, Loss: 0.09777499881991045\n",
      "\n",
      " Average epoch time: 99.21153891086578\n",
      "Accuracy on test set: 57.81%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "57.81"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ConNN 2D K = 9, All Samples with Location Channels added before\n",
    "convNN_k_all_location_before = ConvNN_2D_K_All_Location_Before()\n",
    "\n",
    "convNN_k_all_location_before.to('mps')\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(convNN_k_all_location_before.parameters(), lr=0.001)\n",
    "num_epochs = 10 \n",
    "train_model(convNN_k_all_location_before, cifar10.train_loader, criterion, optimizer, num_epochs)\n",
    "evaluate_accuracy(convNN_k_all_location_before, cifar10.test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Time: 81.79602098464966, Loss: 1.5881803331472684\n",
      "Epoch 2, Time: 107.91402888298035, Loss: 1.3037849923076532\n",
      "Epoch 3, Time: 100.48507595062256, Loss: 1.1484748300384073\n",
      "Epoch 4, Time: 98.87203693389893, Loss: 1.0113189613727658\n",
      "Epoch 5, Time: 95.79153990745544, Loss: 0.8566003597300985\n",
      "Epoch 6, Time: 95.58700799942017, Loss: 0.6867907003825887\n",
      "Epoch 7, Time: 91.66097617149353, Loss: 0.5179980193143305\n",
      "Epoch 8, Time: 96.27479195594788, Loss: 0.3865226810164464\n",
      "Epoch 9, Time: 105.01204204559326, Loss: 0.2909380830919651\n",
      "Epoch 10, Time: 93.43074202537537, Loss: 0.23003525745666697\n",
      "\n",
      " Average epoch time: 96.68242628574372\n",
      "Accuracy on test set: 58.14%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "58.14"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ConNN 2D K = 9, N = 64 samples with Location Channels added before\n",
    "convNN_k_n_location_before = ConvNN_2D_K_N_Location_Before()\n",
    "\n",
    "convNN_k_n_location_before.to('mps')\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(convNN_k_n_location_before.parameters(), lr=0.001)\n",
    "num_epochs = 10 \n",
    "train_model(convNN_k_n_location_before, cifar10.train_loader, criterion, optimizer, num_epochs)\n",
    "evaluate_accuracy(convNN_k_n_location_before, cifar10.test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Time: 74.92505407333374, Loss: 1.6053015551603664\n",
      "Epoch 2, Time: 83.55609202384949, Loss: 1.2975710497030517\n",
      "Epoch 3, Time: 100.73823809623718, Loss: 1.1161814317526415\n",
      "Epoch 4, Time: 88.86760187149048, Loss: 0.9325352026830853\n",
      "Epoch 5, Time: 88.95465803146362, Loss: 0.7363759284205449\n",
      "Epoch 6, Time: 100.82403612136841, Loss: 0.5282915237614566\n",
      "Epoch 7, Time: 96.99496293067932, Loss: 0.3596633702821439\n",
      "Epoch 8, Time: 90.96927404403687, Loss: 0.24099548423038725\n",
      "Epoch 9, Time: 90.5924379825592, Loss: 0.18628977498758936\n",
      "Epoch 10, Time: 90.69966316223145, Loss: 0.14287526123440059\n",
      "\n",
      " Average epoch time: 90.71220183372498\n",
      "Accuracy on test set: 56.83%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "56.83"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ConNN 2D K = 9, All Samples with Location Channels added before\n",
    "convNN_spatial_k_n_location_before = ConvNN_2D_Spatial_K_N_Location_Before()\n",
    "\n",
    "convNN_spatial_k_n_location_before.to('mps')\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(convNN_spatial_k_n_location_before.parameters(), lr=0.001)\n",
    "num_epochs = 10 \n",
    "train_model(convNN_spatial_k_n_location_before, cifar10.train_loader, criterion, optimizer, num_epochs)\n",
    "evaluate_accuracy(convNN_spatial_k_n_location_before, cifar10.test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Branching Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Time: 85.53256130218506, Loss: 1.3833571510089329\n",
      "Epoch 2, Time: 93.36223411560059, Loss: 0.9212241892314628\n",
      "Epoch 3, Time: 94.01718306541443, Loss: 0.5725646117687835\n",
      "Epoch 4, Time: 92.33943605422974, Loss: 0.24386605677549797\n",
      "Epoch 5, Time: 94.57718706130981, Loss: 0.13226696238031282\n",
      "Epoch 6, Time: 100.9719340801239, Loss: 0.10017482763992341\n",
      "Epoch 7, Time: 92.61468005180359, Loss: 0.07984808310443568\n",
      "Epoch 8, Time: 91.45573306083679, Loss: 0.08530400762551218\n",
      "Epoch 9, Time: 91.06785583496094, Loss: 0.08205851266319003\n",
      "Epoch 10, Time: 91.06611800193787, Loss: 0.0640960680340212\n",
      "\n",
      " Average epoch time: 92.70049226284027\n",
      "Accuracy on test set: 66.8%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "66.8"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Branching ConvNN 2D All Sampling with Location Channels added before\n",
    "branching_convNN_k_all_location_before = Branching_ConvNN_2D_K_All_Location_Before()\n",
    "\n",
    "branching_convNN_k_all_location_before.to('mps')\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(branching_convNN_k_all_location_before.parameters(), lr=0.001)\n",
    "num_epochs = 10 \n",
    "train_model(branching_convNN_k_all_location_before, cifar10.train_loader, criterion, optimizer, num_epochs)\n",
    "evaluate_accuracy(branching_convNN_k_all_location_before, cifar10.test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Time: 83.77112913131714, Loss: 1.4188538944477316\n",
      "Epoch 2, Time: 94.23606133460999, Loss: 0.9500628587077645\n",
      "Epoch 3, Time: 94.04767274856567, Loss: 0.5918908300225997\n",
      "Epoch 4, Time: 85.1609878540039, Loss: 0.2529479667182316\n",
      "Epoch 5, Time: 89.79701018333435, Loss: 0.1223194472708494\n",
      "Epoch 6, Time: 91.09826922416687, Loss: 0.10691663158088065\n",
      "Epoch 7, Time: 90.77736806869507, Loss: 0.09069944646678713\n",
      "Epoch 8, Time: 89.95389914512634, Loss: 0.08757478799334491\n",
      "Epoch 9, Time: 94.5812840461731, Loss: 0.07116465632605147\n",
      "Epoch 10, Time: 102.39141988754272, Loss: 0.060762007919731464\n",
      "\n",
      " Average epoch time: 91.58151016235351\n",
      "Accuracy on test set: 65.1%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "65.1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Branching ConvNN 2D Spatial Sampling with Location Channels added before\n",
    "branching_convNN_k_n_location_before = Branching_ConvNN_2D_K_N_Location_Before()\n",
    "\n",
    "branching_convNN_k_n_location_before.to('mps')\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(branching_convNN_k_n_location_before.parameters(), lr=0.001)\n",
    "num_epochs = 10 \n",
    "train_model(branching_convNN_k_n_location_before, cifar10.train_loader, criterion, optimizer, num_epochs)\n",
    "evaluate_accuracy(branching_convNN_k_n_location_before, cifar10.test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Time: 94.06807804107666, Loss: 1.4150934026521795\n",
      "Epoch 2, Time: 103.46013283729553, Loss: 0.9707661204020995\n",
      "Epoch 3, Time: 103.36579298973083, Loss: 0.6381737245699329\n",
      "Epoch 4, Time: 95.47790884971619, Loss: 0.27994981874018676\n",
      "Epoch 5, Time: 96.22189211845398, Loss: 0.1296414005298577\n",
      "Epoch 6, Time: 109.62095499038696, Loss: 0.11480781364330875\n",
      "Epoch 7, Time: 93.30559086799622, Loss: 0.08681446669028972\n",
      "Epoch 8, Time: 89.27326512336731, Loss: 0.07692564570683214\n",
      "Epoch 9, Time: 100.74316811561584, Loss: 0.07736872752864614\n",
      "Epoch 10, Time: 136.39051604270935, Loss: 0.06751669987137286\n",
      "\n",
      " Average epoch time: 102.19272999763488\n",
      "Accuracy on test set: 65.72%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "65.72"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Branching ConvNN 2D Spatial Sampling with Location Channels added before\n",
    "branching_convNN_spatial_k_n_location_before = Branching_ConvNN_2D_Spatial_K_N_Location_Before()\n",
    "\n",
    "branching_convNN_spatial_k_n_location_before.to('mps')\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(branching_convNN_spatial_k_n_location_before.parameters(), lr=0.001)\n",
    "num_epochs = 10 \n",
    "train_model(branching_convNN_spatial_k_n_location_before, cifar10.train_loader, criterion, optimizer, num_epochs)\n",
    "evaluate_accuracy(branching_convNN_spatial_k_n_location_before, cifar10.test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
