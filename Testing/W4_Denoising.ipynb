{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Denoising Testing 2D\n",
    "- CNN - regular convolutional neural network\n",
    "- ConvNN_2D - all sample\n",
    "- ConvNN_2D random sample\n",
    "- ConvNN_2D_spatial - spatial sample\n",
    "- Branching Network - CNN + ConvNN_2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torch\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim \n",
    "\n",
    "\n",
    "# Train + Data \n",
    "import sys \n",
    "sys.path.append('../Layers')\n",
    "from Conv1d_NN import *\n",
    "from Conv2d_NN import *\n",
    "\n",
    "from Conv1d_NN_spatial import * \n",
    "from Conv2d_NN_spatial import * \n",
    "\n",
    "sys.path.append('../Data')\n",
    "from CIFAR10 import CIFAR10_denoise\n",
    "\n",
    "\n",
    "sys.path.append('../Train')\n",
    "from train2d import * \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "branching_denoiser = nn.Sequential(\n",
    "   BranchingNetwork(in_ch = 1, out_ch1 = 16, out_ch2=16, kernel_size = 3), \n",
    "   BranchingNetwork(in_ch = 16, out_ch1 = 8, out_ch2=8, kernel_size = 3),\n",
    "   BranchingNetwork(in_ch = 8, out_ch1 = 4, out_ch2=4, kernel_size =3), \n",
    "   BranchingNetwork(in_ch = 4, out_ch1 = 2, out_ch2=2, kernel_size =3), \n",
    "   BranchingNetwork(in_ch = 2, out_ch1 = 1, out_ch2=1, kernel_size =3) \n",
    ")\n",
    "\n",
    "summary(branching_denoiser, (1, 40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regular CNN 2D denoising\n",
    "CNN_denoising = nn.Sequential(\n",
    "    nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1),\n",
    "    nn.ReLU(),\n",
    "\n",
    "    nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
    "    nn.ReLU(),\n",
    "\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(32768, 1024),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(1024, 10)\n",
    ").to('cpu')\n",
    "\n",
    "from torchsummary import summary \n",
    "summary(CNN_denoising, (3, 32, 32))\n",
    "\n",
    "\n",
    "\n",
    "class BranchingNetwork(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch1, out_ch2, kernel_size):\n",
    "        super().__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        \n",
    "        self.branch1 = nn.Sequential(\n",
    "            nn.Conv1d(in_ch, out_ch1, kernel_size),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.branch2 = nn.Sequential(\n",
    "            Conv1d_NN(in_ch, out_ch2, K = kernel_size, stride = kernel_size), \n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.reduce_channels = nn.Conv1d(out_ch1 + out_ch2, (out_ch1 + out_ch2) // 2, 1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x1 = self.branch1(x)\n",
    "        \n",
    "        x2 = self.branch2(x)\n",
    "        \n",
    "        ## Calculate expected Output size of x2 \n",
    "        expected_x1_size = x2.size(2) \n",
    "        # print(expected_x1_size)\n",
    "        \n",
    "        ## Calculate padding for x1 to match x2's size   \n",
    "        total_padding = expected_x1_size - x1.size(2)\n",
    "        # print(total_padding)\n",
    "        \n",
    "        left_padding = total_padding // 2\n",
    "        right_padding = total_padding - left_padding\n",
    "        \n",
    "        ## Apply dynamic padding to x1\n",
    "        x1 = F.pad(x1, (left_padding, right_padding), 'constant', 0)\n",
    "        \n",
    "        ## Concatenate the outputs along the channel dimension\n",
    "        concat = torch.cat([x1, x2], dim=1)\n",
    "        # print(concat.shape)\n",
    "        \n",
    "        ## Reduce the number of channels\n",
    "        reduce = self.reduce_channels(concat)\n",
    "        # print(reduce.shape)\n",
    "        return reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ConvNN 2d all sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ConvNN 2d random sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ConvNN 2d spatial sample "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Branching Network - CNN + ConvNN 2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
