{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross checking with original implementation vs. optimized implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torch\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim \n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "# Train + Data \n",
    "import sys \n",
    "sys.path.append('../Layers')\n",
    "from Conv1d_NN import *\n",
    "from Conv2d_NN import *\n",
    "from Conv1d_NN_spatial import * \n",
    "from Conv2d_NN_spatial import * \n",
    "from ConvNN_CNN_Branching import *\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Distance Matrix Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "def _calculate_distance_matrix(matrix, sqrt=False):\n",
    "    norm_squared = torch.sum(matrix ** 2, dim=1, keepdim=True)\n",
    "    # print(\"norm_squared\", norm_squared.shape)\n",
    "    # print(\"matrix t\", matrix.transpose(2, 1).shape)\n",
    "    # print(\"matrix\", matrix.shape)\n",
    "    # print(\"matrix t * matrix\", torch.bmm(matrix.transpose(2, 1), matrix).shape)\n",
    "    \n",
    "    dot_product = torch.bmm(matrix.transpose(2, 1), matrix)\n",
    "    dist_matrix = norm_squared + norm_squared.transpose(2, 1) - 2 * dot_product\n",
    "    \n",
    "    dist_matrix = torch.clamp(dist_matrix, min=0)  \n",
    "    \n",
    "    if sqrt:\n",
    "        dist_matrix = torch.sqrt(dist_matrix)\n",
    "    return dist_matrix\n",
    "\n",
    "ex = torch.randn(32, 3, 28)\n",
    "o1 = _calculate_distance_matrix(ex)\n",
    "print(o1.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm squared torch.Size([32, 28, 1])\n",
      "norm sqaured no permute torch.Size([32, 1, 28])\n",
      "norm squared sample torch.Size([32, 1, 10])\n",
      "norm squared sample no permute torch.Size([32, 1, 10])\n",
      "dot product torch.Size([32, 28, 10])\n",
      "dist matrix torch.Size([32, 28, 10])\n",
      "torch.Size([32, 28, 10])\n"
     ]
    }
   ],
   "source": [
    "# N Samples\n",
    "def original_calculate_distance_matrix_N(matrix, matrix_sample, sqrt=False):\n",
    "    \"\"\"Calculates distance matrix between two input matrices\"\"\" \n",
    "    norm_squared = torch.sum(matrix ** 2, dim=1, keepdim=True).permute(0, 2, 1)\n",
    "    \n",
    "    print(\"norm squared\", norm_squared.shape)\n",
    "    print(\"norm sqaured no permute\", torch.sum(matrix ** 2, dim=1, keepdim=True).shape)\n",
    "    \n",
    "    norm_squared_sample = torch.sum(matrix_sample ** 2, dim=1, keepdim=True).transpose(2, 1).permute(0, 2, 1)\n",
    "    print(\"norm squared sample\", norm_squared_sample.shape)\n",
    "    print(\"norm squared sample no permute\", torch.sum(matrix_sample ** 2, dim=1, keepdim=True).shape)\n",
    "    \n",
    "    dot_product = torch.bmm(matrix.transpose(2, 1), matrix_sample)\n",
    "    print(\"dot product\", dot_product.shape)\n",
    "    \n",
    "    dist_matrix = norm_squared + norm_squared_sample - 2 * dot_product\n",
    "    print(\"dist matrix\", dist_matrix.shape)\n",
    "    \n",
    "    dist_matrix = torch.clamp(dist_matrix, min=0.0)  \n",
    "    \n",
    "    if sqrt:\n",
    "        dist_matrix = torch.sqrt(dist_matrix)\n",
    "    return dist_matrix\n",
    "\n",
    "ex = torch.randn(32, 3, 28)\n",
    "ex1 = torch.randn(32, 3, 10)\n",
    "o1 = original_calculate_distance_matrix_N(ex, ex1)\n",
    "print(o1.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Similarity Matrix Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All Samples\n",
    "def original_calculate_similarity_matrix(matrix): \n",
    "    \"\"\"Calculates similarity matrix of the input matrix\"\"\"\n",
    "    normalized_matrix = F.normalize(matrix, p=2, dim=1) # p=2 (L2 Norm - Euclidean Distance), dim=1 (across the channels)\n",
    "    dot_product = torch.bmm(normalized_matrix.transpose(2, 1), normalized_matrix)\n",
    "    similarity_matrix = dot_product \n",
    "    return similarity_matrix\n",
    "\n",
    "def optimized_calculate_similarity_matrix(matrix): \n",
    "    normalized_matrix = F.normalized(matrix, p=2, dim=1)\n",
    "    similarity_matrix = torch.bmm(normalized_matrix.transpose(2, 1), normalized_matrix)\n",
    "    return similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N Samples\n",
    "def original_calculate_similarity_matrix_N(matrix, matrix_sample): \n",
    "    \"\"\"Calculates similarity matrix between two input matrices\"\"\"\n",
    "    norm_matrix = F.normalize(matrix, p=2, dim=1) # p=2 (L2 Norm - Euclidean Distance), dim=1 (across the channels)\n",
    "    norm_sample = F.normalize(matrix_sample, p=2, dim=1)\n",
    "    similarity_matrix = torch.bmm(norm_matrix.transpose(2, 1), norm_sample)\n",
    "    return similarity_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Topk Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original matrix shape torch.Size([32, 3, 28])\n",
      "original similarity matrix shape torch.Size([32, 28, 28])\n",
      "prime shape torch.Size([32, 3, 140])\n"
     ]
    }
   ],
   "source": [
    "# All Samples\n",
    "\n",
    "@staticmethod \n",
    "def prime_vmap_2d(matrix, magnitude_matrix, num_nearest_neighbors, maximum): \n",
    "    \"\"\"Vectorization / Vmap Implementation for Nearest Neighbor Tensor 2D\"\"\"\n",
    "    batched_process = torch.vmap(process_batch, in_dims=(0, 0, None), out_dims=0)\n",
    "    prime = batched_process(matrix, magnitude_matrix, num_nearest_neighbors, flatten=True, maximum=maximum)\n",
    "    return prime \n",
    "\n",
    "@staticmethod \n",
    "def prime_vmap_3d(matrix, magnitude_matrix, num_nearest_neighbors, maximum): \n",
    "    \"\"\"Vectorization / Vmap Implementation for Nearest Neighbor Tensor 3D\"\"\"\n",
    "    batched_process = torch.vmap(process_batch, in_dims=(0, 0, None), out_dims=0)\n",
    "    prime = batched_process(matrix, magnitude_matrix, num_nearest_neighbors, flatten=False, maximum=maximum)\n",
    "    return prime\n",
    "\n",
    "@staticmethod \n",
    "def process_batch(matrix, magnitude_matrix, num_nearest_neighbors, flatten, maximum): \n",
    "    \"\"\"Process the batch of matrices by finding the K nearest neighbors with reshaping.\"\"\"\n",
    "    ind = torch.topk(magnitude_matrix, num_nearest_neighbors, largest=maximum).indices \n",
    "    neigh = matrix[:, ind]\n",
    "    if flatten: \n",
    "        reshape = torch.flatten(neigh, start_dim=1)\n",
    "        return reshape\n",
    "    return neigh\n",
    "\n",
    "mat = torch.randn(32, 3, 28)\n",
    "mag = original_calculate_similarity_matrix(mat)\n",
    "prime = prime_vmap_2d(mat, mag, 5, True)\n",
    "\n",
    "print('original matrix shape', mat.shape)\n",
    "print('original similarity matrix shape', mag.shape)\n",
    "print('prime shape', prime.shape)\n",
    "\n",
    "# 28 * 5 = 140 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original matrix shape torch.Size([32, 3, 28])\n",
      "original similarity matrix shape torch.Size([32, 28, 28])\n",
      "prime shape torch.Size([32, 3, 140])\n",
      "tensor([[[ 2.3307,  1.7655,  0.5343,  ...,  0.7687,  0.7188,  1.3099],\n",
      "         [ 0.5816,  0.8979,  0.8920,  ..., -2.1041, -0.6582, -0.9405],\n",
      "         [-0.9124,  0.5200,  0.1506,  ..., -0.5886,  0.5900,  0.9902]],\n",
      "\n",
      "        [[ 1.7783,  0.3377,  0.8736,  ..., -0.4878, -0.6091, -0.3954],\n",
      "         [-0.6327, -0.1128, -0.1515,  ..., -1.2519, -1.8199, -0.7666],\n",
      "         [ 0.2774,  0.1525, -0.0997,  ..., -0.9424, -0.2138, -1.4212]],\n",
      "\n",
      "        [[-1.8757, -0.3479, -2.0375,  ..., -0.1934, -1.3167,  0.4096],\n",
      "         [ 1.4788,  0.5998,  0.9316,  ..., -1.5570, -0.1427, -1.2595],\n",
      "         [-1.7019, -0.7538, -0.4602,  ...,  1.0518,  0.8979,  2.8289]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.2432, -0.2307, -0.5662,  ...,  2.1841,  0.7420,  0.6716],\n",
      "         [ 0.6447,  0.1323, -0.0841,  ...,  0.7177,  1.7078, -0.0492],\n",
      "         [-1.9008, -0.5443, -0.5578,  ...,  0.3047,  0.2020,  0.4818]],\n",
      "\n",
      "        [[-0.3057, -0.6223, -0.1548,  ...,  0.8062,  1.3387,  1.5123],\n",
      "         [-0.2832, -0.7876, -0.8287,  ...,  0.3223,  1.1884, -1.3765],\n",
      "         [-0.0464, -0.3533, -0.2774,  ...,  2.4497,  0.7898,  1.1893]],\n",
      "\n",
      "        [[ 0.6481,  0.5295,  0.2105,  ...,  0.5295, -0.6904,  0.6481],\n",
      "         [ 1.3424,  2.2586,  0.5021,  ...,  2.2586,  1.4897,  1.3424],\n",
      "         [-0.4726, -0.3758, -0.5133,  ..., -0.3758, -0.7779, -0.4726]]])\n"
     ]
    }
   ],
   "source": [
    "torch.set_printoptions(precision=4, sci_mode=False)\n",
    "\n",
    "\n",
    "def prime_brute(matrix, dist_matrix, K): \n",
    "    stack_list = [] \n",
    "    count = 0 \n",
    "    for i in range(matrix.shape[0]): \n",
    "        # print(\"i\", i)\n",
    "        concat_list = [] \n",
    "        for j in range(matrix.shape[2]): \n",
    "            # Get the indices of the nearest neighbors\n",
    "            indices = torch.topk(dist_matrix[i, j, :], K, largest=True).indices\n",
    "            # print(\"indices\", indices)\n",
    "            # Get the nearest neighbors\n",
    "            nearest_neighbors = matrix[i, :, indices]\n",
    "            \n",
    "            # Concatenate the nearest neighbors\n",
    "            concat_list.append(nearest_neighbors)\n",
    "            count += 1\n",
    "        # Concatenate the tensor list to create the convolution matrix \n",
    "        # print()\n",
    "        concat = torch.cat(concat_list, dim=1)\n",
    "        stack_list.append(concat)\n",
    "    prime = torch.stack(stack_list, dim= 0)\n",
    "    # print(\"count\", count)\n",
    "    return prime\n",
    "        \n",
    "\n",
    "mat = torch.randn(32, 3, 28)\n",
    "sim = original_calculate_similarity_matrix(mat)\n",
    "prime_b = prime_brute(mat, sim, 5)\n",
    "print('original matrix shape', mat.shape)\n",
    "print('original similarity matrix shape', sim.shape)\n",
    "print('prime shape', prime.shape)\n",
    "print(prime_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topk indices:  torch.Size([32, 28, 5])\n",
      "batch_size:  32\n",
      "channels:  3\n",
      "tokens:  28\n",
      "K:  5\n",
      "tensor([[[[ 0, 19, 13, 27,  9],\n",
      "          [ 1,  3, 14,  8, 16],\n",
      "          [ 2, 12, 27, 26,  6],\n",
      "          ...,\n",
      "          [25, 22, 13, 17, 24],\n",
      "          [26,  6, 11, 15, 12],\n",
      "          [27, 12,  2, 26,  6]],\n",
      "\n",
      "         [[ 0, 19, 13, 27,  9],\n",
      "          [ 1,  3, 14,  8, 16],\n",
      "          [ 2, 12, 27, 26,  6],\n",
      "          ...,\n",
      "          [25, 22, 13, 17, 24],\n",
      "          [26,  6, 11, 15, 12],\n",
      "          [27, 12,  2, 26,  6]],\n",
      "\n",
      "         [[ 0, 19, 13, 27,  9],\n",
      "          [ 1,  3, 14,  8, 16],\n",
      "          [ 2, 12, 27, 26,  6],\n",
      "          ...,\n",
      "          [25, 22, 13, 17, 24],\n",
      "          [26,  6, 11, 15, 12],\n",
      "          [27, 12,  2, 26,  6]]],\n",
      "\n",
      "\n",
      "        [[[ 0,  6, 24, 15,  2],\n",
      "          [ 1, 10, 21, 12,  3],\n",
      "          [ 2, 24, 26,  0, 15],\n",
      "          ...,\n",
      "          [25, 19, 22,  4, 15],\n",
      "          [26, 18, 22,  2, 15],\n",
      "          [27, 14,  3, 20, 10]],\n",
      "\n",
      "         [[ 0,  6, 24, 15,  2],\n",
      "          [ 1, 10, 21, 12,  3],\n",
      "          [ 2, 24, 26,  0, 15],\n",
      "          ...,\n",
      "          [25, 19, 22,  4, 15],\n",
      "          [26, 18, 22,  2, 15],\n",
      "          [27, 14,  3, 20, 10]],\n",
      "\n",
      "         [[ 0,  6, 24, 15,  2],\n",
      "          [ 1, 10, 21, 12,  3],\n",
      "          [ 2, 24, 26,  0, 15],\n",
      "          ...,\n",
      "          [25, 19, 22,  4, 15],\n",
      "          [26, 18, 22,  2, 15],\n",
      "          [27, 14,  3, 20, 10]]],\n",
      "\n",
      "\n",
      "        [[[ 0, 21, 26,  5, 18],\n",
      "          [ 1, 15, 12,  7, 22],\n",
      "          [ 2, 14,  6,  7, 27],\n",
      "          ...,\n",
      "          [25, 12, 13,  3, 19],\n",
      "          [26,  0, 24, 21,  4],\n",
      "          [27,  6,  2, 23, 10]],\n",
      "\n",
      "         [[ 0, 21, 26,  5, 18],\n",
      "          [ 1, 15, 12,  7, 22],\n",
      "          [ 2, 14,  6,  7, 27],\n",
      "          ...,\n",
      "          [25, 12, 13,  3, 19],\n",
      "          [26,  0, 24, 21,  4],\n",
      "          [27,  6,  2, 23, 10]],\n",
      "\n",
      "         [[ 0, 21, 26,  5, 18],\n",
      "          [ 1, 15, 12,  7, 22],\n",
      "          [ 2, 14,  6,  7, 27],\n",
      "          ...,\n",
      "          [25, 12, 13,  3, 19],\n",
      "          [26,  0, 24, 21,  4],\n",
      "          [27,  6,  2, 23, 10]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0, 19,  1, 15,  5],\n",
      "          [ 1, 15,  0, 19,  9],\n",
      "          [ 2, 22, 20, 14, 21],\n",
      "          ...,\n",
      "          [25, 24, 10,  4, 16],\n",
      "          [26, 10, 11, 17, 19],\n",
      "          [27, 17,  4, 13, 14]],\n",
      "\n",
      "         [[ 0, 19,  1, 15,  5],\n",
      "          [ 1, 15,  0, 19,  9],\n",
      "          [ 2, 22, 20, 14, 21],\n",
      "          ...,\n",
      "          [25, 24, 10,  4, 16],\n",
      "          [26, 10, 11, 17, 19],\n",
      "          [27, 17,  4, 13, 14]],\n",
      "\n",
      "         [[ 0, 19,  1, 15,  5],\n",
      "          [ 1, 15,  0, 19,  9],\n",
      "          [ 2, 22, 20, 14, 21],\n",
      "          ...,\n",
      "          [25, 24, 10,  4, 16],\n",
      "          [26, 10, 11, 17, 19],\n",
      "          [27, 17,  4, 13, 14]]],\n",
      "\n",
      "\n",
      "        [[[ 0, 16, 18, 25, 26],\n",
      "          [ 1, 27,  4,  5,  8],\n",
      "          [ 2,  3, 14, 12,  6],\n",
      "          ...,\n",
      "          [25, 18, 16, 15,  0],\n",
      "          [26, 23, 24,  9,  0],\n",
      "          [27,  1,  4,  5, 17]],\n",
      "\n",
      "         [[ 0, 16, 18, 25, 26],\n",
      "          [ 1, 27,  4,  5,  8],\n",
      "          [ 2,  3, 14, 12,  6],\n",
      "          ...,\n",
      "          [25, 18, 16, 15,  0],\n",
      "          [26, 23, 24,  9,  0],\n",
      "          [27,  1,  4,  5, 17]],\n",
      "\n",
      "         [[ 0, 16, 18, 25, 26],\n",
      "          [ 1, 27,  4,  5,  8],\n",
      "          [ 2,  3, 14, 12,  6],\n",
      "          ...,\n",
      "          [25, 18, 16, 15,  0],\n",
      "          [26, 23, 24,  9,  0],\n",
      "          [27,  1,  4,  5, 17]]],\n",
      "\n",
      "\n",
      "        [[[ 0, 19, 21, 18,  2],\n",
      "          [ 1, 20,  6, 12, 14],\n",
      "          [ 2,  3, 21, 25,  8],\n",
      "          ...,\n",
      "          [25,  2, 27, 19,  3],\n",
      "          [26, 13,  8,  4,  9],\n",
      "          [27,  5, 19, 25,  0]],\n",
      "\n",
      "         [[ 0, 19, 21, 18,  2],\n",
      "          [ 1, 20,  6, 12, 14],\n",
      "          [ 2,  3, 21, 25,  8],\n",
      "          ...,\n",
      "          [25,  2, 27, 19,  3],\n",
      "          [26, 13,  8,  4,  9],\n",
      "          [27,  5, 19, 25,  0]],\n",
      "\n",
      "         [[ 0, 19, 21, 18,  2],\n",
      "          [ 1, 20,  6, 12, 14],\n",
      "          [ 2,  3, 21, 25,  8],\n",
      "          ...,\n",
      "          [25,  2, 27, 19,  3],\n",
      "          [26, 13,  8,  4,  9],\n",
      "          [27,  5, 19, 25,  0]]]])\n",
      "indices_expanded shape: torch.Size([32, 3, 28, 5])\n",
      "\n",
      "prime_new shape: torch.Size([32, 3, 140])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "_, topk_indices = torch.topk(sim, k=5, dim=2, largest=True)  \n",
    "print(\"topk indices: \", topk_indices.shape)  \n",
    "\n",
    "\n",
    "batch_size, channels, tokens = mat.shape\n",
    "K = topk_indices.shape[-1]  \n",
    "print(\"batch_size: \", batch_size)\n",
    "print(\"channels: \", channels)\n",
    "print(\"tokens: \", tokens)\n",
    "print(\"K: \", K)\n",
    "\n",
    "# Expand topk_indices: add a channel dimension at dim=1\n",
    "indices_expanded = topk_indices.unsqueeze(1).expand(batch_size, channels, tokens, K)\n",
    "print(indices_expanded)\n",
    "\n",
    "print(\"indices_expanded shape:\", indices_expanded.shape)  # torch.Size([32, 3, 28, 5])\n",
    "\n",
    "\n",
    "\n",
    "print()\n",
    "\n",
    "# Create index tensors for batch and channel dimensions:\n",
    "batch_indices = torch.arange(batch_size).view(batch_size, 1, 1, 1).expand(batch_size, channels, tokens, K)\n",
    "\n",
    "channel_indices = torch.arange(channels).view(1, channels, 1, 1).expand(batch_size, channels, tokens, K)\n",
    "\n",
    "# Now use advanced indexing:\n",
    "# For each [b, c, i, j], we select mat[b, c, indices_expanded[b, c, i, j]]\n",
    "prime = mat[batch_indices, channel_indices, indices_expanded]\n",
    "# prime will have shape [32, 3, 28, 5]\n",
    "\n",
    "# Finally, reshape (flatten the token and neighbor dimensions) to get [32, 3, 28*5] = [32, 3, 140]\n",
    "prime_new = prime.view(batch_size, channels, -1)\n",
    "\n",
    "print(\"prime_new shape:\", prime_new.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.allclose(prime_b, prime_new))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimized check\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(precision=4, sci_mode=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_similarity_matrix(matrix): \n",
    "    \"\"\"Calculates similarity matrix of the input matrix\"\"\"\n",
    "    normalized_matrix = F.normalize(matrix, p=2, dim=1) # p=2 (L2 Norm - Euclidean Distance), dim=1 (across the channels)\n",
    "    dot_product = torch.bmm(normalized_matrix.transpose(2, 1), normalized_matrix)\n",
    "    similarity_matrix = dot_product \n",
    "    return similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prime_brute(matrix, dist_matrix, K): \n",
    "    stack_list = [] \n",
    "    count = 0 \n",
    "    for i in range(matrix.shape[0]): \n",
    "        concat_list = [] \n",
    "        for j in range(matrix.shape[2]): \n",
    "            indices = torch.topk(dist_matrix[i, j, :], K, largest=True).indices\n",
    "\n",
    "            nearest_neighbors = matrix[i, :, indices]\n",
    "            \n",
    "            concat_list.append(nearest_neighbors)\n",
    "            count += 1\n",
    "        concat = torch.cat(concat_list, dim=1)\n",
    "        stack_list.append(concat)\n",
    "    prime = torch.stack(stack_list, dim= 0)\n",
    "    return prime\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All Samples\n",
    "\n",
    "@staticmethod \n",
    "def prime_vmap_2d(matrix, magnitude_matrix, num_nearest_neighbors, maximum): \n",
    "    \"\"\"Vectorization / Vmap Implementation for Nearest Neighbor Tensor 2D\"\"\"\n",
    "    batched_process = torch.vmap(process_batch, in_dims=(0, 0, None), out_dims=0)\n",
    "    prime = batched_process(matrix, magnitude_matrix, num_nearest_neighbors, flatten=True, maximum=maximum)\n",
    "    return prime \n",
    "\n",
    "@staticmethod \n",
    "def prime_vmap_3d(matrix, magnitude_matrix, num_nearest_neighbors, maximum): \n",
    "    \"\"\"Vectorization / Vmap Implementation for Nearest Neighbor Tensor 3D\"\"\"\n",
    "    batched_process = torch.vmap(process_batch, in_dims=(0, 0, None), out_dims=0)\n",
    "    prime = batched_process(matrix, magnitude_matrix, num_nearest_neighbors, flatten=False, maximum=maximum)\n",
    "    return prime\n",
    "\n",
    "@staticmethod \n",
    "def process_batch(matrix, magnitude_matrix, num_nearest_neighbors, flatten, maximum): \n",
    "    \"\"\"Process the batch of matrices by finding the K nearest neighbors with reshaping.\"\"\"\n",
    "    ind = torch.topk(magnitude_matrix, num_nearest_neighbors, largest=maximum).indices \n",
    "    neigh = matrix[:, ind]\n",
    "    if flatten: \n",
    "        reshape = torch.flatten(neigh, start_dim=1)\n",
    "        return reshape\n",
    "    return neigh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prime_optimized(matrix, dist_matrix, K=5, maximum=False):\n",
    "\n",
    "    _, topk_indices = torch.topk(dist_matrix, k=K, dim=2, largest=True)  \n",
    "\n",
    "\n",
    "    batch_size, channels, tokens = matrix.shape\n",
    "    K = topk_indices.shape[-1]  \n",
    "\n",
    "    indices_expanded = topk_indices.unsqueeze(1).expand(batch_size, channels, tokens, K)\n",
    "\n",
    "    batch_indices = torch.arange(batch_size).view(batch_size, 1, 1, 1).expand(batch_size, channels, tokens, K)\n",
    "\n",
    "    channel_indices = torch.arange(channels).view(1, channels, 1, 1).expand(batch_size, channels, tokens, K)\n",
    "\n",
    "    prime = matrix[batch_indices, channel_indices, indices_expanded]\n",
    "\n",
    "    prime_new = prime.view(batch_size, channels, -1)\n",
    "\n",
    "    return prime_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _prime(matrix, magnitude_matrix, K, maximum):\n",
    "    b, c, t = matrix.shape \n",
    "\n",
    "    _, topk_indices = torch.topk(magnitude_matrix, k = K, dim=2, largest=maximum)\n",
    "    \n",
    "    tk = topk_indices.shape[-1]\n",
    "    \n",
    "    assert K == tk, \"Error: K must be same as tk. K == tk.\"\n",
    "    \n",
    "    indices_expanded = topk_indices.unsqueeze(1).expand(b, c, t, tk)\n",
    "    batch_indices = torch.arange(b).view(b, 1, 1, 1).expand(b, c, t, tk)\n",
    "    channel_indices = torch.arange(c).view(1, c, 1, 1).expand(b, c, t, tk)\n",
    "    \n",
    "    prime = matrix[batch_indices, channel_indices, indices_expanded]\n",
    "    prime = prime.view(b, c, -1)\n",
    "    return prime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original matrix shape torch.Size([32, 3, 28])\n",
      "original similarity matrix shape torch.Size([32, 28, 28])\n",
      "\n",
      "prime brute shape torch.Size([32, 3, 140])\n",
      "prime optimized shape torch.Size([32, 3, 140])\n",
      "prime vmap shape torch.Size([32, 3, 140])\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "mat = torch.randn(32, 3, 28)\n",
    "sim = calculate_similarity_matrix(mat)\n",
    "prime_b = prime_brute(mat, sim, 5)\n",
    "prime_o = prime_optimized(mat, sim, 5)\n",
    "prime_f = prime_vmap_2d(mat, sim, 5, True)\n",
    "prime_ = _prime(mat, sim, 5, True)\n",
    "print('original matrix shape', mat.shape)\n",
    "print('original similarity matrix shape', sim.shape)\n",
    "print()\n",
    "print('prime brute shape', prime_b.shape)\n",
    "print('prime optimized shape', prime_o.shape)\n",
    "print('prime vmap shape', prime_f.shape)\n",
    "\n",
    "print(torch.allclose(prime_b, prime_o))\n",
    "print(torch.allclose(prime_b, prime_f))\n",
    "print(torch.allclose(prime_o, prime_f))\n",
    "print(torch.allclose(prime_b, prime_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### N Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(precision=4, sci_mode=False)\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N Samples\n",
    "def calculate_similarity_matrix_N(matrix, matrix_sample): \n",
    "    \"\"\"Calculates similarity matrix between two input matrices\"\"\"\n",
    "    norm_matrix = F.normalize(matrix, p=2, dim=1) # p=2 (L2 Norm - Euclidean Distance), dim=1 (across the channels)\n",
    "    norm_sample = F.normalize(matrix_sample, p=2, dim=1)\n",
    "    similarity_matrix = torch.bmm(norm_matrix.transpose(2, 1), norm_sample)\n",
    "    return similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prime_vmap_2d_N(matrix, magnitude_matrix, num_nearest_neighbors, rand_idx, maximum): \n",
    "    \"\"\"Vectorization / Vmap Implementation for Nearest Neighbor Tensor 2D\"\"\"\n",
    "    batched_process = torch.vmap(process_batch_N, in_dims=(0, 0, None, None), out_dims=0)\n",
    "    prime = batched_process(matrix, magnitude_matrix, num_nearest_neighbors, rand_idx, flatten=True, maximum=maximum)\n",
    "    return prime \n",
    "\n",
    "def prime_vmap_3d_N(matrix, magnitude_matrix, num_nearest_neighbors, rand_idx, maximum): \n",
    "    \"\"\"Vectorization / Vmap Implementation for Nearest Neighbor Tensor 3D\"\"\"\n",
    "    batched_process = torch.vmap(process_batch_N, in_dims=(0, 0, None, None), out_dims=0)\n",
    "    prime = batched_process(matrix, magnitude_matrix, num_nearest_neighbors, rand_idx, flatten=False, maximum=maximum)\n",
    "    return prime\n",
    "\n",
    "def process_batch_N(matrix, magnitude_matrix, num_nearest_neighbors, rand_idx, flatten, maximum): \n",
    "    \"\"\"Process the batch of matrices by finding the K nearest neighbors with reshaping.\"\"\"\n",
    "    topk_ind = torch.topk(magnitude_matrix, num_nearest_neighbors - 1, largest=maximum).indices\n",
    "    device = topk_ind.device\n",
    "    rand_idx = rand_idx.to(device) # same device as topk_ind\n",
    "    mapped_tensor = rand_idx[topk_ind] \n",
    "    index_tensor = torch.arange(0, matrix.shape[1], device=device).unsqueeze(1) # shape [40, 1]\n",
    "    final_tensor = torch.cat([index_tensor, mapped_tensor], dim=1)\n",
    "    neigh = matrix[:, final_tensor] \n",
    "    if flatten: \n",
    "        reshape = torch.flatten(neigh, start_dim=1)\n",
    "        return reshape\n",
    "    return neigh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _prime_N(matrix, magnitude_matrix, K, rand_idx, maximum):\n",
    "    \"\"\"\n",
    "    Create prime tensor for the N-samples case.\n",
    "    \n",
    "    Args:\n",
    "        matrix (torch.Tensor): Input tensor of shape [b, c, t].\n",
    "        magnitude_matrix (torch.Tensor): Magnitude matrix of shape [b, t, s] \n",
    "                                           (where s is the number of sampled tokens).\n",
    "        K (int): Total number of neighbors to consider (including the self index).\n",
    "        rand_idx (torch.Tensor): 1D tensor of length s containing the sampled indices.\n",
    "        maximum (bool): If True, select the largest values (e.g. for similarity); if False, select the smallest (e.g. for distance).\n",
    "        \n",
    "    Returns:\n",
    "        torch.Tensor: A prime tensor of shape [b, c, t*K].\n",
    "    \"\"\"\n",
    "    b, c, t = matrix.shape\n",
    "    # print(\"batch \", b)\n",
    "    # print(\"channel \", c)\n",
    "    # print(\"token \", t)\n",
    "        \n",
    "\n",
    "    _, topk_indices = torch.topk(magnitude_matrix, k=K - 1, dim=2, largest=maximum)\n",
    "    tk = topk_indices.shape[-1]\n",
    "    assert K == tk + 1, \"Error: K must be same as tk + 1. K == tk + 1.\"\n",
    "    # print(\"topk_indices shape: \", topk_indices.shape)  # torch.Size([32, 28, 4])\n",
    "    \n",
    "    mapped_tensor = rand_idx[topk_indices]\n",
    "    # print(\"mapped_tensor shape: \", mapped_tensor.shape)  # torch.Size([32, 28, 4])\n",
    "    # print(mapped_tensor)\n",
    "\n",
    "    token_indices = torch.arange(t, device=matrix.device).view(1, t, 1).expand(b, t, 1)\n",
    "    # print(\"token_indices shape: \", token_indices.shape)  # torch.Size([32, 28, 1])\n",
    "    # \n",
    "    \n",
    "    final_indices = torch.cat([token_indices, mapped_tensor], dim=2)\n",
    "    # print(\"final_indices shape: \", final_indices.shape)  # torch.Size([32, 28, 5])\n",
    "\n",
    "    indices_expanded = final_indices.unsqueeze(1).expand(b, c, t, K)\n",
    "    # print(\"indices_expanded shape: \", indices_expanded.shape)  # torch.Size([32, 3, 28, 5])\n",
    "    \n",
    "    batch_indices = torch.arange(b, device=matrix.device).view(b, 1, 1, 1).expand(b, c, t, K)\n",
    "    channel_indices = torch.arange(c, device=matrix.device).view(1, c, 1, 1).expand(b, c, t, K)\n",
    "    \n",
    "\n",
    "    prime = matrix[batch_indices, channel_indices, indices_expanded]  \n",
    "    \n",
    "    prime = prime.view(b, c, -1)\n",
    "    return prime\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p1 shape torch.Size([32, 3, 140])\n",
      "o1 shape torch.Size([32, 3, 140])\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "samples = 10\n",
    "x1 = torch.randn(32, 3, 28)\n",
    "\n",
    "\n",
    "rand_idx = torch.tensor(np.random.choice(x1.shape[2], samples, replace=False)) # list \n",
    "x1_sample = x1[:, :, rand_idx]\n",
    "\n",
    "\n",
    "sim = calculate_similarity_matrix_N(x1, x1_sample)\n",
    "p1 = prime_vmap_2d_N(x1, sim, 5, rand_idx, True)\n",
    "o1 = _prime_N(x1, sim, 5, rand_idx, True)\n",
    "print('p1 shape', p1.shape)\n",
    "print('o1 shape', o1.shape)\n",
    "print(torch.allclose(p1, o1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rand_idx tensor([20,  4,  0, 26,  6, 15,  8, 27,  9, 10])\n",
      "rand_idx_1 tensor([23, 11,  1, 18, 15, 17,  7, 10,  0,  9])\n"
     ]
    }
   ],
   "source": [
    "rand_idx = torch.tensor(np.random.choice(x1.shape[2], samples, replace=False)) # list \n",
    "print('rand_idx', rand_idx)\n",
    "\n",
    "rand_idx_1 = torch.randperm(x1.shape[2], device=x1.device)[:samples]\n",
    "\n",
    "print('rand_idx_1', rand_idx_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[    -1.0198,     -0.7261,     -0.3265,  ...,      0.7224,\n",
      "               0.2761,      0.5273],\n",
      "         [     0.3269,      0.7684,      0.5119,  ...,      0.1771,\n",
      "               0.9181,      1.8624],\n",
      "         [     0.9327,      0.5142,      1.9450,  ...,     -1.0296,\n",
      "               0.2873,      0.7453]],\n",
      "\n",
      "        [[     1.4551,      0.9084,      0.4332,  ...,     -0.3708,\n",
      "               0.2935,     -1.3222],\n",
      "         [    -0.4963,     -0.3979,     -0.0089,  ...,      0.4365,\n",
      "               0.1287,      0.3454],\n",
      "         [    -1.4958,     -0.5424,     -0.7425,  ...,     -1.2643,\n",
      "              -0.3374,     -2.2412]],\n",
      "\n",
      "        [[    -0.2315,      1.1534,      1.4498,  ...,      1.1534,\n",
      "               1.4498,     -1.3786],\n",
      "         [     0.4918,     -0.4089,     -0.1386,  ...,     -0.4089,\n",
      "              -0.1386,      0.9560],\n",
      "         [     1.9510,      1.9407,      1.8860,  ...,      1.9407,\n",
      "               1.8860,      0.1638]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[     0.1174,      0.0060,      1.4110,  ...,      1.4110,\n",
      "              -1.4104,      0.1706],\n",
      "         [     0.5836,      0.0022,     -1.0200,  ...,     -1.0200,\n",
      "               0.2573,     -0.3821],\n",
      "         [     0.4170,      0.5461,      0.7704,  ...,      0.7704,\n",
      "              -0.9164,     -1.4303]],\n",
      "\n",
      "        [[     0.8563,      0.8493,      0.5917,  ...,      0.5917,\n",
      "              -0.4114,      0.2946],\n",
      "         [    -0.3981,     -0.9105,     -0.7929,  ...,     -0.7929,\n",
      "              -0.2794,      1.1326],\n",
      "         [     0.0576,     -0.8912,      0.9700,  ...,      0.9700,\n",
      "               0.3208,     -1.3650]],\n",
      "\n",
      "        [[    -0.4207,      0.1891,     -0.5483,  ...,     -1.1443,\n",
      "               0.6150,     -0.0492],\n",
      "         [     2.1306,      1.5159,     -0.6896,  ...,     -0.9537,\n",
      "              -0.3050,     -1.0708],\n",
      "         [    -2.1327,      0.3161,     -1.9066,  ...,     -0.2652,\n",
      "               1.2264,     -0.5997]]])\n"
     ]
    }
   ],
   "source": [
    "print(p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[    -1.0198,     -0.7261,     -0.3265,  ...,      0.7224,\n",
      "               0.2761,      0.5273],\n",
      "         [     0.3269,      0.7684,      0.5119,  ...,      0.1771,\n",
      "               0.9181,      1.8624],\n",
      "         [     0.9327,      0.5142,      1.9450,  ...,     -1.0296,\n",
      "               0.2873,      0.7453]],\n",
      "\n",
      "        [[     1.4551,      0.9084,      0.4332,  ...,     -0.3708,\n",
      "               0.2935,     -1.3222],\n",
      "         [    -0.4963,     -0.3979,     -0.0089,  ...,      0.4365,\n",
      "               0.1287,      0.3454],\n",
      "         [    -1.4958,     -0.5424,     -0.7425,  ...,     -1.2643,\n",
      "              -0.3374,     -2.2412]],\n",
      "\n",
      "        [[    -0.2315,      1.1534,      1.4498,  ...,      1.1534,\n",
      "               1.4498,     -1.3786],\n",
      "         [     0.4918,     -0.4089,     -0.1386,  ...,     -0.4089,\n",
      "              -0.1386,      0.9560],\n",
      "         [     1.9510,      1.9407,      1.8860,  ...,      1.9407,\n",
      "               1.8860,      0.1638]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[     0.1174,      0.0060,      1.4110,  ...,      1.4110,\n",
      "              -1.4104,      0.1706],\n",
      "         [     0.5836,      0.0022,     -1.0200,  ...,     -1.0200,\n",
      "               0.2573,     -0.3821],\n",
      "         [     0.4170,      0.5461,      0.7704,  ...,      0.7704,\n",
      "              -0.9164,     -1.4303]],\n",
      "\n",
      "        [[     0.8563,      0.8493,      0.5917,  ...,      0.5917,\n",
      "              -0.4114,      0.2946],\n",
      "         [    -0.3981,     -0.9105,     -0.7929,  ...,     -0.7929,\n",
      "              -0.2794,      1.1326],\n",
      "         [     0.0576,     -0.8912,      0.9700,  ...,      0.9700,\n",
      "               0.3208,     -1.3650]],\n",
      "\n",
      "        [[    -0.4207,      0.1891,     -0.5483,  ...,     -1.1443,\n",
      "               0.6150,     -0.0492],\n",
      "         [     2.1306,      1.5159,     -0.6896,  ...,     -0.9537,\n",
      "              -0.3050,     -1.0708],\n",
      "         [    -2.1327,      0.3161,     -1.9066,  ...,     -0.2652,\n",
      "               1.2264,     -0.5997]]])\n"
     ]
    }
   ],
   "source": [
    "print(o1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization for function: prime\n",
    "- This function gathers the K nearest neighbors from each element and creates a new matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i. All Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _prime_v3(matrix, magnitude_matrix, K, maximum):\n",
    "    b, c, t = matrix.shape\n",
    "    # Direct indexing approach that avoids intermediate tensors\n",
    "    _, indices = torch.topk(magnitude_matrix, k=K, dim=2, largest=maximum)\n",
    "    \n",
    "    # Pre-allocate output\n",
    "    result = torch.empty(b, c, t*K, dtype=matrix.dtype, device=matrix.device)\n",
    "    \n",
    "    # More efficient batched indexing\n",
    "    for i in range(b):\n",
    "        for j in range(t):\n",
    "            idx = indices[i, j]  # [K]\n",
    "            result[i, :, j*K:(j+1)*K] = matrix[i, :, idx]\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.jit.script\n",
    "def _prime_v2(matrix: torch.Tensor, magnitude_matrix: torch.Tensor, \n",
    "             K: int, maximum: bool) -> torch.Tensor:\n",
    "    b, c, t = matrix.shape\n",
    "    # Get top-K indices: shape [b, t, K]\n",
    "    _, topk_indices = torch.topk(magnitude_matrix, k=K, dim=2, largest=maximum)\n",
    "    \n",
    "    # Expand indices to add channel dimension: [b, 1, t, K] then expand to [b, c, t, K]\n",
    "    topk_indices_exp = topk_indices.unsqueeze(1).expand(b, c, t, K)\n",
    "    \n",
    "    # Unsqueeze matrix and expand so that the gathered dimension has size K.\n",
    "    # matrix.unsqueeze(-1) yields shape [b, c, t, 1]\n",
    "    # Then expand to [b, c, t, K] and force contiguous memory.\n",
    "    matrix_expanded = matrix.unsqueeze(-1).expand(b, c, t, K).contiguous()\n",
    "    \n",
    "    # Gather along the token dimension (dim=2) using the expanded indices.\n",
    "    prime = torch.gather(matrix_expanded, dim=2, index=topk_indices_exp)\n",
    "    \n",
    "    # Flatten the token and neighbor dimensions: [b, c, t*K]\n",
    "    prime = prime.view(b, c, -1)\n",
    "    return prime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.jit.script\n",
    "def _prime(matrix: torch.Tensor, magnitude_matrix: torch.Tensor, K: int, maximum: bool) -> torch.Tensor:\n",
    "    b, c, t = matrix.shape \n",
    "\n",
    "    _, topk_indices = torch.topk(magnitude_matrix, k = K, dim=2, largest=maximum)\n",
    "    \n",
    "    tk = topk_indices.shape[-1]\n",
    "    \n",
    "    assert K == tk, \"Error: K must be same as tk. K == tk.\"\n",
    "    \n",
    "    indices_expanded = topk_indices.unsqueeze(1).expand(b, c, t, tk)\n",
    "    batch_indices = torch.arange(b).view(b, 1, 1, 1).expand(b, c, t, tk)\n",
    "    channel_indices = torch.arange(c).view(1, c, 1, 1).expand(b, c, t, tk)\n",
    "    \n",
    "    prime = matrix[batch_indices, channel_indices, indices_expanded]\n",
    "    prime = prime.view(b, c, -1)\n",
    "    return prime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original matrix shape torch.Size([32, 3, 28])\n",
      "original similarity matrix shape torch.Size([32, 28, 28])\n",
      "prime vmap shape torch.Size([32, 3, 140])\n",
      "prime shape torch.Size([32, 3, 140])\n",
      "prime v2 shape torch.Size([32, 3, 140])\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "mat = torch.randn(32, 3, 28)\n",
    "sim = calculate_similarity_matrix(mat)\n",
    "prime_f = prime_vmap_2d(mat, sim, 5, True)\n",
    "prime_ = _prime(mat, sim, 5, True)\n",
    "prime_v2_ = _prime_v2(mat, sim, 5, True)\n",
    "prime_v3_ = _prime_v3(mat, sim, 5, True)\n",
    "\n",
    "print('original matrix shape', mat.shape)\n",
    "print('original similarity matrix shape', sim.shape)\n",
    "print('prime vmap shape', prime_f.shape)\n",
    "print('prime shape', prime_.shape)\n",
    "print('prime v2 shape', prime_v2_.shape)\n",
    "print(torch.allclose(prime_f, prime_))\n",
    "print(torch.allclose(prime_f, prime_v2_))\n",
    "print(torch.allclose(prime_, prime_v2_))\n",
    "print(torch.allclose(prime_f, prime_v3_))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ii. N Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.jit.script\n",
    "def _prime_N_v3(matrix: torch.Tensor, magnitude_matrix: torch.Tensor, \n",
    "                               K: int, rand_idx: torch.Tensor, maximum: bool) -> torch.Tensor:\n",
    "    b, c, t = matrix.shape\n",
    "\n",
    "    # Get top-(K-1) indices\n",
    "    _, topk_indices = torch.topk(magnitude_matrix, k=K - 1, dim=2, largest=maximum)\n",
    "    tk = topk_indices.shape[-1]\n",
    "    assert K == tk + 1, \"Error: K must be same as tk + 1. K == tk + 1.\"\n",
    "\n",
    "    # Map indices\n",
    "    mapped_tensor = rand_idx[topk_indices]\n",
    "\n",
    "    # Create self indices for each token\n",
    "    token_indices = torch.arange(t, device=matrix.device).view(1, t, 1).expand(b, t, 1)\n",
    "\n",
    "    # Concatenate self index with neighbor indices\n",
    "    final_indices = torch.cat([token_indices, mapped_tensor], dim=2)\n",
    "\n",
    "    # Pre-allocate output tensor\n",
    "    result = torch.empty(b, c, t*K, device=matrix.device, dtype=matrix.dtype)\n",
    "    \n",
    "    # Process each batch and token position\n",
    "    for i in range(b):\n",
    "        for j in range(t):\n",
    "            # Get the K indices for this position\n",
    "            indices = final_indices[i, j]  # Shape: [K]\n",
    "            # Fill the result tensor directly\n",
    "            result[i, :, j*K:(j+1)*K] = matrix[i, :, indices]\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.jit.script\n",
    "def _prime_N_v2(matrix: torch.Tensor, magnitude_matrix: torch.Tensor, K: int, rand_idx: torch.Tensor, maximum: bool) -> torch.Tensor:\n",
    "    b, c, t = matrix.shape\n",
    "\n",
    "    # Get top-(K-1) indices from the magnitude matrix; shape: [b, t, K-1]\n",
    "    _, topk_indices = torch.topk(magnitude_matrix, k=K - 1, dim=2, largest=maximum)\n",
    "    tk = topk_indices.shape[-1]\n",
    "    assert K == tk + 1, \"Error: K must be same as tk + 1. K == tk + 1.\"\n",
    "\n",
    "    # Map indices from the sampled space to the full token indices using rand_idx.\n",
    "    # mapped_tensor will have shape: [b, t, K-1]\n",
    "    mapped_tensor = rand_idx[topk_indices]\n",
    "\n",
    "    # Create self indices for each token; shape: [1, t, 1] then expand to [b, t, 1]\n",
    "    token_indices = torch.arange(t, device=matrix.device).view(1, t, 1).expand(b, t, 1)\n",
    "\n",
    "    # Concatenate self index with neighbor indices to form final indices; shape: [b, t, K]\n",
    "    final_indices = torch.cat([token_indices, mapped_tensor], dim=2)\n",
    "\n",
    "    # Expand final_indices to include the channel dimension; result shape: [b, c, t, K]\n",
    "    indices_expanded = final_indices.unsqueeze(1).expand(b, c, t, K)\n",
    "\n",
    "    # Expand matrix to shape [b, c, t, 1] and then to [b, c, t, K] (ensuring contiguous memory)\n",
    "    matrix_expanded = matrix.unsqueeze(-1).expand(b, c, t, K).contiguous()\n",
    "\n",
    "    # Gather neighbor features along the token dimension (dim=2)\n",
    "    prime = torch.gather(matrix_expanded, dim=2, index=indices_expanded)  # shape: [b, c, t, K]\n",
    "\n",
    "    # Flatten the token and neighbor dimensions into one: [b, c, t*K]\n",
    "    prime = prime.view(b, c, -1)\n",
    "    return prime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.jit.script\n",
    "def _prime_N(matrix: torch.Tensor, magnitude_matrix: torch.Tensor, K: int, rand_idx: torch.Tensor, maximum: bool) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Create prime tensor for the N-samples case.\n",
    "    \n",
    "    Args:\n",
    "        matrix (torch.Tensor): Input tensor of shape [b, c, t].\n",
    "        magnitude_matrix (torch.Tensor): Magnitude matrix of shape [b, t, s] \n",
    "                                           (where s is the number of sampled tokens).\n",
    "        K (int): Total number of neighbors to consider (including the self index).\n",
    "        rand_idx (torch.Tensor): 1D tensor of length s containing the sampled indices.\n",
    "        maximum (bool): If True, select the largest values (e.g. for similarity); if False, select the smallest (e.g. for distance).\n",
    "        \n",
    "    Returns:\n",
    "        torch.Tensor: A prime tensor of shape [b, c, t*K].\n",
    "    \"\"\"\n",
    "    b, c, t = matrix.shape\n",
    "    # print(\"batch \", b)\n",
    "    # print(\"channel \", c)\n",
    "    # print(\"token \", t)\n",
    "        \n",
    "\n",
    "    _, topk_indices = torch.topk(magnitude_matrix, k=K - 1, dim=2, largest=maximum)\n",
    "    tk = topk_indices.shape[-1]\n",
    "    assert K == tk + 1, \"Error: K must be same as tk + 1. K == tk + 1.\"\n",
    "    # print(\"topk_indices shape: \", topk_indices.shape)  # torch.Size([32, 28, 4])\n",
    "    \n",
    "    mapped_tensor = rand_idx[topk_indices]\n",
    "    # print(\"mapped_tensor shape: \", mapped_tensor.shape)  # torch.Size([32, 28, 4])\n",
    "    # print(mapped_tensor)\n",
    "\n",
    "    token_indices = torch.arange(t, device=matrix.device).view(1, t, 1).expand(b, t, 1)\n",
    "    # print(\"token_indices shape: \", token_indices.shape)  # torch.Size([32, 28, 1])\n",
    "    # \n",
    "    \n",
    "    final_indices = torch.cat([token_indices, mapped_tensor], dim=2)\n",
    "    # print(\"final_indices shape: \", final_indices.shape)  # torch.Size([32, 28, 5])\n",
    "\n",
    "    indices_expanded = final_indices.unsqueeze(1).expand(b, c, t, K)\n",
    "    # print(\"indices_expanded shape: \", indices_expanded.shape)  # torch.Size([32, 3, 28, 5])\n",
    "    \n",
    "    batch_indices = torch.arange(b, device=matrix.device).view(b, 1, 1, 1).expand(b, c, t, K)\n",
    "    channel_indices = torch.arange(c, device=matrix.device).view(1, c, 1, 1).expand(b, c, t, K)\n",
    "    \n",
    "\n",
    "    prime = matrix[batch_indices, channel_indices, indices_expanded]  \n",
    "    \n",
    "    prime = prime.view(b, c, -1)\n",
    "    return prime\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p1 shape torch.Size([32, 3, 140])\n",
      "o1 shape torch.Size([32, 3, 140])\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "samples = 10\n",
    "x1 = torch.randn(32, 3, 28)\n",
    "\n",
    "\n",
    "rand_idx = torch.tensor(np.random.choice(x1.shape[2], samples, replace=False)) # list \n",
    "x1_sample = x1[:, :, rand_idx]\n",
    "\n",
    "\n",
    "sim = calculate_similarity_matrix_N(x1, x1_sample)\n",
    "p1 = prime_vmap_2d_N(x1, sim, 5, rand_idx, True)\n",
    "o1 = _prime_N(x1, sim, 5, rand_idx, True)\n",
    "o1_v2 = _prime_N_v2(x1, sim, 5,rand_idx, True)\n",
    "o1_v3 = _prime_N_v3(x1, sim, 5, rand_idx, True)\n",
    "print('p1 shape', p1.shape)\n",
    "print('o1 shape', o1.shape)\n",
    "print(torch.allclose(p1, o1))\n",
    "print(torch.allclose(p1, o1_v2))\n",
    "print(torch.allclose(o1, o1_v2))\n",
    "print(torch.allclose(o1, o1_v3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time complexity for prime og, prime v1, prime v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " All samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration = 30000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for vmap:  10.530007123947144\n"
     ]
    }
   ],
   "source": [
    "ex = torch.randn(32, 3, 28)\n",
    "o1 = _calculate_distance_matrix(ex)\n",
    "\n",
    "start = time.time()\n",
    "for i in range(iteration):\n",
    "    prime_vmap_2d(ex, o1, 5, True)\n",
    "end = time.time()\n",
    "print(\"Time taken for vmap: \", end - start)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for prime v1:  9.789667844772339\n"
     ]
    }
   ],
   "source": [
    "ex = torch.randn(32, 3, 28)\n",
    "o1 = _calculate_distance_matrix(ex)\n",
    "\n",
    "start = time.time()\n",
    "for i in range(iteration):\n",
    "    _prime(ex, o1, 5, True)\n",
    "end = time.time()\n",
    "print(\"Time taken for prime v1: \", end - start)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for prime v2:  7.953621864318848\n"
     ]
    }
   ],
   "source": [
    "ex = torch.randn(32, 3, 28)\n",
    "o1 = _calculate_distance_matrix(ex)\n",
    "\n",
    "start = time.time()\n",
    "for i in range(iteration):\n",
    "    _prime_v2(ex, o1, 5, True)\n",
    "end = time.time()\n",
    "print(\"Time taken for prime v2: \", end - start)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[106], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(iteration):\n\u001b[0;32m----> 6\u001b[0m     \u001b[43m_prime_v3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mo1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTime taken for prime v3: \u001b[39m\u001b[38;5;124m\"\u001b[39m, end \u001b[38;5;241m-\u001b[39m start)\n",
      "Cell \u001b[0;32mIn[96], line 13\u001b[0m, in \u001b[0;36m_prime_v3\u001b[0;34m(matrix, magnitude_matrix, K, maximum)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(t):\n\u001b[1;32m     12\u001b[0m         idx \u001b[38;5;241m=\u001b[39m indices[i, j]  \u001b[38;5;66;03m# [K]\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m         result[i, :, j\u001b[38;5;241m*\u001b[39mK:(j\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m*\u001b[39mK] \u001b[38;5;241m=\u001b[39m matrix[i, :, idx]\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ex = torch.randn(32, 3, 28)\n",
    "o1 = _calculate_distance_matrix(ex)\n",
    "\n",
    "start = time.time()\n",
    "for i in range(iteration):\n",
    "    _prime_v3(ex, o1, 5, True)\n",
    "end = time.time()\n",
    "print(\"Time taken for prime v3: \", end - start)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for vmap N:  7.737882852554321\n"
     ]
    }
   ],
   "source": [
    "samples = 10\n",
    "ex = torch.randn(32, 3, 28)\n",
    "rand_idx = torch.tensor(np.random.choice(ex.shape[2], samples, replace=False)) # list \n",
    "ex_sample = ex[:, :, rand_idx]\n",
    "sim = calculate_similarity_matrix_N(ex, ex_sample)\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "for i in range(iteration):\n",
    "    prime_vmap_2d_N(x1, sim, 5, rand_idx, True)\n",
    "end = time.time()\n",
    "print(\"Time taken for vmap N: \", end - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for prime v1 N:  6.5011138916015625\n"
     ]
    }
   ],
   "source": [
    "samples = 10\n",
    "ex = torch.randn(32, 3, 28)\n",
    "rand_idx = torch.tensor(np.random.choice(ex.shape[2], samples, replace=False)) # list \n",
    "ex_sample = ex[:, :, rand_idx]\n",
    "sim = calculate_similarity_matrix_N(ex, ex_sample)\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "for i in range(iteration):\n",
    "    _prime_N(x1, sim, 5, rand_idx, True)\n",
    "end = time.time()\n",
    "print(\"Time taken for prime v1 N: \", end - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for prime v2 N:  5.222126007080078\n"
     ]
    }
   ],
   "source": [
    "samples = 10\n",
    "ex = torch.randn(32, 3, 28)\n",
    "rand_idx = torch.tensor(np.random.choice(ex.shape[2], samples, replace=False)) # list \n",
    "ex_sample = ex[:, :, rand_idx]\n",
    "sim = calculate_similarity_matrix_N(ex, ex_sample)\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "for i in range(iteration):\n",
    "    _prime_N_v2(x1, sim, 5, rand_idx, True)\n",
    "end = time.time()\n",
    "print(\"Time taken for prime v2 N: \", end - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[107], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(iteration):\n\u001b[0;32m---> 10\u001b[0m     \u001b[43m_prime_N_v3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTime taken for prime v3 N: \u001b[39m\u001b[38;5;124m\"\u001b[39m, end \u001b[38;5;241m-\u001b[39m start)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "samples = 10\n",
    "ex = torch.randn(32, 3, 28)\n",
    "rand_idx = torch.tensor(np.random.choice(ex.shape[2], samples, replace=False)) # list \n",
    "ex_sample = ex[:, :, rand_idx]\n",
    "sim = calculate_similarity_matrix_N(ex, ex_sample)\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "for i in range(iteration):\n",
    "    _prime_N_v3(x1, sim, 5, rand_idx, True)\n",
    "end = time.time()\n",
    "print(\"Time taken for prime v3 N: \", end - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
