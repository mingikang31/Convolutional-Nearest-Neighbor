{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross checking with original implementation vs. optimized implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torch\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim \n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "# Train + Data \n",
    "import sys \n",
    "sys.path.append('../Layers')\n",
    "from Conv1d_NN import *\n",
    "from Conv2d_NN import *\n",
    "from Conv1d_NN_spatial import * \n",
    "from Conv2d_NN_spatial import * \n",
    "from ConvNN_CNN_Branching import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Distance Matrix Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm_squared torch.Size([32, 1, 28])\n",
      "matrix t torch.Size([32, 28, 3])\n",
      "matrix torch.Size([32, 3, 28])\n",
      "matrix t * matrix torch.Size([32, 28, 28])\n",
      "torch.Size([32, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "def _calculate_distance_matrix(matrix, sqrt=False):\n",
    "    norm_squared = torch.sum(matrix ** 2, dim=1, keepdim=True)\n",
    "    print(\"norm_squared\", norm_squared.shape)\n",
    "    print(\"matrix t\", matrix.transpose(2, 1).shape)\n",
    "    print(\"matrix\", matrix.shape)\n",
    "    print(\"matrix t * matrix\", torch.bmm(matrix.transpose(2, 1), matrix).shape)\n",
    "    \n",
    "    dot_product = torch.bmm(matrix.transpose(2, 1), matrix)\n",
    "    dist_matrix = norm_squared + norm_squared.transpose(2, 1) - 2 * dot_product\n",
    "    \n",
    "    dist_matrix = torch.clamp(dist_matrix, min=0)  \n",
    "    \n",
    "    if sqrt:\n",
    "        dist_matrix = torch.sqrt(dist_matrix)\n",
    "    return dist_matrix\n",
    "\n",
    "ex = torch.randn(32, 3, 28)\n",
    "o1 = _calculate_distance_matrix(ex)\n",
    "print(o1.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm squared torch.Size([32, 28, 1])\n",
      "norm sqaured no permute torch.Size([32, 1, 28])\n",
      "norm squared sample torch.Size([32, 1, 10])\n",
      "norm squared sample no permute torch.Size([32, 1, 10])\n",
      "dot product torch.Size([32, 28, 10])\n",
      "dist matrix torch.Size([32, 28, 10])\n",
      "torch.Size([32, 28, 10])\n"
     ]
    }
   ],
   "source": [
    "# N Samples\n",
    "def original_calculate_distance_matrix_N(matrix, matrix_sample, sqrt=False):\n",
    "    \"\"\"Calculates distance matrix between two input matrices\"\"\" \n",
    "    norm_squared = torch.sum(matrix ** 2, dim=1, keepdim=True).permute(0, 2, 1)\n",
    "    \n",
    "    print(\"norm squared\", norm_squared.shape)\n",
    "    print(\"norm sqaured no permute\", torch.sum(matrix ** 2, dim=1, keepdim=True).shape)\n",
    "    \n",
    "    norm_squared_sample = torch.sum(matrix_sample ** 2, dim=1, keepdim=True).transpose(2, 1).permute(0, 2, 1)\n",
    "    print(\"norm squared sample\", norm_squared_sample.shape)\n",
    "    print(\"norm squared sample no permute\", torch.sum(matrix_sample ** 2, dim=1, keepdim=True).shape)\n",
    "    \n",
    "    dot_product = torch.bmm(matrix.transpose(2, 1), matrix_sample)\n",
    "    print(\"dot product\", dot_product.shape)\n",
    "    \n",
    "    dist_matrix = norm_squared + norm_squared_sample - 2 * dot_product\n",
    "    print(\"dist matrix\", dist_matrix.shape)\n",
    "    \n",
    "    dist_matrix = torch.clamp(dist_matrix, min=0.0)  \n",
    "    \n",
    "    if sqrt:\n",
    "        dist_matrix = torch.sqrt(dist_matrix)\n",
    "    return dist_matrix\n",
    "\n",
    "ex = torch.randn(32, 3, 28)\n",
    "ex1 = torch.randn(32, 3, 10)\n",
    "o1 = original_calculate_distance_matrix_N(ex, ex1)\n",
    "print(o1.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Similarity Matrix Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All Samples\n",
    "def original_calculate_similarity_matrix(matrix): \n",
    "    \"\"\"Calculates similarity matrix of the input matrix\"\"\"\n",
    "    normalized_matrix = F.normalize(matrix, p=2, dim=1) # p=2 (L2 Norm - Euclidean Distance), dim=1 (across the channels)\n",
    "    dot_product = torch.bmm(normalized_matrix.transpose(2, 1), normalized_matrix)\n",
    "    similarity_matrix = dot_product \n",
    "    return similarity_matrix\n",
    "\n",
    "def optimized_calculate_similarity_matrix(matrix): \n",
    "    normalized_matrix = F.normalized(matrix, p=2, dim=1)\n",
    "    similarity_matrix = torch.bmm(normalized_matrix.transpose(2, 1), normalized_matrix)\n",
    "    return similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N Samples\n",
    "def original_calculate_similarity_matrix_N(matrix, matrix_sample): \n",
    "    \"\"\"Calculates similarity matrix between two input matrices\"\"\"\n",
    "    norm_matrix = F.normalize(matrix, p=2, dim=1) # p=2 (L2 Norm - Euclidean Distance), dim=1 (across the channels)\n",
    "    norm_sample = F.normalize(matrix_sample, p=2, dim=1)\n",
    "    similarity_matrix = torch.bmm(norm_matrix.transpose(2, 1), norm_sample)\n",
    "    return similarity_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Topk Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original matrix shape torch.Size([32, 3, 28])\n",
      "original similarity matrix shape torch.Size([32, 28, 28])\n",
      "prime shape torch.Size([32, 3, 140])\n"
     ]
    }
   ],
   "source": [
    "# All Samples\n",
    "\n",
    "@staticmethod \n",
    "def prime_vmap_2d(matrix, magnitude_matrix, num_nearest_neighbors, maximum): \n",
    "    \"\"\"Vectorization / Vmap Implementation for Nearest Neighbor Tensor 2D\"\"\"\n",
    "    batched_process = torch.vmap(process_batch, in_dims=(0, 0, None), out_dims=0)\n",
    "    prime = batched_process(matrix, magnitude_matrix, num_nearest_neighbors, flatten=True, maximum=maximum)\n",
    "    return prime \n",
    "\n",
    "@staticmethod \n",
    "def prime_vmap_3d(matrix, magnitude_matrix, num_nearest_neighbors, maximum): \n",
    "    \"\"\"Vectorization / Vmap Implementation for Nearest Neighbor Tensor 3D\"\"\"\n",
    "    batched_process = torch.vmap(process_batch, in_dims=(0, 0, None), out_dims=0)\n",
    "    prime = batched_process(matrix, magnitude_matrix, num_nearest_neighbors, flatten=False, maximum=maximum)\n",
    "    return prime\n",
    "\n",
    "@staticmethod \n",
    "def process_batch(matrix, magnitude_matrix, num_nearest_neighbors, flatten, maximum): \n",
    "    \"\"\"Process the batch of matrices by finding the K nearest neighbors with reshaping.\"\"\"\n",
    "    ind = torch.topk(magnitude_matrix, num_nearest_neighbors, largest=maximum).indices \n",
    "    neigh = matrix[:, ind]\n",
    "    if flatten: \n",
    "        reshape = torch.flatten(neigh, start_dim=1)\n",
    "        return reshape\n",
    "    return neigh\n",
    "\n",
    "mat = torch.randn(32, 3, 28)\n",
    "mag = original_calculate_similarity_matrix(mat)\n",
    "prime = prime_vmap_2d(mat, mag, 5, True)\n",
    "\n",
    "print('original matrix shape', mat.shape)\n",
    "print('original similarity matrix shape', mag.shape)\n",
    "print('prime shape', prime.shape)\n",
    "\n",
    "# 28 * 5 = 140 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original matrix shape torch.Size([32, 3, 28])\n",
      "original similarity matrix shape torch.Size([32, 28, 28])\n",
      "prime shape torch.Size([32, 3, 140])\n",
      "tensor([[[    -1.5924,     -2.5385,     -1.2956,  ...,      0.3354,\n",
      "               0.0738,     -0.2522],\n",
      "         [    -0.4405,     -0.5790,     -0.8369,  ...,     -1.6449,\n",
      "              -0.7586,     -1.0002],\n",
      "         [    -1.2106,     -1.1426,     -1.1020,  ...,     -0.1723,\n",
      "              -0.4518,     -1.2235]],\n",
      "\n",
      "        [[     1.1693,      0.2221,     -0.0012,  ...,     -0.5522,\n",
      "              -1.8914,     -1.2325],\n",
      "         [    -1.1885,     -0.9788,     -0.7985,  ...,      2.4023,\n",
      "               0.7875,      0.4440],\n",
      "         [     0.9487,      0.6893,      0.9037,  ...,     -1.3192,\n",
      "               0.3648,      0.1712]],\n",
      "\n",
      "        [[    -1.2736,     -0.4560,     -0.8498,  ...,      0.0286,\n",
      "               0.0068,     -0.4560],\n",
      "         [     0.5743,      0.4282,      0.9951,  ...,      0.1451,\n",
      "              -0.1089,      0.4282],\n",
      "         [    -1.2815,     -0.8203,     -1.3526,  ...,     -0.3584,\n",
      "              -1.1852,     -0.8203]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[    -0.6564,     -1.5257,     -0.3830,  ...,      1.4223,\n",
      "               0.6118,      1.9753],\n",
      "         [    -0.2298,     -0.2356,      1.3104,  ...,     -1.4462,\n",
      "              -0.8422,     -0.0251],\n",
      "         [     1.3798,      1.2288,      1.6778,  ...,      0.7830,\n",
      "               0.0564,     -1.0786]],\n",
      "\n",
      "        [[    -0.5509,     -0.2852,     -0.3311,  ...,      0.4302,\n",
      "               0.7988,      0.5583],\n",
      "         [    -0.2463,     -0.1801,     -0.6524,  ...,     -0.4950,\n",
      "              -0.1260,     -0.1728],\n",
      "         [     0.6864,      0.3877,      0.9365,  ...,      0.5743,\n",
      "               0.4504,      0.6135]],\n",
      "\n",
      "        [[    -0.3295,     -0.3150,      0.1110,  ...,     -0.4266,\n",
      "              -2.1503,     -0.8334],\n",
      "         [    -0.5456,      0.0269,     -0.0938,  ...,      0.0524,\n",
      "               1.3340,     -0.7690],\n",
      "         [     1.0314,      2.0589,      1.8910,  ...,      0.0238,\n",
      "              -0.7778,     -0.3510]]])\n"
     ]
    }
   ],
   "source": [
    "torch.set_printoptions(precision=4, sci_mode=False)\n",
    "\n",
    "\n",
    "def prime_brute(matrix, dist_matrix, K): \n",
    "    stack_list = [] \n",
    "    count = 0 \n",
    "    for i in range(matrix.shape[0]): \n",
    "        # print(\"i\", i)\n",
    "        concat_list = [] \n",
    "        for j in range(matrix.shape[2]): \n",
    "            # Get the indices of the nearest neighbors\n",
    "            indices = torch.topk(dist_matrix[i, j, :], K, largest=True).indices\n",
    "            # print(\"indices\", indices)\n",
    "            # Get the nearest neighbors\n",
    "            nearest_neighbors = matrix[i, :, indices]\n",
    "            \n",
    "            # Concatenate the nearest neighbors\n",
    "            concat_list.append(nearest_neighbors)\n",
    "            count += 1\n",
    "        # Concatenate the tensor list to create the convolution matrix \n",
    "        # print()\n",
    "        concat = torch.cat(concat_list, dim=1)\n",
    "        stack_list.append(concat)\n",
    "    prime = torch.stack(stack_list, dim= 0)\n",
    "    # print(\"count\", count)\n",
    "    return prime\n",
    "        \n",
    "\n",
    "mat = torch.randn(32, 3, 28)\n",
    "sim = original_calculate_similarity_matrix(mat)\n",
    "prime_b = prime_brute(mat, sim, 5)\n",
    "print('original matrix shape', mat.shape)\n",
    "print('original similarity matrix shape', sim.shape)\n",
    "print('prime shape', prime.shape)\n",
    "print(prime_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topk indices:  torch.Size([32, 28, 5])\n",
      "batch_size:  32\n",
      "channels:  3\n",
      "tokens:  28\n",
      "K:  5\n",
      "indices_expanded shape: torch.Size([32, 3, 28, 5])\n",
      "\n",
      "prime_new shape: torch.Size([32, 3, 140])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "_, topk_indices = torch.topk(sim, k=5, dim=2, largest=True)  \n",
    "print(\"topk indices: \", topk_indices.shape)  \n",
    "\n",
    "\n",
    "batch_size, channels, tokens = mat.shape\n",
    "K = topk_indices.shape[-1]  \n",
    "print(\"batch_size: \", batch_size)\n",
    "print(\"channels: \", channels)\n",
    "print(\"tokens: \", tokens)\n",
    "print(\"K: \", K)\n",
    "\n",
    "# Expand topk_indices: add a channel dimension at dim=1\n",
    "indices_expanded = topk_indices.unsqueeze(1).expand(batch_size, channels, tokens, K)\n",
    "\n",
    "print(\"indices_expanded shape:\", indices_expanded.shape)  # torch.Size([32, 3, 28, 5])\n",
    "\n",
    "\n",
    "\n",
    "print()\n",
    "\n",
    "# Create index tensors for batch and channel dimensions:\n",
    "batch_indices = torch.arange(batch_size).view(batch_size, 1, 1, 1).expand(batch_size, channels, tokens, K)\n",
    "\n",
    "channel_indices = torch.arange(channels).view(1, channels, 1, 1).expand(batch_size, channels, tokens, K)\n",
    "\n",
    "# Now use advanced indexing:\n",
    "# For each [b, c, i, j], we select mat[b, c, indices_expanded[b, c, i, j]]\n",
    "prime = mat[batch_indices, channel_indices, indices_expanded]\n",
    "# prime will have shape [32, 3, 28, 5]\n",
    "\n",
    "# Finally, reshape (flatten the token and neighbor dimensions) to get [32, 3, 28*5] = [32, 3, 140]\n",
    "prime_new = prime.view(batch_size, channels, -1)\n",
    "\n",
    "print(\"prime_new shape:\", prime_new.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.allclose(prime_b, prime_new))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimized check\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(precision=4, sci_mode=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_similarity_matrix(matrix): \n",
    "    \"\"\"Calculates similarity matrix of the input matrix\"\"\"\n",
    "    normalized_matrix = F.normalize(matrix, p=2, dim=1) # p=2 (L2 Norm - Euclidean Distance), dim=1 (across the channels)\n",
    "    dot_product = torch.bmm(normalized_matrix.transpose(2, 1), normalized_matrix)\n",
    "    similarity_matrix = dot_product \n",
    "    return similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prime_brute(matrix, dist_matrix, K): \n",
    "    stack_list = [] \n",
    "    count = 0 \n",
    "    for i in range(matrix.shape[0]): \n",
    "        concat_list = [] \n",
    "        for j in range(matrix.shape[2]): \n",
    "            indices = torch.topk(dist_matrix[i, j, :], K, largest=True).indices\n",
    "\n",
    "            nearest_neighbors = matrix[i, :, indices]\n",
    "            \n",
    "            concat_list.append(nearest_neighbors)\n",
    "            count += 1\n",
    "        concat = torch.cat(concat_list, dim=1)\n",
    "        stack_list.append(concat)\n",
    "    prime = torch.stack(stack_list, dim= 0)\n",
    "    return prime\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All Samples\n",
    "\n",
    "@staticmethod \n",
    "def prime_vmap_2d(matrix, magnitude_matrix, num_nearest_neighbors, maximum): \n",
    "    \"\"\"Vectorization / Vmap Implementation for Nearest Neighbor Tensor 2D\"\"\"\n",
    "    batched_process = torch.vmap(process_batch, in_dims=(0, 0, None), out_dims=0)\n",
    "    prime = batched_process(matrix, magnitude_matrix, num_nearest_neighbors, flatten=True, maximum=maximum)\n",
    "    return prime \n",
    "\n",
    "@staticmethod \n",
    "def prime_vmap_3d(matrix, magnitude_matrix, num_nearest_neighbors, maximum): \n",
    "    \"\"\"Vectorization / Vmap Implementation for Nearest Neighbor Tensor 3D\"\"\"\n",
    "    batched_process = torch.vmap(process_batch, in_dims=(0, 0, None), out_dims=0)\n",
    "    prime = batched_process(matrix, magnitude_matrix, num_nearest_neighbors, flatten=False, maximum=maximum)\n",
    "    return prime\n",
    "\n",
    "@staticmethod \n",
    "def process_batch(matrix, magnitude_matrix, num_nearest_neighbors, flatten, maximum): \n",
    "    \"\"\"Process the batch of matrices by finding the K nearest neighbors with reshaping.\"\"\"\n",
    "    ind = torch.topk(magnitude_matrix, num_nearest_neighbors, largest=maximum).indices \n",
    "    neigh = matrix[:, ind]\n",
    "    if flatten: \n",
    "        reshape = torch.flatten(neigh, start_dim=1)\n",
    "        return reshape\n",
    "    return neigh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prime_optimized(matrix, dist_matrix, K=5, maximum=False):\n",
    "\n",
    "    _, topk_indices = torch.topk(dist_matrix, k=K, dim=2, largest=True)  \n",
    "\n",
    "\n",
    "    batch_size, channels, tokens = matrix.shape\n",
    "    K = topk_indices.shape[-1]  \n",
    "\n",
    "    indices_expanded = topk_indices.unsqueeze(1).expand(batch_size, channels, tokens, K)\n",
    "\n",
    "    batch_indices = torch.arange(batch_size).view(batch_size, 1, 1, 1).expand(batch_size, channels, tokens, K)\n",
    "\n",
    "    channel_indices = torch.arange(channels).view(1, channels, 1, 1).expand(batch_size, channels, tokens, K)\n",
    "\n",
    "    prime = matrix[batch_indices, channel_indices, indices_expanded]\n",
    "\n",
    "    prime_new = prime.view(batch_size, channels, -1)\n",
    "\n",
    "    return prime_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _prime(matrix, magnitude_matrix, K, maximum):\n",
    "    b, c, t = matrix.shape \n",
    "\n",
    "    _, topk_indices = torch.topk(magnitude_matrix, k = K, dim=2, largest=maximum)\n",
    "    \n",
    "    tk = topk_indices.shape[-1]\n",
    "    \n",
    "    assert K == tk, \"Error: K must be same as tk. K == tk.\"\n",
    "    \n",
    "    indices_expanded = topk_indices.unsqueeze(1).expand(b, c, t, tk)\n",
    "    batch_indices = torch.arange(b).view(b, 1, 1, 1).expand(b, c, t, tk)\n",
    "    channel_indices = torch.arange(c).view(1, c, 1, 1).expand(b, c, t, tk)\n",
    "    \n",
    "    prime = matrix[batch_indices, channel_indices, indices_expanded]\n",
    "    prime = prime.view(b, c, -1)\n",
    "    return prime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original matrix shape torch.Size([32, 3, 28])\n",
      "original similarity matrix shape torch.Size([32, 28, 28])\n",
      "\n",
      "prime brute shape torch.Size([32, 3, 140])\n",
      "prime optimized shape torch.Size([32, 3, 140])\n",
      "prime vmap shape torch.Size([32, 3, 140])\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "mat = torch.randn(32, 3, 28)\n",
    "sim = calculate_similarity_matrix(mat)\n",
    "prime_b = prime_brute(mat, sim, 5)\n",
    "prime_o = prime_optimized(mat, sim, 5)\n",
    "prime_f = prime_vmap_2d(mat, sim, 5, True)\n",
    "prime_ = _prime(mat, sim, 5, True)\n",
    "print('original matrix shape', mat.shape)\n",
    "print('original similarity matrix shape', sim.shape)\n",
    "print()\n",
    "print('prime brute shape', prime_b.shape)\n",
    "print('prime optimized shape', prime_o.shape)\n",
    "print('prime vmap shape', prime_f.shape)\n",
    "\n",
    "print(torch.allclose(prime_b, prime_o))\n",
    "print(torch.allclose(prime_b, prime_f))\n",
    "print(torch.allclose(prime_o, prime_f))\n",
    "print(torch.allclose(prime_b, prime_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### N Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(precision=4, sci_mode=False)\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N Samples\n",
    "def calculate_similarity_matrix_N(matrix, matrix_sample): \n",
    "    \"\"\"Calculates similarity matrix between two input matrices\"\"\"\n",
    "    norm_matrix = F.normalize(matrix, p=2, dim=1) # p=2 (L2 Norm - Euclidean Distance), dim=1 (across the channels)\n",
    "    norm_sample = F.normalize(matrix_sample, p=2, dim=1)\n",
    "    similarity_matrix = torch.bmm(norm_matrix.transpose(2, 1), norm_sample)\n",
    "    return similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prime_vmap_2d_N(matrix, magnitude_matrix, num_nearest_neighbors, rand_idx, maximum): \n",
    "    \"\"\"Vectorization / Vmap Implementation for Nearest Neighbor Tensor 2D\"\"\"\n",
    "    batched_process = torch.vmap(process_batch_N, in_dims=(0, 0, None, None), out_dims=0)\n",
    "    prime = batched_process(matrix, magnitude_matrix, num_nearest_neighbors, rand_idx, flatten=True, maximum=maximum)\n",
    "    return prime \n",
    "\n",
    "def prime_vmap_3d_N(matrix, magnitude_matrix, num_nearest_neighbors, rand_idx, maximum): \n",
    "    \"\"\"Vectorization / Vmap Implementation for Nearest Neighbor Tensor 3D\"\"\"\n",
    "    batched_process = torch.vmap(process_batch_N, in_dims=(0, 0, None, None), out_dims=0)\n",
    "    prime = batched_process(matrix, magnitude_matrix, num_nearest_neighbors, rand_idx, flatten=False, maximum=maximum)\n",
    "    return prime\n",
    "\n",
    "def process_batch_N(matrix, magnitude_matrix, num_nearest_neighbors, rand_idx, flatten, maximum): \n",
    "    \"\"\"Process the batch of matrices by finding the K nearest neighbors with reshaping.\"\"\"\n",
    "    topk_ind = torch.topk(magnitude_matrix, num_nearest_neighbors - 1, largest=maximum).indices\n",
    "    device = topk_ind.device\n",
    "    rand_idx = rand_idx.to(device) # same device as topk_ind\n",
    "    mapped_tensor = rand_idx[topk_ind] \n",
    "    index_tensor = torch.arange(0, matrix.shape[1], device=device).unsqueeze(1) # shape [40, 1]\n",
    "    final_tensor = torch.cat([index_tensor, mapped_tensor], dim=1)\n",
    "    neigh = matrix[:, final_tensor] \n",
    "    if flatten: \n",
    "        reshape = torch.flatten(neigh, start_dim=1)\n",
    "        return reshape\n",
    "    return neigh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _prime_N(matrix, magnitude_matrix, K, rand_idx, maximum):\n",
    "    \"\"\"\n",
    "    Create prime tensor for the N-samples case.\n",
    "    \n",
    "    Args:\n",
    "        matrix (torch.Tensor): Input tensor of shape [b, c, t].\n",
    "        magnitude_matrix (torch.Tensor): Magnitude matrix of shape [b, t, s] \n",
    "                                           (where s is the number of sampled tokens).\n",
    "        K (int): Total number of neighbors to consider (including the self index).\n",
    "        rand_idx (torch.Tensor): 1D tensor of length s containing the sampled indices.\n",
    "        maximum (bool): If True, select the largest values (e.g. for similarity); if False, select the smallest (e.g. for distance).\n",
    "        \n",
    "    Returns:\n",
    "        torch.Tensor: A prime tensor of shape [b, c, t*K].\n",
    "    \"\"\"\n",
    "    b, c, t = matrix.shape\n",
    "    # print(\"batch \", b)\n",
    "    # print(\"channel \", c)\n",
    "    # print(\"token \", t)\n",
    "        \n",
    "\n",
    "    _, topk_indices = torch.topk(magnitude_matrix, k=K - 1, dim=2, largest=maximum)\n",
    "    tk = topk_indices.shape[-1]\n",
    "    assert K == tk + 1, \"Error: K must be same as tk + 1. K == tk + 1.\"\n",
    "    # print(\"topk_indices shape: \", topk_indices.shape)  # torch.Size([32, 28, 4])\n",
    "    \n",
    "    mapped_tensor = rand_idx[topk_indices]\n",
    "    # print(\"mapped_tensor shape: \", mapped_tensor.shape)  # torch.Size([32, 28, 4])\n",
    "    # print(mapped_tensor)\n",
    "\n",
    "    token_indices = torch.arange(t, device=matrix.device).view(1, t, 1).expand(b, t, 1)\n",
    "    # print(\"token_indices shape: \", token_indices.shape)  # torch.Size([32, 28, 1])\n",
    "    # \n",
    "    \n",
    "    final_indices = torch.cat([token_indices, mapped_tensor], dim=2)\n",
    "    # print(\"final_indices shape: \", final_indices.shape)  # torch.Size([32, 28, 5])\n",
    "\n",
    "    indices_expanded = final_indices.unsqueeze(1).expand(b, c, t, K)\n",
    "    # print(\"indices_expanded shape: \", indices_expanded.shape)  # torch.Size([32, 3, 28, 5])\n",
    "    \n",
    "    batch_indices = torch.arange(b, device=matrix.device).view(b, 1, 1, 1).expand(b, c, t, K)\n",
    "    channel_indices = torch.arange(c, device=matrix.device).view(1, c, 1, 1).expand(b, c, t, K)\n",
    "    \n",
    "\n",
    "    prime = matrix[batch_indices, channel_indices, indices_expanded]  \n",
    "    \n",
    "    prime = prime.view(b, c, -1)\n",
    "    return prime\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p1 shape torch.Size([32, 3, 140])\n",
      "o1 shape torch.Size([32, 3, 140])\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "samples = 10\n",
    "x1 = torch.randn(32, 3, 28)\n",
    "\n",
    "\n",
    "rand_idx = torch.tensor(np.random.choice(x1.shape[2], samples, replace=False)) # list \n",
    "x1_sample = x1[:, :, rand_idx]\n",
    "\n",
    "\n",
    "sim = calculate_similarity_matrix_N(x1, x1_sample)\n",
    "p1 = prime_vmap_2d_N(x1, sim, 5, rand_idx, True)\n",
    "o1 = _prime_N(x1, sim, 5, rand_idx, True)\n",
    "print('p1 shape', p1.shape)\n",
    "print('o1 shape', o1.shape)\n",
    "print(torch.allclose(p1, o1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rand_idx tensor([ 5,  8, 13,  7,  0, 15,  3,  4, 27,  9])\n",
      "rand_idx_1 tensor([ 5,  6,  3, 19,  7, 25, 22, 13, 24, 16])\n"
     ]
    }
   ],
   "source": [
    "rand_idx = torch.tensor(np.random.choice(x1.shape[2], samples, replace=False)) # list \n",
    "print('rand_idx', rand_idx)\n",
    "\n",
    "rand_idx_1 = torch.randperm(x1.shape[2], device=x1.device)[:samples]\n",
    "\n",
    "print('rand_idx_1', rand_idx_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.7054, -0.5324, -0.6979,  ...,  0.0762,  0.0899, -0.5545],\n",
      "         [ 0.9618,  0.4471, -0.1476,  ...,  0.4534, -0.9644, -1.8902],\n",
      "         [-1.6330, -0.4950, -1.0002,  ..., -0.0175,  0.4213,  1.1160]],\n",
      "\n",
      "        [[-0.8165, -0.7850, -0.4812,  ..., -1.5276, -0.2738, -1.0009],\n",
      "         [-1.3051, -1.2610, -0.4478,  ...,  2.3161,  1.9332, -0.0130],\n",
      "         [ 0.4081, -0.4222, -0.4186,  ...,  0.0178,  0.4994, -1.0493]],\n",
      "\n",
      "        [[-0.6573,  0.5262,  0.9635,  ..., -0.8781, -0.0802,  0.9964],\n",
      "         [ 0.7645,  0.5400,  1.5223,  ..., -0.1346, -0.4807, -0.7846],\n",
      "         [-1.5110, -0.6122, -0.7162,  ...,  1.3568,  2.0220,  0.4099]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 2.0408,  0.8770,  0.4432,  ...,  0.4432,  0.3405, -0.4371],\n",
      "         [ 1.0867, -0.1394,  0.8812,  ...,  0.8812, -0.5191,  0.5409],\n",
      "         [ 0.1134,  0.2625,  0.7772,  ...,  0.7772,  1.4208,  0.3238]],\n",
      "\n",
      "        [[-0.2865,  1.0177, -1.7552,  ..., -0.8602, -1.7552,  0.4325],\n",
      "         [ 1.9554,  1.7016,  0.9289,  ...,  0.6327,  0.9289, -1.0662],\n",
      "         [ 0.7702, -0.6935, -0.9649,  ..., -0.8280, -0.9649, -1.0469]],\n",
      "\n",
      "        [[ 1.1941,  1.3344,  0.8136,  ...,  1.2590,  0.3336,  1.9514],\n",
      "         [ 0.4343,  0.9892,  1.1330,  ...,  0.3287, -0.3173,  0.1815],\n",
      "         [-0.5905, -0.4823, -0.1686,  ...,  1.4882,  1.4727,  0.7070]]])\n"
     ]
    }
   ],
   "source": [
    "print(p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.7054, -0.5324, -0.6979,  ...,  0.0762,  0.0899, -0.5545],\n",
      "         [ 0.9618,  0.4471, -0.1476,  ...,  0.4534, -0.9644, -1.8902],\n",
      "         [-1.6330, -0.4950, -1.0002,  ..., -0.0175,  0.4213,  1.1160]],\n",
      "\n",
      "        [[-0.8165, -0.7850, -0.4812,  ..., -1.5276, -0.2738, -1.0009],\n",
      "         [-1.3051, -1.2610, -0.4478,  ...,  2.3161,  1.9332, -0.0130],\n",
      "         [ 0.4081, -0.4222, -0.4186,  ...,  0.0178,  0.4994, -1.0493]],\n",
      "\n",
      "        [[-0.6573,  0.5262,  0.9635,  ..., -0.8781, -0.0802,  0.9964],\n",
      "         [ 0.7645,  0.5400,  1.5223,  ..., -0.1346, -0.4807, -0.7846],\n",
      "         [-1.5110, -0.6122, -0.7162,  ...,  1.3568,  2.0220,  0.4099]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 2.0408,  0.8770,  0.4432,  ...,  0.4432,  0.3405, -0.4371],\n",
      "         [ 1.0867, -0.1394,  0.8812,  ...,  0.8812, -0.5191,  0.5409],\n",
      "         [ 0.1134,  0.2625,  0.7772,  ...,  0.7772,  1.4208,  0.3238]],\n",
      "\n",
      "        [[-0.2865,  1.0177, -1.7552,  ..., -0.8602, -1.7552,  0.4325],\n",
      "         [ 1.9554,  1.7016,  0.9289,  ...,  0.6327,  0.9289, -1.0662],\n",
      "         [ 0.7702, -0.6935, -0.9649,  ..., -0.8280, -0.9649, -1.0469]],\n",
      "\n",
      "        [[ 1.1941,  1.3344,  0.8136,  ...,  1.2590,  0.3336,  1.9514],\n",
      "         [ 0.4343,  0.9892,  1.1330,  ...,  0.3287, -0.3173,  0.1815],\n",
      "         [-0.5905, -0.4823, -0.1686,  ...,  1.4882,  1.4727,  0.7070]]])\n"
     ]
    }
   ],
   "source": [
    "print(o1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
