{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross checking with original implementation vs. optimized implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torch\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim \n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "# Train + Data \n",
    "import sys \n",
    "sys.path.append('../Layers')\n",
    "from Conv1d_NN import *\n",
    "from Conv2d_NN import *\n",
    "from Conv1d_NN_spatial import * \n",
    "from Conv2d_NN_spatial import * \n",
    "from ConvNN_CNN_Branching import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Distance Matrix Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm_squared torch.Size([32, 1, 28])\n",
      "matrix t torch.Size([32, 28, 3])\n",
      "matrix torch.Size([32, 3, 28])\n",
      "matrix t * matrix torch.Size([32, 28, 28])\n",
      "torch.Size([32, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "def _calculate_distance_matrix(matrix, sqrt=False):\n",
    "    norm_squared = torch.sum(matrix ** 2, dim=1, keepdim=True)\n",
    "    print(\"norm_squared\", norm_squared.shape)\n",
    "    print(\"matrix t\", matrix.transpose(2, 1).shape)\n",
    "    print(\"matrix\", matrix.shape)\n",
    "    print(\"matrix t * matrix\", torch.bmm(matrix.transpose(2, 1), matrix).shape)\n",
    "    \n",
    "    dot_product = torch.bmm(matrix.transpose(2, 1), matrix)\n",
    "    dist_matrix = norm_squared + norm_squared.transpose(2, 1) - 2 * dot_product\n",
    "    \n",
    "    dist_matrix = torch.clamp(dist_matrix, min=0)  \n",
    "    \n",
    "    if sqrt:\n",
    "        dist_matrix = torch.sqrt(dist_matrix)\n",
    "    return dist_matrix\n",
    "\n",
    "ex = torch.randn(32, 3, 28)\n",
    "o1 = _calculate_distance_matrix(ex)\n",
    "print(o1.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm squared torch.Size([32, 28, 1])\n",
      "norm sqaured no permute torch.Size([32, 1, 28])\n",
      "norm squared sample torch.Size([32, 1, 10])\n",
      "norm squared sample no permute torch.Size([32, 1, 10])\n",
      "dot product torch.Size([32, 28, 10])\n",
      "dist matrix torch.Size([32, 28, 10])\n",
      "torch.Size([32, 28, 10])\n"
     ]
    }
   ],
   "source": [
    "# N Samples\n",
    "def original_calculate_distance_matrix_N(matrix, matrix_sample, sqrt=False):\n",
    "    \"\"\"Calculates distance matrix between two input matrices\"\"\" \n",
    "    norm_squared = torch.sum(matrix ** 2, dim=1, keepdim=True).permute(0, 2, 1)\n",
    "    \n",
    "    print(\"norm squared\", norm_squared.shape)\n",
    "    print(\"norm sqaured no permute\", torch.sum(matrix ** 2, dim=1, keepdim=True).shape)\n",
    "    \n",
    "    norm_squared_sample = torch.sum(matrix_sample ** 2, dim=1, keepdim=True).transpose(2, 1).permute(0, 2, 1)\n",
    "    print(\"norm squared sample\", norm_squared_sample.shape)\n",
    "    print(\"norm squared sample no permute\", torch.sum(matrix_sample ** 2, dim=1, keepdim=True).shape)\n",
    "    \n",
    "    dot_product = torch.bmm(matrix.transpose(2, 1), matrix_sample)\n",
    "    print(\"dot product\", dot_product.shape)\n",
    "    \n",
    "    dist_matrix = norm_squared + norm_squared_sample - 2 * dot_product\n",
    "    print(\"dist matrix\", dist_matrix.shape)\n",
    "    \n",
    "    dist_matrix = torch.clamp(dist_matrix, min=0.0)  \n",
    "    \n",
    "    if sqrt:\n",
    "        dist_matrix = torch.sqrt(dist_matrix)\n",
    "    return dist_matrix\n",
    "\n",
    "ex = torch.randn(32, 3, 28)\n",
    "ex1 = torch.randn(32, 3, 10)\n",
    "o1 = original_calculate_distance_matrix_N(ex, ex1)\n",
    "print(o1.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Similarity Matrix Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All Samples\n",
    "def original_calculate_similarity_matrix(matrix): \n",
    "    \"\"\"Calculates similarity matrix of the input matrix\"\"\"\n",
    "    normalized_matrix = F.normalize(matrix, p=2, dim=1) # p=2 (L2 Norm - Euclidean Distance), dim=1 (across the channels)\n",
    "    dot_product = torch.bmm(normalized_matrix.transpose(2, 1), normalized_matrix)\n",
    "    similarity_matrix = dot_product \n",
    "    return similarity_matrix\n",
    "\n",
    "def optimized_calculate_similarity_matrix(matrix): \n",
    "    normalized_matrix = F.normalized(matrix, p=2, dim=1)\n",
    "    similarity_matrix = torch.bmm(normalized_matrix.transpose(2, 1), normalized_matrix)\n",
    "    return similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N Samples\n",
    "def original_calculate_similarity_matrix_N(matrix, matrix_sample): \n",
    "    \"\"\"Calculates similarity matrix between two input matrices\"\"\"\n",
    "    norm_matrix = F.normalize(matrix, p=2, dim=1) # p=2 (L2 Norm - Euclidean Distance), dim=1 (across the channels)\n",
    "    norm_sample = F.normalize(matrix_sample, p=2, dim=1)\n",
    "    similarity_matrix = torch.bmm(norm_matrix.transpose(2, 1), norm_sample)\n",
    "    return similarity_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Topk Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original matrix shape torch.Size([32, 3, 28])\n",
      "original similarity matrix shape torch.Size([32, 28, 28])\n",
      "prime shape torch.Size([32, 3, 140])\n"
     ]
    }
   ],
   "source": [
    "# All Samples\n",
    "\n",
    "@staticmethod \n",
    "def prime_vmap_2d(matrix, magnitude_matrix, num_nearest_neighbors, maximum): \n",
    "    \"\"\"Vectorization / Vmap Implementation for Nearest Neighbor Tensor 2D\"\"\"\n",
    "    batched_process = torch.vmap(process_batch, in_dims=(0, 0, None), out_dims=0)\n",
    "    prime = batched_process(matrix, magnitude_matrix, num_nearest_neighbors, flatten=True, maximum=maximum)\n",
    "    return prime \n",
    "\n",
    "@staticmethod \n",
    "def prime_vmap_3d(matrix, magnitude_matrix, num_nearest_neighbors, maximum): \n",
    "    \"\"\"Vectorization / Vmap Implementation for Nearest Neighbor Tensor 3D\"\"\"\n",
    "    batched_process = torch.vmap(process_batch, in_dims=(0, 0, None), out_dims=0)\n",
    "    prime = batched_process(matrix, magnitude_matrix, num_nearest_neighbors, flatten=False, maximum=maximum)\n",
    "    return prime\n",
    "\n",
    "@staticmethod \n",
    "def process_batch(matrix, magnitude_matrix, num_nearest_neighbors, flatten, maximum): \n",
    "    \"\"\"Process the batch of matrices by finding the K nearest neighbors with reshaping.\"\"\"\n",
    "    ind = torch.topk(magnitude_matrix, num_nearest_neighbors, largest=maximum).indices \n",
    "    neigh = matrix[:, ind]\n",
    "    if flatten: \n",
    "        reshape = torch.flatten(neigh, start_dim=1)\n",
    "        return reshape\n",
    "    return neigh\n",
    "\n",
    "mat = torch.randn(32, 3, 28)\n",
    "mag = original_calculate_similarity_matrix(mat)\n",
    "prime = prime_vmap_2d(mat, mag, 5, True)\n",
    "\n",
    "print('original matrix shape', mat.shape)\n",
    "print('original similarity matrix shape', mag.shape)\n",
    "print('prime shape', prime.shape)\n",
    "\n",
    "# 28 * 5 = 140 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original matrix shape torch.Size([32, 3, 28])\n",
      "original similarity matrix shape torch.Size([32, 28, 28])\n",
      "prime shape torch.Size([32, 3, 140])\n",
      "tensor([[[-0.5865, -0.5183, -0.5359,  ...,  0.2010, -0.4622,  0.7154],\n",
      "         [ 1.2395,  0.5388,  1.0418,  ..., -0.5152, -0.3412, -0.3728],\n",
      "         [ 0.4944,  0.5314,  1.0704,  ...,  0.1287,  1.3529,  0.7918]],\n",
      "\n",
      "        [[-1.7115, -1.7791, -1.9969,  ..., -0.2711,  0.3555, -0.6732],\n",
      "         [-1.3086, -0.7488, -0.6359,  ...,  1.1209,  1.3102,  1.9382],\n",
      "         [-0.4066, -0.1557, -0.1028,  ...,  0.4914, -0.5082, -1.0255]],\n",
      "\n",
      "        [[-2.8810, -0.4386, -1.6857,  ..., -0.9492, -0.2095, -0.2460],\n",
      "         [ 0.8553,  0.2906,  0.4509,  ..., -0.6014, -1.1020, -0.2151],\n",
      "         [-0.4248,  0.0626, -1.8269,  ...,  1.0447,  0.1566,  0.4234]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.3938, -0.7453, -1.3284,  ..., -1.3938, -0.8943, -0.7827],\n",
      "         [-0.0819, -0.2186, -0.2709,  ..., -0.0819, -1.2010, -1.0662],\n",
      "         [ 0.5803,  0.4700, -0.3583,  ...,  0.5803, -0.5836,  0.1117]],\n",
      "\n",
      "        [[-0.7298, -1.5396, -1.2956,  ...,  0.1313,  0.5815,  0.4492],\n",
      "         [ 0.3536,  0.3587,  0.6032,  ..., -0.4435, -0.8764, -1.5409],\n",
      "         [ 0.4621,  0.8964, -0.0531,  ..., -0.5401, -0.1236, -0.5726]],\n",
      "\n",
      "        [[ 0.1326,  0.9885,  0.6009,  ...,  0.9588,  1.2637,  0.4020],\n",
      "         [ 0.0830, -0.4098,  1.4054,  ..., -0.8228,  0.0042,  0.2943],\n",
      "         [-0.2932, -1.8251, -1.0299,  ..., -0.4478,  1.7038,  0.6862]]])\n"
     ]
    }
   ],
   "source": [
    "torch.set_printoptions(precision=4, sci_mode=False)\n",
    "\n",
    "\n",
    "def prime_brute(matrix, dist_matrix, K): \n",
    "    stack_list = [] \n",
    "    count = 0 \n",
    "    for i in range(matrix.shape[0]): \n",
    "        # print(\"i\", i)\n",
    "        concat_list = [] \n",
    "        for j in range(matrix.shape[2]): \n",
    "            # Get the indices of the nearest neighbors\n",
    "            indices = torch.topk(dist_matrix[i, j, :], K, largest=True).indices\n",
    "            # print(\"indices\", indices)\n",
    "            # Get the nearest neighbors\n",
    "            nearest_neighbors = matrix[i, :, indices]\n",
    "            \n",
    "            # Concatenate the nearest neighbors\n",
    "            concat_list.append(nearest_neighbors)\n",
    "            count += 1\n",
    "        # Concatenate the tensor list to create the convolution matrix \n",
    "        # print()\n",
    "        concat = torch.cat(concat_list, dim=1)\n",
    "        stack_list.append(concat)\n",
    "    prime = torch.stack(stack_list, dim= 0)\n",
    "    # print(\"count\", count)\n",
    "    return prime\n",
    "        \n",
    "\n",
    "mat = torch.randn(32, 3, 28)\n",
    "sim = original_calculate_similarity_matrix(mat)\n",
    "prime_b = prime_brute(mat, sim, 5)\n",
    "print('original matrix shape', mat.shape)\n",
    "print('original similarity matrix shape', sim.shape)\n",
    "print('prime shape', prime.shape)\n",
    "print(prime_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topk indices:  torch.Size([32, 28, 5])\n",
      "batch_size:  32\n",
      "channels:  3\n",
      "tokens:  28\n",
      "K:  5\n",
      "tensor([[[[ 0, 20, 11,  6,  9],\n",
      "          [ 1, 26, 18, 14,  8],\n",
      "          [ 2, 22, 21,  0, 13],\n",
      "          ...,\n",
      "          [25,  4,  5,  7, 19],\n",
      "          [26,  8,  1, 18, 14],\n",
      "          [27, 16,  3, 12, 19]],\n",
      "\n",
      "         [[ 0, 20, 11,  6,  9],\n",
      "          [ 1, 26, 18, 14,  8],\n",
      "          [ 2, 22, 21,  0, 13],\n",
      "          ...,\n",
      "          [25,  4,  5,  7, 19],\n",
      "          [26,  8,  1, 18, 14],\n",
      "          [27, 16,  3, 12, 19]],\n",
      "\n",
      "         [[ 0, 20, 11,  6,  9],\n",
      "          [ 1, 26, 18, 14,  8],\n",
      "          [ 2, 22, 21,  0, 13],\n",
      "          ...,\n",
      "          [25,  4,  5,  7, 19],\n",
      "          [26,  8,  1, 18, 14],\n",
      "          [27, 16,  3, 12, 19]]],\n",
      "\n",
      "\n",
      "        [[[ 0, 15, 22,  2,  5],\n",
      "          [ 1, 19, 24, 21, 23],\n",
      "          [ 2,  6, 25, 20,  9],\n",
      "          ...,\n",
      "          [25,  9, 12,  2, 18],\n",
      "          [26, 10,  8, 27, 16],\n",
      "          [27, 16, 23,  8, 26]],\n",
      "\n",
      "         [[ 0, 15, 22,  2,  5],\n",
      "          [ 1, 19, 24, 21, 23],\n",
      "          [ 2,  6, 25, 20,  9],\n",
      "          ...,\n",
      "          [25,  9, 12,  2, 18],\n",
      "          [26, 10,  8, 27, 16],\n",
      "          [27, 16, 23,  8, 26]],\n",
      "\n",
      "         [[ 0, 15, 22,  2,  5],\n",
      "          [ 1, 19, 24, 21, 23],\n",
      "          [ 2,  6, 25, 20,  9],\n",
      "          ...,\n",
      "          [25,  9, 12,  2, 18],\n",
      "          [26, 10,  8, 27, 16],\n",
      "          [27, 16, 23,  8, 26]]],\n",
      "\n",
      "\n",
      "        [[[ 0, 23, 17, 26, 27],\n",
      "          [ 1, 19,  9, 22, 24],\n",
      "          [ 2,  4, 18,  7,  3],\n",
      "          ...,\n",
      "          [25, 20,  6, 15, 21],\n",
      "          [26, 17,  0, 16, 23],\n",
      "          [27,  8, 22, 18,  9]],\n",
      "\n",
      "         [[ 0, 23, 17, 26, 27],\n",
      "          [ 1, 19,  9, 22, 24],\n",
      "          [ 2,  4, 18,  7,  3],\n",
      "          ...,\n",
      "          [25, 20,  6, 15, 21],\n",
      "          [26, 17,  0, 16, 23],\n",
      "          [27,  8, 22, 18,  9]],\n",
      "\n",
      "         [[ 0, 23, 17, 26, 27],\n",
      "          [ 1, 19,  9, 22, 24],\n",
      "          [ 2,  4, 18,  7,  3],\n",
      "          ...,\n",
      "          [25, 20,  6, 15, 21],\n",
      "          [26, 17,  0, 16, 23],\n",
      "          [27,  8, 22, 18,  9]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0, 21, 27, 23,  8],\n",
      "          [ 1, 23, 20,  4,  9],\n",
      "          [ 2, 18, 25, 22, 13],\n",
      "          ...,\n",
      "          [25, 18,  2, 13, 10],\n",
      "          [26, 27, 11,  0, 20],\n",
      "          [27, 26,  0, 20,  1]],\n",
      "\n",
      "         [[ 0, 21, 27, 23,  8],\n",
      "          [ 1, 23, 20,  4,  9],\n",
      "          [ 2, 18, 25, 22, 13],\n",
      "          ...,\n",
      "          [25, 18,  2, 13, 10],\n",
      "          [26, 27, 11,  0, 20],\n",
      "          [27, 26,  0, 20,  1]],\n",
      "\n",
      "         [[ 0, 21, 27, 23,  8],\n",
      "          [ 1, 23, 20,  4,  9],\n",
      "          [ 2, 18, 25, 22, 13],\n",
      "          ...,\n",
      "          [25, 18,  2, 13, 10],\n",
      "          [26, 27, 11,  0, 20],\n",
      "          [27, 26,  0, 20,  1]]],\n",
      "\n",
      "\n",
      "        [[[ 0,  2,  7, 24,  5],\n",
      "          [ 1, 10, 11, 14,  9],\n",
      "          [ 2,  0,  8,  7,  3],\n",
      "          ...,\n",
      "          [25,  4, 20, 18, 15],\n",
      "          [26, 13, 23,  4, 22],\n",
      "          [27, 22,  4, 26, 23]],\n",
      "\n",
      "         [[ 0,  2,  7, 24,  5],\n",
      "          [ 1, 10, 11, 14,  9],\n",
      "          [ 2,  0,  8,  7,  3],\n",
      "          ...,\n",
      "          [25,  4, 20, 18, 15],\n",
      "          [26, 13, 23,  4, 22],\n",
      "          [27, 22,  4, 26, 23]],\n",
      "\n",
      "         [[ 0,  2,  7, 24,  5],\n",
      "          [ 1, 10, 11, 14,  9],\n",
      "          [ 2,  0,  8,  7,  3],\n",
      "          ...,\n",
      "          [25,  4, 20, 18, 15],\n",
      "          [26, 13, 23,  4, 22],\n",
      "          [27, 22,  4, 26, 23]]],\n",
      "\n",
      "\n",
      "        [[[ 0,  3, 20, 23, 12],\n",
      "          [ 1, 12, 26,  0,  3],\n",
      "          [ 2,  7, 10, 11, 16],\n",
      "          ...,\n",
      "          [25, 15,  6, 21, 24],\n",
      "          [26, 22, 25,  1,  3],\n",
      "          [27, 23, 17, 10,  4]],\n",
      "\n",
      "         [[ 0,  3, 20, 23, 12],\n",
      "          [ 1, 12, 26,  0,  3],\n",
      "          [ 2,  7, 10, 11, 16],\n",
      "          ...,\n",
      "          [25, 15,  6, 21, 24],\n",
      "          [26, 22, 25,  1,  3],\n",
      "          [27, 23, 17, 10,  4]],\n",
      "\n",
      "         [[ 0,  3, 20, 23, 12],\n",
      "          [ 1, 12, 26,  0,  3],\n",
      "          [ 2,  7, 10, 11, 16],\n",
      "          ...,\n",
      "          [25, 15,  6, 21, 24],\n",
      "          [26, 22, 25,  1,  3],\n",
      "          [27, 23, 17, 10,  4]]]])\n",
      "indices_expanded shape: torch.Size([32, 3, 28, 5])\n",
      "\n",
      "prime_new shape: torch.Size([32, 3, 140])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "_, topk_indices = torch.topk(sim, k=5, dim=2, largest=True)  \n",
    "print(\"topk indices: \", topk_indices.shape)  \n",
    "\n",
    "\n",
    "batch_size, channels, tokens = mat.shape\n",
    "K = topk_indices.shape[-1]  \n",
    "print(\"batch_size: \", batch_size)\n",
    "print(\"channels: \", channels)\n",
    "print(\"tokens: \", tokens)\n",
    "print(\"K: \", K)\n",
    "\n",
    "# Expand topk_indices: add a channel dimension at dim=1\n",
    "indices_expanded = topk_indices.unsqueeze(1).expand(batch_size, channels, tokens, K)\n",
    "print(indices_expanded)\n",
    "\n",
    "print(\"indices_expanded shape:\", indices_expanded.shape)  # torch.Size([32, 3, 28, 5])\n",
    "\n",
    "\n",
    "\n",
    "print()\n",
    "\n",
    "# Create index tensors for batch and channel dimensions:\n",
    "batch_indices = torch.arange(batch_size).view(batch_size, 1, 1, 1).expand(batch_size, channels, tokens, K)\n",
    "\n",
    "channel_indices = torch.arange(channels).view(1, channels, 1, 1).expand(batch_size, channels, tokens, K)\n",
    "\n",
    "# Now use advanced indexing:\n",
    "# For each [b, c, i, j], we select mat[b, c, indices_expanded[b, c, i, j]]\n",
    "prime = mat[batch_indices, channel_indices, indices_expanded]\n",
    "# prime will have shape [32, 3, 28, 5]\n",
    "\n",
    "# Finally, reshape (flatten the token and neighbor dimensions) to get [32, 3, 28*5] = [32, 3, 140]\n",
    "prime_new = prime.view(batch_size, channels, -1)\n",
    "\n",
    "print(\"prime_new shape:\", prime_new.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.allclose(prime_b, prime_new))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimized check\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(precision=4, sci_mode=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_similarity_matrix(matrix): \n",
    "    \"\"\"Calculates similarity matrix of the input matrix\"\"\"\n",
    "    normalized_matrix = F.normalize(matrix, p=2, dim=1) # p=2 (L2 Norm - Euclidean Distance), dim=1 (across the channels)\n",
    "    dot_product = torch.bmm(normalized_matrix.transpose(2, 1), normalized_matrix)\n",
    "    similarity_matrix = dot_product \n",
    "    return similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prime_brute(matrix, dist_matrix, K): \n",
    "    stack_list = [] \n",
    "    count = 0 \n",
    "    for i in range(matrix.shape[0]): \n",
    "        concat_list = [] \n",
    "        for j in range(matrix.shape[2]): \n",
    "            indices = torch.topk(dist_matrix[i, j, :], K, largest=True).indices\n",
    "\n",
    "            nearest_neighbors = matrix[i, :, indices]\n",
    "            \n",
    "            concat_list.append(nearest_neighbors)\n",
    "            count += 1\n",
    "        concat = torch.cat(concat_list, dim=1)\n",
    "        stack_list.append(concat)\n",
    "    prime = torch.stack(stack_list, dim= 0)\n",
    "    return prime\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All Samples\n",
    "\n",
    "@staticmethod \n",
    "def prime_vmap_2d(matrix, magnitude_matrix, num_nearest_neighbors, maximum): \n",
    "    \"\"\"Vectorization / Vmap Implementation for Nearest Neighbor Tensor 2D\"\"\"\n",
    "    batched_process = torch.vmap(process_batch, in_dims=(0, 0, None), out_dims=0)\n",
    "    prime = batched_process(matrix, magnitude_matrix, num_nearest_neighbors, flatten=True, maximum=maximum)\n",
    "    return prime \n",
    "\n",
    "@staticmethod \n",
    "def prime_vmap_3d(matrix, magnitude_matrix, num_nearest_neighbors, maximum): \n",
    "    \"\"\"Vectorization / Vmap Implementation for Nearest Neighbor Tensor 3D\"\"\"\n",
    "    batched_process = torch.vmap(process_batch, in_dims=(0, 0, None), out_dims=0)\n",
    "    prime = batched_process(matrix, magnitude_matrix, num_nearest_neighbors, flatten=False, maximum=maximum)\n",
    "    return prime\n",
    "\n",
    "@staticmethod \n",
    "def process_batch(matrix, magnitude_matrix, num_nearest_neighbors, flatten, maximum): \n",
    "    \"\"\"Process the batch of matrices by finding the K nearest neighbors with reshaping.\"\"\"\n",
    "    ind = torch.topk(magnitude_matrix, num_nearest_neighbors, largest=maximum).indices \n",
    "    neigh = matrix[:, ind]\n",
    "    if flatten: \n",
    "        reshape = torch.flatten(neigh, start_dim=1)\n",
    "        return reshape\n",
    "    return neigh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prime_optimized(matrix, dist_matrix, K=5, maximum=False):\n",
    "\n",
    "    _, topk_indices = torch.topk(dist_matrix, k=K, dim=2, largest=True)  \n",
    "\n",
    "\n",
    "    batch_size, channels, tokens = matrix.shape\n",
    "    K = topk_indices.shape[-1]  \n",
    "\n",
    "    indices_expanded = topk_indices.unsqueeze(1).expand(batch_size, channels, tokens, K)\n",
    "\n",
    "    batch_indices = torch.arange(batch_size).view(batch_size, 1, 1, 1).expand(batch_size, channels, tokens, K)\n",
    "\n",
    "    channel_indices = torch.arange(channels).view(1, channels, 1, 1).expand(batch_size, channels, tokens, K)\n",
    "\n",
    "    prime = matrix[batch_indices, channel_indices, indices_expanded]\n",
    "\n",
    "    prime_new = prime.view(batch_size, channels, -1)\n",
    "\n",
    "    return prime_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _prime(matrix, magnitude_matrix, K, maximum):\n",
    "    b, c, t = matrix.shape \n",
    "\n",
    "    _, topk_indices = torch.topk(magnitude_matrix, k = K, dim=2, largest=maximum)\n",
    "    \n",
    "    tk = topk_indices.shape[-1]\n",
    "    \n",
    "    assert K == tk, \"Error: K must be same as tk. K == tk.\"\n",
    "    \n",
    "    indices_expanded = topk_indices.unsqueeze(1).expand(b, c, t, tk)\n",
    "    batch_indices = torch.arange(b).view(b, 1, 1, 1).expand(b, c, t, tk)\n",
    "    channel_indices = torch.arange(c).view(1, c, 1, 1).expand(b, c, t, tk)\n",
    "    \n",
    "    prime = matrix[batch_indices, channel_indices, indices_expanded]\n",
    "    prime = prime.view(b, c, -1)\n",
    "    return prime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original matrix shape torch.Size([32, 3, 28])\n",
      "original similarity matrix shape torch.Size([32, 28, 28])\n",
      "\n",
      "prime brute shape torch.Size([32, 3, 140])\n",
      "prime optimized shape torch.Size([32, 3, 140])\n",
      "prime vmap shape torch.Size([32, 3, 140])\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "mat = torch.randn(32, 3, 28)\n",
    "sim = calculate_similarity_matrix(mat)\n",
    "prime_b = prime_brute(mat, sim, 5)\n",
    "prime_o = prime_optimized(mat, sim, 5)\n",
    "prime_f = prime_vmap_2d(mat, sim, 5, True)\n",
    "prime_ = _prime(mat, sim, 5, True)\n",
    "print('original matrix shape', mat.shape)\n",
    "print('original similarity matrix shape', sim.shape)\n",
    "print()\n",
    "print('prime brute shape', prime_b.shape)\n",
    "print('prime optimized shape', prime_o.shape)\n",
    "print('prime vmap shape', prime_f.shape)\n",
    "\n",
    "print(torch.allclose(prime_b, prime_o))\n",
    "print(torch.allclose(prime_b, prime_f))\n",
    "print(torch.allclose(prime_o, prime_f))\n",
    "print(torch.allclose(prime_b, prime_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### N Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(precision=4, sci_mode=False)\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N Samples\n",
    "def calculate_similarity_matrix_N(matrix, matrix_sample): \n",
    "    \"\"\"Calculates similarity matrix between two input matrices\"\"\"\n",
    "    norm_matrix = F.normalize(matrix, p=2, dim=1) # p=2 (L2 Norm - Euclidean Distance), dim=1 (across the channels)\n",
    "    norm_sample = F.normalize(matrix_sample, p=2, dim=1)\n",
    "    similarity_matrix = torch.bmm(norm_matrix.transpose(2, 1), norm_sample)\n",
    "    return similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prime_vmap_2d_N(matrix, magnitude_matrix, num_nearest_neighbors, rand_idx, maximum): \n",
    "    \"\"\"Vectorization / Vmap Implementation for Nearest Neighbor Tensor 2D\"\"\"\n",
    "    batched_process = torch.vmap(process_batch_N, in_dims=(0, 0, None, None), out_dims=0)\n",
    "    prime = batched_process(matrix, magnitude_matrix, num_nearest_neighbors, rand_idx, flatten=True, maximum=maximum)\n",
    "    return prime \n",
    "\n",
    "def prime_vmap_3d_N(matrix, magnitude_matrix, num_nearest_neighbors, rand_idx, maximum): \n",
    "    \"\"\"Vectorization / Vmap Implementation for Nearest Neighbor Tensor 3D\"\"\"\n",
    "    batched_process = torch.vmap(process_batch_N, in_dims=(0, 0, None, None), out_dims=0)\n",
    "    prime = batched_process(matrix, magnitude_matrix, num_nearest_neighbors, rand_idx, flatten=False, maximum=maximum)\n",
    "    return prime\n",
    "\n",
    "def process_batch_N(matrix, magnitude_matrix, num_nearest_neighbors, rand_idx, flatten, maximum): \n",
    "    \"\"\"Process the batch of matrices by finding the K nearest neighbors with reshaping.\"\"\"\n",
    "    topk_ind = torch.topk(magnitude_matrix, num_nearest_neighbors - 1, largest=maximum).indices\n",
    "    device = topk_ind.device\n",
    "    rand_idx = rand_idx.to(device) # same device as topk_ind\n",
    "    mapped_tensor = rand_idx[topk_ind] \n",
    "    index_tensor = torch.arange(0, matrix.shape[1], device=device).unsqueeze(1) # shape [40, 1]\n",
    "    final_tensor = torch.cat([index_tensor, mapped_tensor], dim=1)\n",
    "    neigh = matrix[:, final_tensor] \n",
    "    if flatten: \n",
    "        reshape = torch.flatten(neigh, start_dim=1)\n",
    "        return reshape\n",
    "    return neigh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _prime_N(matrix, magnitude_matrix, K, rand_idx, maximum):\n",
    "    \"\"\"\n",
    "    Create prime tensor for the N-samples case.\n",
    "    \n",
    "    Args:\n",
    "        matrix (torch.Tensor): Input tensor of shape [b, c, t].\n",
    "        magnitude_matrix (torch.Tensor): Magnitude matrix of shape [b, t, s] \n",
    "                                           (where s is the number of sampled tokens).\n",
    "        K (int): Total number of neighbors to consider (including the self index).\n",
    "        rand_idx (torch.Tensor): 1D tensor of length s containing the sampled indices.\n",
    "        maximum (bool): If True, select the largest values (e.g. for similarity); if False, select the smallest (e.g. for distance).\n",
    "        \n",
    "    Returns:\n",
    "        torch.Tensor: A prime tensor of shape [b, c, t*K].\n",
    "    \"\"\"\n",
    "    b, c, t = matrix.shape\n",
    "    # print(\"batch \", b)\n",
    "    # print(\"channel \", c)\n",
    "    # print(\"token \", t)\n",
    "        \n",
    "\n",
    "    _, topk_indices = torch.topk(magnitude_matrix, k=K - 1, dim=2, largest=maximum)\n",
    "    tk = topk_indices.shape[-1]\n",
    "    assert K == tk + 1, \"Error: K must be same as tk + 1. K == tk + 1.\"\n",
    "    # print(\"topk_indices shape: \", topk_indices.shape)  # torch.Size([32, 28, 4])\n",
    "    \n",
    "    mapped_tensor = rand_idx[topk_indices]\n",
    "    # print(\"mapped_tensor shape: \", mapped_tensor.shape)  # torch.Size([32, 28, 4])\n",
    "    # print(mapped_tensor)\n",
    "\n",
    "    token_indices = torch.arange(t, device=matrix.device).view(1, t, 1).expand(b, t, 1)\n",
    "    # print(\"token_indices shape: \", token_indices.shape)  # torch.Size([32, 28, 1])\n",
    "    # \n",
    "    \n",
    "    final_indices = torch.cat([token_indices, mapped_tensor], dim=2)\n",
    "    # print(\"final_indices shape: \", final_indices.shape)  # torch.Size([32, 28, 5])\n",
    "\n",
    "    indices_expanded = final_indices.unsqueeze(1).expand(b, c, t, K)\n",
    "    # print(\"indices_expanded shape: \", indices_expanded.shape)  # torch.Size([32, 3, 28, 5])\n",
    "    \n",
    "    batch_indices = torch.arange(b, device=matrix.device).view(b, 1, 1, 1).expand(b, c, t, K)\n",
    "    channel_indices = torch.arange(c, device=matrix.device).view(1, c, 1, 1).expand(b, c, t, K)\n",
    "    \n",
    "\n",
    "    prime = matrix[batch_indices, channel_indices, indices_expanded]  \n",
    "    \n",
    "    prime = prime.view(b, c, -1)\n",
    "    return prime\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p1 shape torch.Size([32, 3, 140])\n",
      "o1 shape torch.Size([32, 3, 140])\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "samples = 10\n",
    "x1 = torch.randn(32, 3, 28)\n",
    "\n",
    "\n",
    "rand_idx = torch.tensor(np.random.choice(x1.shape[2], samples, replace=False)) # list \n",
    "x1_sample = x1[:, :, rand_idx]\n",
    "\n",
    "\n",
    "sim = calculate_similarity_matrix_N(x1, x1_sample)\n",
    "p1 = prime_vmap_2d_N(x1, sim, 5, rand_idx, True)\n",
    "o1 = _prime_N(x1, sim, 5, rand_idx, True)\n",
    "print('p1 shape', p1.shape)\n",
    "print('o1 shape', o1.shape)\n",
    "print(torch.allclose(p1, o1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rand_idx tensor([17,  5, 26, 15, 11, 27,  8, 14, 13, 25])\n",
      "rand_idx_1 tensor([24, 12,  3,  5, 25, 13, 16, 20,  6,  2])\n"
     ]
    }
   ],
   "source": [
    "rand_idx = torch.tensor(np.random.choice(x1.shape[2], samples, replace=False)) # list \n",
    "print('rand_idx', rand_idx)\n",
    "\n",
    "rand_idx_1 = torch.randperm(x1.shape[2], device=x1.device)[:samples]\n",
    "\n",
    "print('rand_idx_1', rand_idx_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.2694, -0.2975,  0.0531,  ..., -0.8539, -0.5894, -0.4942],\n",
      "         [ 0.4386,  1.2617,  1.9679,  ..., -0.1308, -0.1011, -0.2730],\n",
      "         [ 0.2822,  0.1671,  0.3515,  ..., -1.7980,  0.0064,  0.0574]],\n",
      "\n",
      "        [[ 1.7518,  1.2711,  2.3639,  ...,  1.1061,  2.3639,  1.2711],\n",
      "         [-0.7599, -1.1533, -2.1803,  ...,  2.1738, -2.1803, -1.1533],\n",
      "         [-0.5267, -0.1448, -0.0572,  ...,  0.9943, -0.0572, -0.1448]],\n",
      "\n",
      "        [[-1.2693, -0.8747, -1.3881,  ..., -0.8747, -0.0742, -1.3881],\n",
      "         [ 0.7128,  0.2238, -0.1755,  ...,  0.2238, -0.0850, -0.1755],\n",
      "         [-0.4798, -0.4872, -0.6020,  ..., -0.4872, -3.1228, -0.6020]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 2.6302,  2.9570,  1.4378,  ...,  0.4437,  2.9570,  0.2356],\n",
      "         [ 1.6285,  0.6963,  0.4922,  ..., -0.2838,  0.6963, -0.6965],\n",
      "         [ 0.0815,  0.7962,  0.6793,  ..., -0.4098,  0.7962,  0.1178]],\n",
      "\n",
      "        [[ 0.0246,  0.2150, -0.0120,  ..., -0.9588,  1.1807,  1.5767],\n",
      "         [ 0.6311,  0.7079, -0.0340,  ...,  1.1877,  0.4322,  0.5445],\n",
      "         [ 0.5661,  0.1787,  0.3671,  ..., -2.0961, -1.6543, -1.7992]],\n",
      "\n",
      "        [[-0.1610, -0.5593, -1.3007,  ...,  1.5264,  1.5164,  1.0232],\n",
      "         [ 1.9358,  1.4047,  0.3177,  ..., -0.0748, -1.0595, -1.6445],\n",
      "         [-0.1443, -0.6470,  0.6294,  ...,  0.5867, -0.1282,  1.1074]]])\n"
     ]
    }
   ],
   "source": [
    "print(p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.2694, -0.2975,  0.0531,  ..., -0.8539, -0.5894, -0.4942],\n",
      "         [ 0.4386,  1.2617,  1.9679,  ..., -0.1308, -0.1011, -0.2730],\n",
      "         [ 0.2822,  0.1671,  0.3515,  ..., -1.7980,  0.0064,  0.0574]],\n",
      "\n",
      "        [[ 1.7518,  1.2711,  2.3639,  ...,  1.1061,  2.3639,  1.2711],\n",
      "         [-0.7599, -1.1533, -2.1803,  ...,  2.1738, -2.1803, -1.1533],\n",
      "         [-0.5267, -0.1448, -0.0572,  ...,  0.9943, -0.0572, -0.1448]],\n",
      "\n",
      "        [[-1.2693, -0.8747, -1.3881,  ..., -0.8747, -0.0742, -1.3881],\n",
      "         [ 0.7128,  0.2238, -0.1755,  ...,  0.2238, -0.0850, -0.1755],\n",
      "         [-0.4798, -0.4872, -0.6020,  ..., -0.4872, -3.1228, -0.6020]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 2.6302,  2.9570,  1.4378,  ...,  0.4437,  2.9570,  0.2356],\n",
      "         [ 1.6285,  0.6963,  0.4922,  ..., -0.2838,  0.6963, -0.6965],\n",
      "         [ 0.0815,  0.7962,  0.6793,  ..., -0.4098,  0.7962,  0.1178]],\n",
      "\n",
      "        [[ 0.0246,  0.2150, -0.0120,  ..., -0.9588,  1.1807,  1.5767],\n",
      "         [ 0.6311,  0.7079, -0.0340,  ...,  1.1877,  0.4322,  0.5445],\n",
      "         [ 0.5661,  0.1787,  0.3671,  ..., -2.0961, -1.6543, -1.7992]],\n",
      "\n",
      "        [[-0.1610, -0.5593, -1.3007,  ...,  1.5264,  1.5164,  1.0232],\n",
      "         [ 1.9358,  1.4047,  0.3177,  ..., -0.0748, -1.0595, -1.6445],\n",
      "         [-0.1443, -0.6470,  0.6294,  ...,  0.5867, -0.1282,  1.1074]]])\n"
     ]
    }
   ],
   "source": [
    "print(o1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
