{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Branching network CNN & ConvNN channels ratio \n",
    "- Branching network CNN & ConvNN channels ratio tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mingikang/miniforge3/envs/ML/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Torch\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim \n",
    "\n",
    "\n",
    "# Train + Data \n",
    "import sys \n",
    "sys.path.append('../Layers')\n",
    "from Conv1d_NN_spatial import * \n",
    "from Conv2d_NN_spatial import * \n",
    "\n",
    "sys.path.append('../Data')\n",
    "from CIFAR10 import * \n",
    "\n",
    "\n",
    "sys.path.append('../Models')\n",
    "from models_2d import *\n",
    "\n",
    "sys.path.append('../Train')\n",
    "from train2d import * \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "cifar10 = CIFAR10()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i.a. Control Model (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Time: 20.386385202407837, Loss: 1.3867303351764484\n",
      "Epoch 2, Time: 19.809027910232544, Loss: 0.8324027435706399\n",
      "Epoch 3, Time: 20.917338132858276, Loss: 0.41221488842650145\n",
      "Epoch 4, Time: 22.700978994369507, Loss: 0.11169533632562288\n",
      "Epoch 5, Time: 22.000359773635864, Loss: 0.04843749803380178\n",
      "Epoch 6, Time: 21.676279067993164, Loss: 0.05190996082661593\n",
      "Epoch 7, Time: 25.63969612121582, Loss: 0.043952928459131256\n",
      "Epoch 8, Time: 23.604048252105713, Loss: 0.0385089573845484\n",
      "Epoch 9, Time: 21.84818696975708, Loss: 0.04112788204885567\n",
      "Epoch 10, Time: 21.940598011016846, Loss: 0.029408731801367466\n",
      "\n",
      " Average epoch time: 22.052289843559265\n",
      "Accuracy on test set: 64.46%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "64.46"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CNN\n",
    "CNN_1 = CNN()\n",
    "\n",
    "# Test + Eval\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(CNN_1.parameters(), lr=0.001)\n",
    "num_epochs = 10 \n",
    "train_model(CNN_1, cifar10.train_loader, criterion, optimizer, num_epochs)\n",
    "evaluate_accuracy(CNN_1, cifar10.test_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i.b. Control Model (ConvNN K, All Sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Time: 55.324108839035034, Loss: 1.492999423190456\n",
      "Epoch 2, Time: 55.117668867111206, Loss: 1.1709280427916886\n",
      "Epoch 3, Time: 339.9752480983734, Loss: 0.9580171751549177\n",
      "Epoch 4, Time: 101.52640581130981, Loss: 0.7408937683038395\n",
      "Epoch 5, Time: 1457.1778450012207, Loss: 0.5333706660724967\n",
      "Epoch 6, Time: 160.39961695671082, Loss: 0.36083765234560006\n",
      "Epoch 7, Time: 1295.6668319702148, Loss: 0.2652174834295383\n",
      "Epoch 8, Time: 297.79807591438293, Loss: 0.20433503577528556\n",
      "Epoch 9, Time: 52.71545720100403, Loss: 0.1754020130871545\n",
      "Epoch 10, Time: 52.1993887424469, Loss: 0.1519088471913353\n",
      "\n",
      " Average epoch time: 386.790064740181\n",
      "Accuracy on test set: 56.03%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "56.03"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convNN_2d_k_all = ConvNN_2D_K_All()\n",
    "\n",
    "# Test + Eval\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(convNN_2d_k_all.parameters(), lr=0.001)\n",
    "num_epochs = 10 \n",
    "train_model(convNN_2d_k_all, cifar10.train_loader, criterion, optimizer, num_epochs)\n",
    "evaluate_accuracy(convNN_2d_k_all, cifar10.test_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ii. Changing the channel ratios\n",
    "- 0, 2, 4, 8, 12, 16, 20, 24, 28, 30, 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Time: 67.1108877658844, Loss: 1.4489912985993163\n",
      "Epoch 2, Time: 64.74061894416809, Loss: 1.0703512270127415\n",
      "Epoch 3, Time: 65.91416025161743, Loss: 0.7958788811550725\n",
      "Epoch 4, Time: 66.0019919872284, Loss: 0.48670538147087294\n",
      "Epoch 5, Time: 65.68274784088135, Loss: 0.29185653641781845\n",
      "Epoch 6, Time: 65.93833994865417, Loss: 0.18746196069514087\n",
      "Epoch 7, Time: 64.73951005935669, Loss: 0.16315991002316002\n",
      "Epoch 8, Time: 65.03830409049988, Loss: 0.14328532542466468\n",
      "Epoch 9, Time: 65.0835931301117, Loss: 0.12519640550184089\n",
      "Epoch 10, Time: 65.14130783081055, Loss: 0.11371596972190101\n",
      "\n",
      " Average epoch time: 65.53914618492126\n",
      "Accuracy on test set: 57.48%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "57.48"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Branching All Samples, ratio = 0:32\n",
    "branching_convNN_2D_k_all_0_32 = Branching_ConvNN_2D_K_All(channel_ratio = (0, 32))\n",
    "\n",
    "\n",
    "# Test + Eval\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(branching_convNN_2D_k_all_0_32.parameters(), lr=0.001)\n",
    "num_epochs = 10 \n",
    "train_model(branching_convNN_2D_k_all_0_32, cifar10.train_loader, criterion, optimizer, num_epochs)\n",
    "evaluate_accuracy(branching_convNN_2D_k_all_0_32, cifar10.test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Time: 69.53709101676941, Loss: 1.4419782704404553\n",
      "Epoch 2, Time: 67.75156497955322, Loss: 1.046088614503441\n",
      "Epoch 3, Time: 68.98831415176392, Loss: 0.7639279342673319\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(branching_convNN_2D_k_all_2_30\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[1;32m      8\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m \n\u001b[0;32m----> 9\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbranching_convNN_2D_k_all_2_30\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcifar10\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m evaluate_accuracy(branching_convNN_2D_k_all_2_30, cifar10\u001b[38;5;241m.\u001b[39mtest_loader)\n",
      "File \u001b[0;32m~/Developer/Convolutional-Nearest-Neighbor/Testing/../Train/train2d.py:33\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, criterion, optimizer, num_epochs)\u001b[0m\n\u001b[1;32m     31\u001b[0m images, labels \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmps\u001b[39m\u001b[38;5;124m'\u001b[39m), labels\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmps\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m## TODO edit later\u001b[39;00m\n\u001b[1;32m     32\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 33\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     35\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/miniforge3/envs/ML/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/ML/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Developer/Convolutional-Nearest-Neighbor/Testing/../Models/models_2d.py:353\u001b[0m, in \u001b[0;36mBranching_ConvNN_2D_K_All.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m--> 353\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    354\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x)\n\u001b[1;32m    356\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflatten(x)\n",
      "File \u001b[0;32m~/miniforge3/envs/ML/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/ML/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Developer/Convolutional-Nearest-Neighbor/Testing/../Layers/ConvNN_CNN_Branching.py:59\u001b[0m, in \u001b[0;36mConvNN_CNN_Random_BranchingLayer.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     56\u001b[0m     x1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbranch1(x)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchannel_ratio[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 59\u001b[0m     x2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbranch2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchannel_ratio[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     62\u001b[0m     concat \u001b[38;5;241m=\u001b[39m x2\n",
      "File \u001b[0;32m~/miniforge3/envs/ML/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/ML/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/ML/lib/python3.12/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/miniforge3/envs/ML/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/ML/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Developer/Convolutional-Nearest-Neighbor/Testing/../Layers/Conv2d_NN.py:148\u001b[0m, in \u001b[0;36mConv2d_NN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    143\u001b[0m         x1 \u001b[38;5;241m=\u001b[39m x\n\u001b[1;32m    146\u001b[0m x2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflatten(x1)\n\u001b[0;32m--> 148\u001b[0m x3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConv1d_NN\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx2\u001b[49m\u001b[43m)\u001b[49m  \n\u001b[1;32m    150\u001b[0m unflatten \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mUnflatten(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, unflattened_size\u001b[38;5;241m=\u001b[39mx1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m:])\n\u001b[1;32m    151\u001b[0m x4 \u001b[38;5;241m=\u001b[39m unflatten(x3)\n",
      "File \u001b[0;32m~/miniforge3/envs/ML/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/ML/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Developer/Convolutional-Nearest-Neighbor/Testing/../Layers/Conv1d_NN.py:113\u001b[0m, in \u001b[0;36mConv1d_NN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmagnitude_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msimilarity\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    111\u001b[0m     matrix_magnitude \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcalculate_similarity_matrix(x1)\n\u001b[0;32m--> 113\u001b[0m prime_2d \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprime_vmap_2d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmatrix_magnitude\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mK\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaximum\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m    115\u001b[0m \u001b[38;5;66;03m# Conv1d Layer\u001b[39;00m\n\u001b[1;32m    116\u001b[0m x2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1d_layer(prime_2d)\n",
      "File \u001b[0;32m~/Developer/Convolutional-Nearest-Neighbor/Testing/../Layers/Conv1d_NN.py:184\u001b[0m, in \u001b[0;36mConv1d_NN.prime_vmap_2d\u001b[0;34m(matrix, magnitude_matrix, num_nearest_neighbors, maximum)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Vectorization / Vmap Implementation for Nearest Neighbor Tensor 2D\"\"\"\u001b[39;00m\n\u001b[1;32m    183\u001b[0m batched_process \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mvmap(Conv1d_NN\u001b[38;5;241m.\u001b[39mprocess_batch, in_dims\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m), out_dims\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 184\u001b[0m prime \u001b[38;5;241m=\u001b[39m \u001b[43mbatched_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmatrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmagnitude_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_nearest_neighbors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflatten\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaximum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximum\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m prime\n",
      "File \u001b[0;32m~/miniforge3/envs/ML/lib/python3.12/site-packages/torch/_functorch/apis.py:188\u001b[0m, in \u001b[0;36mvmap.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 188\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvmap_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandomness\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/ML/lib/python3.12/site-packages/torch/_functorch/vmap.py:278\u001b[0m, in \u001b[0;36mvmap_impl\u001b[0;34m(func, in_dims, out_dims, randomness, chunk_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _chunked_vmap(func, flat_in_dims, chunks_flat_args,\n\u001b[1;32m    275\u001b[0m                          args_spec, out_dims, randomness, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    277\u001b[0m \u001b[38;5;66;03m# If chunk_size is not specified.\u001b[39;00m\n\u001b[0;32m--> 278\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_flat_vmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflat_in_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs_spec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandomness\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/ML/lib/python3.12/site-packages/torch/_functorch/vmap.py:44\u001b[0m, in \u001b[0;36mdoesnt_support_saved_tensors_hooks.<locals>.fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfn\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mdisable_saved_tensors_hooks(message):\n\u001b[0;32m---> 44\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/ML/lib/python3.12/site-packages/torch/_functorch/vmap.py:391\u001b[0m, in \u001b[0;36m_flat_vmap\u001b[0;34m(func, batch_size, flat_in_dims, flat_args, args_spec, out_dims, randomness, **kwargs)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    390\u001b[0m     batched_inputs \u001b[38;5;241m=\u001b[39m _create_batched_inputs(flat_in_dims, flat_args, vmap_level, args_spec)\n\u001b[0;32m--> 391\u001b[0m     batched_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbatched_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unwrap_batched(batched_outputs, out_dims, vmap_level, batch_size, func)\n\u001b[1;32m    393\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/Developer/Convolutional-Nearest-Neighbor/Testing/../Layers/Conv1d_NN.py:200\u001b[0m, in \u001b[0;36mConv1d_NN.process_batch\u001b[0;34m(matrix, magnitude_matrix, num_nearest_neighbors, flatten, maximum)\u001b[0m\n\u001b[1;32m    198\u001b[0m neigh \u001b[38;5;241m=\u001b[39m matrix[:, ind]\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m flatten: \n\u001b[0;32m--> 200\u001b[0m     reshape \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43mneigh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m reshape\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m neigh\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Branching All Samples, ratio = 2:30\n",
    "branching_convNN_2D_k_all_2_30 = Branching_ConvNN_2D_K_All(channel_ratio = (2, 30))\n",
    "\n",
    "\n",
    "# Test + Eval\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(branching_convNN_2D_k_all_2_30.parameters(), lr=0.001)\n",
    "num_epochs = 10 \n",
    "train_model(branching_convNN_2D_k_all_2_30, cifar10.train_loader, criterion, optimizer, num_epochs)\n",
    "evaluate_accuracy(branching_convNN_2D_k_all_2_30, cifar10.test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Time: 64.85607385635376, Loss: 1.432655492249657\n",
      "Epoch 2, Time: 65.08111882209778, Loss: 1.048978096612579\n",
      "Epoch 3, Time: 62.71344518661499, Loss: 0.7671657848312422\n",
      "Epoch 4, Time: 62.44022822380066, Loss: 0.45550018526099223\n",
      "Epoch 5, Time: 63.128973960876465, Loss: 0.24903302299349434\n",
      "Epoch 6, Time: 63.536157846450806, Loss: 0.17851164824355517\n",
      "Epoch 7, Time: 62.636353969573975, Loss: 0.15080192120140776\n",
      "Epoch 8, Time: 62.496565103530884, Loss: 0.1273560276948144\n",
      "Epoch 9, Time: 62.80874991416931, Loss: 0.12740497918063512\n",
      "Epoch 10, Time: 62.94877099990845, Loss: 0.10331697503993255\n",
      "\n",
      " Average epoch time: 63.26464378833771\n",
      "Accuracy on test set: 61.23%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "61.23"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Branching All Samples, ratio = 4:28\n",
    "branching_convNN_2D_k_all_4_28 = Branching_ConvNN_2D_K_All(channel_ratio = (4, 28))\n",
    "\n",
    "\n",
    "# Test + Eval\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(branching_convNN_2D_k_all_4_28.parameters(), lr=0.001)\n",
    "num_epochs = 10 \n",
    "train_model(branching_convNN_2D_k_all_4_28, cifar10.train_loader, criterion, optimizer, num_epochs)\n",
    "evaluate_accuracy(branching_convNN_2D_k_all_4_28, cifar10.test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Time: 61.19792985916138, Loss: 1.418059145474373\n",
      "Epoch 2, Time: 59.7414391040802, Loss: 1.0054685753934525\n",
      "Epoch 3, Time: 60.022013902664185, Loss: 0.6899744186864789\n",
      "Epoch 4, Time: 59.697246074676514, Loss: 0.3587932030258276\n",
      "Epoch 5, Time: 59.77068114280701, Loss: 0.18874874642914366\n",
      "Epoch 6, Time: 59.758814096450806, Loss: 0.14147234147014406\n",
      "Epoch 7, Time: 59.64130711555481, Loss: 0.11533466850459824\n",
      "Epoch 8, Time: 59.987606048583984, Loss: 0.10089333434505841\n",
      "Epoch 9, Time: 60.33809304237366, Loss: 0.10947510088636728\n",
      "Epoch 10, Time: 59.83788800239563, Loss: 0.08595279824805072\n",
      "\n",
      " Average epoch time: 59.999301838874814\n",
      "Accuracy on test set: 63.09%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "63.09"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Branching All Samples, ratio = 8:24\n",
    "branching_convNN_2D_k_all_8_24 = Branching_ConvNN_2D_K_All(channel_ratio = (8, 24))\n",
    "\n",
    "\n",
    "# Test + Eval\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(branching_convNN_2D_k_all_8_24.parameters(), lr=0.001)\n",
    "num_epochs = 10 \n",
    "train_model(branching_convNN_2D_k_all_8_24, cifar10.train_loader, criterion, optimizer, num_epochs)\n",
    "evaluate_accuracy(branching_convNN_2D_k_all_8_24, cifar10.test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Time: 58.1963791847229, Loss: 1.4235734200233694\n",
      "Epoch 2, Time: 57.50885009765625, Loss: 1.003991657434522\n",
      "Epoch 3, Time: 57.61061406135559, Loss: 0.6985888789834269\n",
      "Epoch 4, Time: 59.0339789390564, Loss: 0.3709175358038119\n",
      "Epoch 5, Time: 60.591845989227295, Loss: 0.19088876023269294\n",
      "Epoch 6, Time: 58.259419679641724, Loss: 0.13190793140869958\n",
      "Epoch 7, Time: 59.8674840927124, Loss: 0.11591172651828402\n",
      "Epoch 8, Time: 59.84418034553528, Loss: 0.11133395252145513\n",
      "Epoch 9, Time: 58.17036700248718, Loss: 0.08429410699967836\n",
      "Epoch 10, Time: 58.20538592338562, Loss: 0.0811461406419604\n",
      "\n",
      " Average epoch time: 58.72885053157806\n",
      "Accuracy on test set: 63.35%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "63.35"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Branching All Samples, ratio = 12:20\n",
    "branching_convNN_2D_k_all_12_20 = Branching_ConvNN_2D_K_All(channel_ratio = (12, 20))\n",
    "\n",
    "\n",
    "# Test + Eval\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(branching_convNN_2D_k_all_12_20.parameters(), lr=0.001)\n",
    "num_epochs = 10 \n",
    "train_model(branching_convNN_2D_k_all_12_20, cifar10.train_loader, criterion, optimizer, num_epochs)\n",
    "evaluate_accuracy(branching_convNN_2D_k_all_12_20, cifar10.test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Time: 58.088088274002075, Loss: 1.422457308644224\n",
      "Epoch 2, Time: 57.19394397735596, Loss: 0.9656509002456275\n",
      "Epoch 3, Time: 55.39641189575195, Loss: 0.6189117185447527\n",
      "Epoch 4, Time: 55.291669845581055, Loss: 0.28291548966713576\n",
      "Epoch 5, Time: 55.707717180252075, Loss: 0.15552941159061764\n",
      "Epoch 6, Time: 55.75892972946167, Loss: 0.11077866517841016\n",
      "Epoch 7, Time: 55.296019077301025, Loss: 0.10439961338195416\n",
      "Epoch 8, Time: 55.67546081542969, Loss: 0.08929849700699144\n",
      "Epoch 9, Time: 55.47766613960266, Loss: 0.07187177269572756\n",
      "Epoch 10, Time: 57.65789818763733, Loss: 0.07907561073347669\n",
      "\n",
      " Average epoch time: 56.15438051223755\n",
      "Accuracy on test set: 65.05%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "65.05"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Branching All Samples, ratio = 16:16\n",
    "branching_convNN_2D_k_all_16_16 = Branching_ConvNN_2D_K_All()\n",
    "\n",
    "# Test + Eval\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(branching_convNN_2D_k_all_16_16.parameters(), lr=0.001)\n",
    "num_epochs = 10 \n",
    "train_model(branching_convNN_2D_k_all_16_16, cifar10.train_loader, criterion, optimizer, num_epochs)\n",
    "evaluate_accuracy(branching_convNN_2D_k_all_16_16, cifar10.test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Time: 54.2251672744751, Loss: 1.3710289246895735\n",
      "Epoch 2, Time: 54.18537998199463, Loss: 0.8936816911258356\n",
      "Epoch 3, Time: 53.69429588317871, Loss: 0.530456053821937\n",
      "Epoch 4, Time: 55.66856288909912, Loss: 0.2177892939218551\n",
      "Epoch 5, Time: 55.70700812339783, Loss: 0.1294048293993887\n",
      "Epoch 6, Time: 55.98659014701843, Loss: 0.09678358958957864\n",
      "Epoch 7, Time: 55.466811180114746, Loss: 0.0912884478552548\n",
      "Epoch 8, Time: 56.641682863235474, Loss: 0.0850097917851306\n",
      "Epoch 9, Time: 55.330487966537476, Loss: 0.07171068787265121\n",
      "Epoch 10, Time: 54.21119809150696, Loss: 0.06063723397749962\n",
      "\n",
      " Average epoch time: 55.111718440055846\n",
      "Accuracy on test set: 64.56%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "64.56"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Branching All Samples, ratio = 20:12\n",
    "branching_convNN_2D_k_all_20_12 = Branching_ConvNN_2D_K_All(channel_ratio = (20, 12))\n",
    "\n",
    "\n",
    "# Test + Eval\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(branching_convNN_2D_k_all_20_12.parameters(), lr=0.001)\n",
    "num_epochs = 10 \n",
    "train_model(branching_convNN_2D_k_all_20_12, cifar10.train_loader, criterion, optimizer, num_epochs)\n",
    "evaluate_accuracy(branching_convNN_2D_k_all_20_12, cifar10.test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Time: 52.314812898635864, Loss: 1.3320258033397558\n",
      "Epoch 2, Time: 50.35570001602173, Loss: 0.8472492911702837\n",
      "Epoch 3, Time: 49.838757038116455, Loss: 0.44969532314849936\n",
      "Epoch 4, Time: 49.745102882385254, Loss: 0.16390874358060795\n",
      "Epoch 5, Time: 50.32077693939209, Loss: 0.10934829720578221\n",
      "Epoch 6, Time: 51.967597007751465, Loss: 0.09783752263247338\n",
      "Epoch 7, Time: 50.88846397399902, Loss: 0.07483530736765336\n",
      "Epoch 8, Time: 50.793882846832275, Loss: 0.07526410856421756\n",
      "Epoch 9, Time: 50.86819887161255, Loss: 0.06793669871214772\n",
      "Epoch 10, Time: 51.506097078323364, Loss: 0.05534693939716119\n",
      "\n",
      " Average epoch time: 50.85993895530701\n",
      "Accuracy on test set: 66.82%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "66.82"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Branching All Samples, ratio = 24:8\n",
    "branching_convNN_2D_k_all_24_8 = Branching_ConvNN_2D_K_All(channel_ratio = (24, 8))\n",
    "\n",
    "# Test + Eval\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(branching_convNN_2D_k_all_24_8.parameters(), lr=0.001)\n",
    "num_epochs = 10 \n",
    "train_model(branching_convNN_2D_k_all_24_8, cifar10.train_loader, criterion, optimizer, num_epochs)\n",
    "evaluate_accuracy(branching_convNN_2D_k_all_24_8, cifar10.test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Time: 48.92677664756775, Loss: 1.3319215680784582\n",
      "Epoch 2, Time: 50.10359191894531, Loss: 0.8562879173651986\n",
      "Epoch 3, Time: 49.258078813552856, Loss: 0.4780505197622892\n",
      "Epoch 4, Time: 49.22862386703491, Loss: 0.1769759501842663\n",
      "Epoch 5, Time: 48.21283292770386, Loss: 0.10790114818543406\n",
      "Epoch 6, Time: 48.27678108215332, Loss: 0.08574587608570866\n",
      "Epoch 7, Time: 48.37729287147522, Loss: 0.08291489084023754\n",
      "Epoch 8, Time: 48.14892792701721, Loss: 0.06749717681631481\n",
      "Epoch 9, Time: 48.50195622444153, Loss: 0.06245660811864838\n",
      "Epoch 10, Time: 48.79196214675903, Loss: 0.07325124225753081\n",
      "\n",
      " Average epoch time: 48.7826824426651\n",
      "Accuracy on test set: 66.63%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "66.63"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Branching All Samples, ratio = 28:4\n",
    "branching_convNN_2D_k_all_28_4 = Branching_ConvNN_2D_K_All(channel_ratio = (28, 4))\n",
    "\n",
    "# Test + Eval\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(branching_convNN_2D_k_all_28_4.parameters(), lr=0.001)\n",
    "num_epochs = 10 \n",
    "train_model(branching_convNN_2D_k_all_28_4, cifar10.train_loader, criterion, optimizer, num_epochs)\n",
    "evaluate_accuracy(branching_convNN_2D_k_all_28_4, cifar10.test_loader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Time: 50.478890895843506, Loss: 1.3633839774619587\n",
      "Epoch 2, Time: 49.16928195953369, Loss: 0.8690495645756002\n",
      "Epoch 3, Time: 49.07562589645386, Loss: 0.5142860942713136\n",
      "Epoch 4, Time: 48.86387300491333, Loss: 0.20746198249385334\n",
      "Epoch 5, Time: 48.07813596725464, Loss: 0.11419978540133485\n",
      "Epoch 6, Time: 48.79758810997009, Loss: 0.08891780118790248\n",
      "Epoch 7, Time: 49.11830496788025, Loss: 0.08596553609979189\n",
      "Epoch 8, Time: 49.30661392211914, Loss: 0.07237654757987269\n",
      "Epoch 9, Time: 49.446269035339355, Loss: 0.06886272277945624\n",
      "Epoch 10, Time: 48.41829299926758, Loss: 0.06764114779517558\n",
      "\n",
      " Average epoch time: 49.075287675857545\n",
      "Accuracy on test set: 65.9%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "65.9"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Branching All Samples, ratio = 30:2\n",
    "branching_convNN_2D_k_all_30_2 = Branching_ConvNN_2D_K_All(channel_ratio = (30, 2))\n",
    "\n",
    "# Test + Eval\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(branching_convNN_2D_k_all_30_2.parameters(), lr=0.001)\n",
    "num_epochs = 10 \n",
    "train_model(branching_convNN_2D_k_all_30_2, cifar10.train_loader, criterion, optimizer, num_epochs)\n",
    "evaluate_accuracy(branching_convNN_2D_k_all_30_2, cifar10.test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Time: 22.43901801109314, Loss: 1.3398583686870078\n",
      "Epoch 2, Time: 21.4631609916687, Loss: 0.8049793754087384\n",
      "Epoch 3, Time: 21.790250062942505, Loss: 0.4105562795039333\n",
      "Epoch 4, Time: 20.948057651519775, Loss: 0.13697266616784703\n",
      "Epoch 5, Time: 20.954326152801514, Loss: 0.09722211170712929\n",
      "Epoch 6, Time: 20.702275037765503, Loss: 0.08245340063769008\n",
      "Epoch 7, Time: 20.801069974899292, Loss: 0.0714347384611914\n",
      "Epoch 8, Time: 20.736119985580444, Loss: 0.07361339946941989\n",
      "Epoch 9, Time: 20.273780822753906, Loss: 0.059524457717565656\n",
      "Epoch 10, Time: 19.758816719055176, Loss: 0.06041707495207954\n",
      "\n",
      " Average epoch time: 20.986687541007996\n",
      "Accuracy on test set: 66.48%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "66.48"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Branching All Samples, ratio = 32: 0 \n",
    "branching_convNN_2D_k_all_32_0 = Branching_ConvNN_2D_K_All(channel_ratio = (32, 0))\n",
    "\n",
    "# Test + Eval\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(branching_convNN_2D_k_all_32_0.parameters(), lr=0.001)\n",
    "num_epochs = 10 \n",
    "train_model(branching_convNN_2D_k_all_32_0, cifar10.train_loader, criterion, optimizer, num_epochs)\n",
    "evaluate_accuracy(branching_convNN_2D_k_all_32_0, cifar10.test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
