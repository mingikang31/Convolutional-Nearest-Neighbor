{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# July 12, 13, 16, 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 120])\n",
      "Time taken to run the function: 0.0036056041717529297 seconds\n",
      "torch.Size([1000, 5])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "\n",
    "dist_matrix = torch.rand(1000, 120)\n",
    "print(dist_matrix.shape)\n",
    "num_nearest_neighbors = 5\n",
    "\n",
    "start = time.time() \n",
    "ind = torch.topk(dist_matrix, num_nearest_neighbors, largest=False).indices\n",
    "end = time.time() \n",
    "\n",
    "print(f\"Time taken to run the function: {end - start} seconds\")\n",
    "print(ind.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ex shape:  torch.Size([32, 12, 40])\n",
      "M shape:  torch.Size([12, 40])\n",
      "[ 9 36 34 38 10]\n",
      "M prime shape:  torch.Size([12, 5])\n",
      "Sim shape:  torch.Size([40, 5])\n",
      "Neig shape:  torch.Size([12, 40, 4])\n",
      "M.unsqueeze(2) shape:  torch.Size([12, 40, 1])\n",
      "torch.Size([12, 40, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s7/md5b66vn4l39df_j063nqlp00000gn/T/ipykernel_47693/2407026106.py:33: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:278.)\n",
      "  neig1 = M[:, b]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "B, C, N = 32, 12, 40\n",
    "n_samples = 5\n",
    "k_neig = 5\n",
    "\n",
    "ex = torch.rand(B, C, N)\n",
    "print(\"Ex shape: \", ex.shape)\n",
    "\n",
    "M = ex[0]/torch.norm(ex[0], dim=0)  # Pick first item in patch and normalize the rows\n",
    "print(\"M shape: \", M.shape)\n",
    "\n",
    "rand_idx = np.random.choice(M.shape[1], n_samples, replace=False) \n",
    "print(rand_idx)\n",
    "\n",
    "M_prime = M[:, rand_idx]\n",
    "print(\"M prime shape: \", M_prime.shape)\n",
    "\n",
    "sim = M.T@M_prime\n",
    "print(\"Sim shape: \", sim.shape)\n",
    "\n",
    "\n",
    "# Make similarities between samples equal to -inf, so they are not considered when using topk\n",
    "#sim[rand_idx, np.arange(n_samples)]  =  -np.inf  \n",
    "# print(sim[:rand_idx[0]])\n",
    "# print(sim[:rand_idx[0]].shape)\n",
    "\n",
    "\n",
    "# Only get k-1 neigbors (we'll add the selves later as the first nearest neigbor) \n",
    "_, indxs = torch.topk(sim, k_neig - 1, largest=True) \n",
    "b = [rand_idx[x] for x in indxs]\n",
    "neig1 = M[:, b]\n",
    "print(\"Neig shape: \", neig1.shape)\n",
    "print(\"M.unsqueeze(2) shape: \", M.unsqueeze(2).shape)\n",
    "\n",
    "# Add the selves as the first nearest neigbor\n",
    "neig2 = torch.concat([M.unsqueeze(2), neig1], dim=2)\n",
    "print(neig2.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9 36 34 38 10]\n",
      "9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.7503,  0.8438,  0.7944,  0.7955,  0.6967],\n",
       "        [ 1.0000,  0.6766,  0.6655,  0.7897,  0.7534,  0.8060],\n",
       "        [ 2.0000,  0.5189,  0.7829,  0.7517,  0.8064,  0.6501],\n",
       "        [ 3.0000,  0.7753,  0.7779,  0.7532,  0.6207,  0.5696],\n",
       "        [ 4.0000,  0.6310,  0.7638,  0.8394,  0.5881,  0.7308],\n",
       "        [ 5.0000,  0.7185,  0.8168,  0.7329,  0.7316,  0.5488],\n",
       "        [ 6.0000,  0.5998,  0.7095,  0.7235,  0.7819,  0.6019],\n",
       "        [ 7.0000,  0.8311,  0.8239,  0.6703,  0.7740,  0.4814],\n",
       "        [ 8.0000,  0.8263,  0.8148,  0.7159,  0.8161,  0.7571],\n",
       "        [ 9.0000,  1.0000,  0.7943,  0.6116,  0.7064,  0.5001],\n",
       "        [10.0000,  0.5001,  0.5486,  0.8512,  0.6431,  1.0000],\n",
       "        [11.0000,  0.6797,  0.7357,  0.8085,  0.8417,  0.7498],\n",
       "        [12.0000,  0.7170,  0.8001,  0.7876,  0.7893,  0.7586],\n",
       "        [13.0000,  0.6181,  0.7710,  0.5917,  0.6989,  0.5950],\n",
       "        [14.0000,  0.7383,  0.7222,  0.7238,  0.5803,  0.5989],\n",
       "        [15.0000,  0.7492,  0.7962,  0.5770,  0.8764,  0.5010],\n",
       "        [16.0000,  0.7389,  0.8719,  0.7707,  0.8375,  0.7452],\n",
       "        [17.0000,  0.6769,  0.7550,  0.8293,  0.7425,  0.7330],\n",
       "        [18.0000,  0.6846,  0.7182,  0.6943,  0.7156,  0.7265],\n",
       "        [19.0000,  0.8421,  0.8581,  0.7991,  0.7112,  0.6310],\n",
       "        [20.0000,  0.7486,  0.8286,  0.7597,  0.8505,  0.8324],\n",
       "        [21.0000,  0.8068,  0.8848,  0.5817,  0.6983,  0.5552],\n",
       "        [22.0000,  0.6533,  0.7745,  0.7513,  0.7079,  0.8120],\n",
       "        [23.0000,  0.8827,  0.8718,  0.7501,  0.8088,  0.6200],\n",
       "        [24.0000,  0.8053,  0.8367,  0.7577,  0.7226,  0.6749],\n",
       "        [25.0000,  0.5621,  0.7427,  0.8511,  0.6947,  0.7834],\n",
       "        [26.0000,  0.6969,  0.8035,  0.8175,  0.7873,  0.7703],\n",
       "        [27.0000,  0.7224,  0.7500,  0.8962,  0.7487,  0.8297],\n",
       "        [28.0000,  0.7142,  0.7772,  0.6719,  0.7514,  0.7458],\n",
       "        [29.0000,  0.8206,  0.9462,  0.8004,  0.7798,  0.7037],\n",
       "        [30.0000,  0.7629,  0.8600,  0.8304,  0.8065,  0.5937],\n",
       "        [31.0000,  0.7158,  0.7621,  0.7615,  0.6595,  0.8264],\n",
       "        [32.0000,  0.8420,  0.7728,  0.8309,  0.8306,  0.7388],\n",
       "        [33.0000,  0.6964,  0.7582,  0.6992,  0.8353,  0.7154],\n",
       "        [34.0000,  0.6116,  0.6909,  1.0000,  0.6594,  0.8512],\n",
       "        [35.0000,  0.7958,  0.7985,  0.6450,  0.8395,  0.6477],\n",
       "        [36.0000,  0.7943,  1.0000,  0.6909,  0.8433,  0.5486],\n",
       "        [37.0000,  0.6639,  0.8759,  0.6668,  0.7626,  0.5111],\n",
       "        [38.0000,  0.7064,  0.8433,  0.6594,  1.0000,  0.6431],\n",
       "        [39.0000,  0.6297,  0.7389,  0.8447,  0.8070,  0.7459]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(rand_idx)\n",
    "c = rand_idx[0]\n",
    "print(c)\n",
    "torch.concat([torch.arange(40).unsqueeze(1), sim], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5267, 0.0521, 0.3913, 0.2414, 0.0314, 0.5558, 0.1473, 0.2186, 0.1122,\n",
       "        0.3036, 0.0699, 0.1393])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M[:, c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5267, 0.0521, 0.3913, 0.2414, 0.0314, 0.5558, 0.1473, 0.2186, 0.1122,\n",
       "         0.3036, 0.0699, 0.1393],\n",
       "        [0.1500, 0.0591, 0.2692, 0.2927, 0.1862, 0.4599, 0.3333, 0.4179, 0.4505,\n",
       "         0.1580, 0.0495, 0.2315],\n",
       "        [0.0526, 0.0525, 0.2882, 0.1481, 0.1473, 0.3530, 0.1390, 0.3723, 0.4461,\n",
       "         0.4086, 0.4474, 0.1384],\n",
       "        [0.3753, 0.2861, 0.0714, 0.2012, 0.1917, 0.1101, 0.3585, 0.4051, 0.0747,\n",
       "         0.0452, 0.4327, 0.4420]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neig1[:, c, :].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5267, 0.0521, 0.3913, 0.2414, 0.0314, 0.5558, 0.1473, 0.2186, 0.1122,\n",
       "         0.3036, 0.0699, 0.1393],\n",
       "        [0.5267, 0.0521, 0.3913, 0.2414, 0.0314, 0.5558, 0.1473, 0.2186, 0.1122,\n",
       "         0.3036, 0.0699, 0.1393],\n",
       "        [0.1500, 0.0591, 0.2692, 0.2927, 0.1862, 0.4599, 0.3333, 0.4179, 0.4505,\n",
       "         0.1580, 0.0495, 0.2315],\n",
       "        [0.0526, 0.0525, 0.2882, 0.1481, 0.1473, 0.3530, 0.1390, 0.3723, 0.4461,\n",
       "         0.4086, 0.4474, 0.1384],\n",
       "        [0.3753, 0.2861, 0.0714, 0.2012, 0.1917, 0.1101, 0.3585, 0.4051, 0.0747,\n",
       "         0.0452, 0.4327, 0.4420]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neig2[:, c, :].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Distance/Similarity Matrix check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance matrix sanity check for all samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distance_matrix(matrix): \n",
    "   '''Calculating the distance matrix of the input matrix'''\n",
    "   norm_squared = torch.sum(matrix ** 2, dim=1, keepdim=True)\n",
    "   dot_product = torch.bmm(matrix.transpose(2, 1), matrix)\n",
    "   dist_matrix = norm_squared + norm_squared.transpose(2, 1) - 2 * dot_product\n",
    "   return torch.sqrt(dist_matrix) # May need to remove torch.sqrt - do not need that computation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance Matrix sanity check for N Sample "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distance_matrix_N(m1, m2):\n",
    "   '''Calculate the distance matrix between two input matrices'''\n",
    "   # to make it simple -> normalize the rows, normalize across c (channels), \n",
    "   norm_squared_1 = torch.sum(m1 ** 2, dim=1, keepdim=True)\n",
    "   norm_squared_2 = torch.sum(m2 ** 2, dim=1, keepdim=True).transpose(2, 1)\n",
    "   dot_product = torch.bmm(m1.transpose(2, 1), m2)\n",
    "\n",
    "   norm_squared_1 = norm_squared_1.permute(0, 2, 1)  \n",
    "   norm_squared_2 = norm_squared_2.permute(0, 2, 1)  \n",
    "\n",
    "   dist_matrix = norm_squared_1 + norm_squared_2 - 2 * dot_product\n",
    "   return torch.sqrt(dist_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_matrix(m1, m2): \n",
    "   # Calculate the distance matrix using for-loops \n",
    "   dist_matrix = torch.zeros(m1.shape[0], m1.shape[2], m2.shape[2])\n",
    "   \n",
    "   for i in range(m1.shape[0]): \n",
    "      for j in range(m1.shape[2]): \n",
    "            for k in range(m2.shape[2]): \n",
    "               dist_matrix[i, j, k] = torch.norm(m1[i, :, j] -  m2[i, :, k])\n",
    "   return dist_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 40, 5])\n",
      "torch.Size([32, 40, 5])\n"
     ]
    }
   ],
   "source": [
    "m1 = torch.rand(32, 12, 40)\n",
    "m2 = torch.rand(32, 12, 5)\n",
    "\n",
    "a = calculate_distance_matrix_N(m1, m2)\n",
    "b = dist_matrix(m1, m2)\n",
    "print(a.shape)\n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.1190, 1.5861, 1.1530, 1.4294, 1.6749])\n",
      "tensor([1.1190, 1.5861, 1.1530, 1.4294, 1.6749])\n",
      "True\n",
      "tensor([[1.1190, 1.5861, 1.1530, 1.4294, 1.6749],\n",
      "        [1.0520, 1.4970, 1.1459, 1.2078, 1.7169],\n",
      "        [1.1073, 1.5688, 1.2173, 1.2805, 1.3759]])\n",
      "tensor([[1.1190, 1.5861, 1.1530, 1.4294, 1.6749],\n",
      "        [1.0520, 1.4970, 1.1459, 1.2078, 1.7169],\n",
      "        [1.1073, 1.5688, 1.2173, 1.2805, 1.3759]])\n"
     ]
    }
   ],
   "source": [
    "print(a[0, 0, :])\n",
    "print(b[0, 0, :]) \n",
    "\n",
    "print(torch.allclose(a, b))\n",
    "\n",
    "print(a[0, :3, :])\n",
    "print(b[0, :3, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity Matrix sanity check for N Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_a(matrix): \n",
    "   '''Calculate the similarity matrix of the input matrix'''\n",
    "   normalized_matrix = F.normalize(matrix, p=2, dim=1) # p=2 (L2 Norm - Euclidean Distance), dim=1 (across the channels)\n",
    "   dot_product = torch.bmm(normalized_matrix.transpose(2, 1), normalized_matrix)\n",
    "   similarity_matrix = dot_product \n",
    "   return similarity_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_b(m):\n",
    "    # Normalize the input matrix\n",
    "    normalized_matrix = F.normalize(m, p=2, dim=1)\n",
    "    \n",
    "    # Initialize the similarity matrix with zeros\n",
    "    similarity_matrix = torch.zeros(m.size(0), m.size(2), m.size(2))\n",
    "    \n",
    "    # Calculate the similarity (dot product) between each pair of vectors\n",
    "    for i in range(m.shape[0]): \n",
    "      for j in range(m.shape[2]): \n",
    "            for k in range(m.shape[2]): \n",
    "               similarity_matrix[i, j, k] = torch.dot(normalized_matrix[i, :, j],  normalized_matrix[i, :, k])\n",
    "    \n",
    "    return similarity_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 40, 40])\n",
      "torch.Size([32, 40, 40])\n",
      "tensor([1.0000, 0.6249, 0.6762])\n",
      "tensor([1.0000, 0.6249, 0.6762])\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "m = torch.rand(32, 12, 40)\n",
    "sim1 = sim_a(m)\n",
    "sim2 = sim_b(m)\n",
    "\n",
    "print(sim1.shape)\n",
    "print(sim2.shape)\n",
    "\n",
    "\n",
    "print(sim1[0, 0, :3])\n",
    "print(sim2[0, 0, :3]) \n",
    "\n",
    "print(torch.allclose(sim1, sim2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## For N Samples\n",
    "\n",
    "def sim_c(m1, m2): \n",
    "   normalized_matrix_1 = F.normalize(m1, p=2, dim=1) # p=2 (L2 Norm - Euclidean Distance), dim=1 (across the channels)\n",
    "   normalized_matrix_2 = F.normalize(m2, p=2, dim=1)\n",
    "   \n",
    "   dot_product = torch.bmm(normalized_matrix_1.transpose(2, 1), normalized_matrix_2)\n",
    "            \n",
    "   similarity_matrix = dot_product \n",
    "   return similarity_matrix\n",
    "\n",
    "def sim_d(m1, m2): \n",
    "   \n",
    "   norm1 = F.normalize(m1, p=2, dim=1)\n",
    "   norm2 = F.normalize(m2, p=2, dim=1)\n",
    "       \n",
    "    # Initialize the similarity matrix with zeros\n",
    "   similarity_matrix = torch.zeros(m.size(0), m1.size(2), m2.size(2))\n",
    "\n",
    "   # Calculate the similarity (dot product) between each pair of vectors\n",
    "   for i in range(m1.shape[0]): \n",
    "      for j in range(m1.shape[2]): \n",
    "            for k in range(m2.shape[2]): \n",
    "               similarity_matrix[i, j, k] = torch.dot(norm1[i, :, j],  norm2[i, :, k])\n",
    "\n",
    "   return similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape\n",
      "torch.Size([32, 40, 5])\n",
      "torch.Size([32, 40, 5])\n",
      "\n",
      "sample\n",
      "tensor([[0.7096, 0.8937, 0.7985],\n",
      "        [0.8496, 0.7131, 0.7314],\n",
      "        [0.7478, 0.7187, 0.7948]])\n",
      "tensor([[0.7096, 0.8937, 0.7985],\n",
      "        [0.8496, 0.7131, 0.7314],\n",
      "        [0.7478, 0.7187, 0.7948]])\n",
      "\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "m1 = torch.rand(32, 12, 40)\n",
    "m2 = torch.rand(32, 12, 5)\n",
    "\n",
    "sim3 = sim_c(m1, m2)\n",
    "sim4 = sim_d(m1, m2)\n",
    "print(\"shape\")\n",
    "print(sim3.shape)\n",
    "print(sim4.shape)\n",
    "print()\n",
    "\n",
    "print(\"sample\")\n",
    "print(sim3[0, 0:3, :3])\n",
    "print(sim4[0, 0:3, :3])\n",
    "print()\n",
    "\n",
    "print(torch.allclose(sim3, sim4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Prime comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity check for topk for distance prime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prime(matrix, dist_matrix, num_nearest_neighbors): \n",
    "   '''Returns the convolution matrix of the NNT object using for-loops and vectorization'''\n",
    "   ### Note: For-Loop Implementation and Vectorization Implementation are the same\n",
    "   \n",
    "   ##For-Loop Implementation\n",
    "   \n",
    "   stack_list = [] \n",
    "   \n",
    "   for i in range(matrix.shape[0]): \n",
    "      \n",
    "       concat_list = [] \n",
    "       for j in range(matrix.shape[2]): \n",
    "           # Get the indices of the nearest neighbors\n",
    "           indices = torch.topk(dist_matrix[i, j, :], num_nearest_neighbors, largest=False).indices\n",
    "            \n",
    "           # Get the nearest neighbors\n",
    "           nearest_neighbors = matrix[i, :, indices]\n",
    "            \n",
    "           # Concatenate the nearest neighbors\n",
    "           concat_list.append(nearest_neighbors)\n",
    "      \n",
    "       # Concatenate the tensor list to create the convolution matrix \n",
    "       concat = torch.cat(concat_list, dim=1)\n",
    "       stack_list.append(concat)\n",
    "   prime = torch.stack(stack_list, dim= 0)\n",
    "   \n",
    "   \n",
    "   \n",
    "   return prime\n",
    "\n",
    "def prime_vmap_2d(matrix, magnitude_matrix, num_nearest_neighbors, largest=False): \n",
    "   # Vectorization / Vmap Implementation for Nearest Neighbor Tensor 2D\n",
    "   batched_process = torch.vmap(process_batch, in_dims=(0, 0, None), out_dims=0)\n",
    "   prime = batched_process(matrix, magnitude_matrix, num_nearest_neighbors, flatten=True, largest=largest)\n",
    "   return prime \n",
    "\n",
    "def process_batch(matrix, magnitude_matrix, num_nearest_neighbors, flatten=True, largest=False):\n",
    "      '''Process the batch of matrices''' \n",
    "      ind = torch.topk(magnitude_matrix, num_nearest_neighbors, largest=largest).indices\n",
    "      neigh = matrix[:, ind]\n",
    "      if flatten: \n",
    "         reshape = torch.flatten(neigh, start_dim=1)\n",
    "         return reshape\n",
    "      else: \n",
    "         return neigh\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = torch.rand(32, 12, 40)\n",
    "dist = calculate_distance_matrix(m)\n",
    "\n",
    "p1 = prime(m, dist, 5)\n",
    "p2 = prime_vmap_2d(m, dist, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4591, 0.4045, 0.3830])\n",
      "tensor([0.4591, 0.4045, 0.3830])\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(p1[0, 0, :3])\n",
    "print(p2[0, 0, :3])\n",
    "\n",
    "print(torch.allclose(p1, p2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity check for similarity prime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_prime(matrix, sim_mat, num_nearest_neighbors): \n",
    "   '''Returns the convolution matrix of the NNT object using for-loops and vectorization'''\n",
    "   ### Note: For-Loop Implementation and Vectorization Implementation are the same\n",
    "   \n",
    "   ##For-Loop Implementation\n",
    "   \n",
    "   stack_list = [] \n",
    "   \n",
    "   for i in range(matrix.shape[0]): \n",
    "      \n",
    "       concat_list = [] \n",
    "       for j in range(matrix.shape[2]): \n",
    "           # Get the indices of the nearest neighbors\n",
    "           indices = torch.topk(sim_mat[i, j, :], num_nearest_neighbors, largest=True).indices\n",
    "            \n",
    "           # Get the nearest neighbors\n",
    "           nearest_neighbors = matrix[i, :, indices]\n",
    "            \n",
    "           # Concatenate the nearest neighbors\n",
    "           concat_list.append(nearest_neighbors)\n",
    "      \n",
    "       # Concatenate the tensor list to create the convolution matrix \n",
    "       concat = torch.cat(concat_list, dim=1)\n",
    "       stack_list.append(concat)\n",
    "   prime = torch.stack(stack_list, dim= 0)\n",
    "   \n",
    "   \n",
    "   return prime\n",
    "\n",
    "def sim_prime_vmap_2d(matrix, magnitude_matrix, num_nearest_neighbors, largest=True): \n",
    "   # Vectorization / Vmap Implementation for Nearest Neighbor Tensor 2D\n",
    "   batched_process = torch.vmap(process_batch, in_dims=(0, 0, None), out_dims=0)\n",
    "   prime = batched_process(matrix, magnitude_matrix, num_nearest_neighbors, flatten=True, largest=largest)\n",
    "   return prime \n",
    "\n",
    "def sim_process_batch(matrix, magnitude_matrix, num_nearest_neighbors, flatten=True, largest=False):\n",
    "      '''Process the batch of matrices''' \n",
    "      ind = torch.topk(magnitude_matrix, num_nearest_neighbors, largest=largest).indices\n",
    "      neigh = matrix[:, ind]\n",
    "      if flatten: \n",
    "         reshape = torch.flatten(neigh, start_dim=1)\n",
    "         return reshape\n",
    "      else: \n",
    "         return neigh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = torch.rand(32, 12, 40)\n",
    "sim = sim_a(m)\n",
    "\n",
    "p1 = sim_prime(m, sim, 5)\n",
    "p2 = sim_prime_vmap_2d(m, sim, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0216, 0.4228, 0.2916],\n",
      "        [0.4888, 0.0307, 0.2975],\n",
      "        [0.9265, 0.3255, 0.5084]])\n",
      "tensor([[0.0216, 0.4228, 0.2916],\n",
      "        [0.4888, 0.0307, 0.2975],\n",
      "        [0.9265, 0.3255, 0.5084]])\n",
      "False\n",
      "torch.Size([32, 12, 120])\n"
     ]
    }
   ],
   "source": [
    "print(p1[0, 0:3, :3])\n",
    "print(p2[0, 0:3, :3])\n",
    "\n",
    "print(torch.allclose(p1, p2))\n",
    "\n",
    "print(p1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance prime for N sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "tensor([0.0216, 0.4228, 0.2916, 0.7075, 0.8836, 0.2916, 0.0033, 0.2916, 0.9318,\n",
      "        0.8836, 0.9318, 0.9885, 0.2550, 0.9318, 0.4228, 0.8846, 0.8836, 0.9885,\n",
      "        0.7070, 0.9318])\n",
      "tensor([0.0216, 0.4228, 0.2916, 0.7075, 0.8836, 0.2916, 0.0033, 0.2916, 0.9318,\n",
      "        0.8836, 0.9318, 0.9885, 0.2550, 0.9318, 0.4228, 0.8846, 0.8836, 0.9885,\n",
      "        0.7070, 0.9318])\n"
     ]
    }
   ],
   "source": [
    "# Og shape = [32, 12, 40] \n",
    "# prime1 shape = [32, 40, 5]\n",
    "# prime shape = [32, 12, 200]\n",
    "\n",
    "indices_list1 = [] \n",
    "indices_list2 = [] \n",
    "\n",
    "def prime_brute_N(matrix, magnitude_matrix, num_nearest_neighbors, rand_idx, largest = False):         \n",
    "   stack_list = [] \n",
    "\n",
    "   for i in range(matrix.shape[0]): \n",
    "      \n",
    "      concat_list = []\n",
    "      \n",
    "      for j in range(matrix.shape[2]): \n",
    "            \n",
    "         if j in rand_idx: \n",
    "            indices = torch.topk(magnitude_matrix[i, j, :], num_nearest_neighbors, largest=largest).indices\n",
    "            indices_list = [rand_idx[i] for i in indices]\n",
    "            nearest_neighbors = matrix[i, :, indices_list]\n",
    "         else: \n",
    "            indices = torch.topk(magnitude_matrix[i, j, :], num_nearest_neighbors - 1, largest=largest).indices\n",
    "            indices_list = [j] + [rand_idx[i] for i in indices]\n",
    "            nearest_neighbors = matrix[i, :, indices_list]\n",
    "            \n",
    "         indices_list1.append(indices_list)\n",
    "            \n",
    "         concat_list.append(nearest_neighbors)\n",
    "      \n",
    "      stacked_neighbors = torch.cat(concat_list, dim=1)\n",
    "      stack_list.append(stacked_neighbors)\n",
    "   \n",
    "\n",
    "   prime = torch.stack(stack_list, dim= 0)\n",
    "   return prime\n",
    "\n",
    "def prime_brute_N_v2(matrix, magnitude_matrix, num_nearest_neighbors, rand_idx,largest=False): \n",
    "   stack_list = [] \n",
    "   \n",
    "   for i in range(matrix.shape[0]): \n",
    "      concat_list = [] \n",
    "      \n",
    "      for j in range(matrix.shape[2]): \n",
    "         indices = torch.topk(magnitude_matrix[i, j, :], num_nearest_neighbors - 1, largest=largest).indices\n",
    "         indices_list = [j] + [rand_idx[i] for i in indices] \n",
    "         nearest_neighbors = matrix[i, :, indices_list]\n",
    "         concat_list.append(nearest_neighbors)\n",
    "   \n",
    "         indices_list2.append(indices_list)\n",
    "         \n",
    "      stacked_neighbors = torch.cat(concat_list, dim=1)\n",
    "      stack_list.append(stacked_neighbors)\n",
    "   \n",
    "   prime = torch.stack(stack_list, dim=0)\n",
    "   return prime\n",
    "\n",
    "rand_idx = [3, 8, 14, 28, 39]\n",
    "nnn = 3\n",
    "\n",
    "m1 = torch.rand(32, 12, 40)\n",
    "m2 = m1[:, :, rand_idx]\n",
    "dist = calculate_distance_matrix_N(m1, m2)\n",
    "\n",
    "p1 = prime_brute_N(m1, dist, nnn, rand_idx, False)\n",
    "\n",
    "dist[:, rand_idx, np.arange(len(rand_idx))] = np.inf\n",
    "\n",
    "p2 = prime_brute_N_v2(m1, dist, nnn, rand_idx, False) \n",
    "\n",
    "print(torch.equal(p1, p2))\n",
    "\n",
    "print(p1[0, 0, :20])\n",
    "print(p2[0, 0, :20])\n",
    "\n",
    "\n",
    "# differing_indices = [i for i, (a, b) in enumerate(zip(indices_list1, indices_list2)) if a != b]\n",
    "\n",
    "# # Print the indices\n",
    "# print(differing_indices)\n",
    "# print(indices_list1[3])\n",
    "# print(indices_list2[3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14, 39, 54, 68, 119, 159, 203, 248, 283, 288, 323, 414, 479, 488, 508, 519, 534, 748, 799, 808, 814, 854, 879, 999, 1148, 1268]\n",
      "[28, 3, 14]\n",
      "[39, 28, 3]\n",
      "[39, 8, 3]\n",
      "[14, 39, 8]\n",
      "[[0, 14, 8], [1, 3, 8], [2, 8, 28]]\n"
     ]
    }
   ],
   "source": [
    "differing_indices = [i for i, (a, b) in enumerate(zip(indices_list1, indices_list2)) if a != b]\n",
    "\n",
    "# Print the indices\n",
    "print(differing_indices)\n",
    "print(indices_list1[39])\n",
    "print(indices_list2[39])\n",
    "\n",
    "print(indices_list1[54])\n",
    "print(indices_list2[54])\n",
    "\n",
    "print(indices_list2[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def prime_vmap_2d_N(matrix, magnitude_matrix, num_nearest_neighbors, rand_idx, largest=False):\n",
    "    index = torch.arange(0, matrix.shape[2])\n",
    "    \n",
    "    batched_process = torch.vmap(process_batch_N, in_dims=(0, 0, None, None), out_dims=0)\n",
    "    prime = batched_process(matrix, magnitude_matrix, num_nearest_neighbors, rand_idx, flatten=True, largest=largest)\n",
    "    return prime\n",
    "\n",
    "def process_batch_N(matrix, magnitude_matrix, num_nearest_neighbors, rand_idx, flatten=True, largest=False):\n",
    "    topk_ind = torch.topk(magnitude_matrix, num_nearest_neighbors - 1, largest=largest).indices\n",
    "    mapped_tensor = rand_idx[topk_ind]\n",
    "    index_tensor = torch.arange(0, matrix.shape[1]).unsqueeze(1) # shape [40, 1]\n",
    "    final_tensor = torch.cat([index_tensor, mapped_tensor], dim=1)\n",
    "         \n",
    "    neigh = matrix[:, final_tensor]\n",
    "    if flatten:\n",
    "        reshape = torch.flatten(neigh, start_dim=1)\n",
    "        return reshape\n",
    "    else:\n",
    "        return neigh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 12, 40])\n",
      "torch.Size([32, 40, 5])\n",
      "torch.Size([32, 12, 120])\n"
     ]
    }
   ],
   "source": [
    "rand_idx = torch.tensor([3, 8, 14, 28, 39])\n",
    "rand_idx = [3, 8, 14, 28, 39]\n",
    "\n",
    "\n",
    "print(m1.shape) \n",
    "print(dist.shape)\n",
    "p3 = prime_vmap_2d_N(m1, dist, nnn, torch.tensor(rand_idx), False)\n",
    "print(p3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(torch.allclose(p2, p3))\n",
    "print(torch.allclose(p1, p3))\n",
    "print(torch.allclose(p1, p2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4, 4],\n",
      "        [4, 4],\n",
      "        [4, 0]])\n",
      "tensor([[39, 39],\n",
      "        [39, 39],\n",
      "        [39,  3]])\n",
      "tensor([[ 0, 39, 39],\n",
      "        [ 1, 39, 39],\n",
      "        [ 2, 39,  3]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Example tensor of size [40, 2]\n",
    "original_tensor = torch.randint(0, 5, (40, 2))\n",
    "\n",
    "# Mapping list: the index corresponds to the number in the original tensor\n",
    "mapping_list = [3, 8, 14, 28, 39]\n",
    "\n",
    "# Convert the mapping list to a tensor\n",
    "mapping_tensor = torch.tensor(mapping_list)\n",
    "\n",
    "# Use the original tensor to index the mapping tensor\n",
    "mapped_tensor = mapping_tensor[original_tensor]\n",
    "\n",
    "# Create a tensor that adds numbers from 0 to 39\n",
    "index_tensor = torch.arange(40).unsqueeze(1)  # shape [40, 1]\n",
    "\n",
    "# Concatenate the index tensor with the mapped tensor\n",
    "final_tensor = torch.cat((index_tensor, mapped_tensor), dim=1)\n",
    "\n",
    "print(original_tensor[:3, :])\n",
    "print(mapped_tensor[:3, :])\n",
    "print(final_tensor[:3, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0155, 1.5307, 1.4502, 1.3405, 1.4851],\n",
      "        [1.0813, 1.6507, 1.6002, 1.3544, 1.1218],\n",
      "        [1.3391, 1.4990, 1.1786, 2.0250, 1.5569],\n",
      "        [   inf, 1.5706, 1.3242, 1.5635, 1.4475],\n",
      "        [1.5554, 1.6324, 1.6491, 1.7839, 1.2585],\n",
      "        [0.9596, 1.5664, 1.1294, 1.6351, 1.5507],\n",
      "        [1.0040, 1.5696, 1.3818, 1.7687, 1.4577],\n",
      "        [1.2212, 1.4889, 1.6367, 1.2570, 1.0519],\n",
      "        [1.5706,    inf, 0.8682, 1.3536, 1.3824],\n",
      "        [1.4758, 1.0443, 1.2268, 1.7363, 1.4955]])\n",
      "torch.Size([32, 40, 5])\n",
      "torch.Size([32, 40, 2])\n"
     ]
    }
   ],
   "source": [
    "rand_idx = [3, 8, 14, 28, 39]\n",
    "nnn = 3\n",
    "\n",
    "m1 = torch.rand(32, 12, 40)\n",
    "m2 = m1[:, :, rand_idx]\n",
    "dist = calculate_distance_matrix_N(m1, m2)\n",
    "\n",
    "dist[:, rand_idx, np.arange(len(rand_idx))] = np.inf\n",
    "print(dist[0, 0:10, :])\n",
    "print(dist.shape)\n",
    "\n",
    "ind = torch.topk(dist, nnn-1, largest=False).indices\n",
    "print(ind.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MK",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
