{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# July 12, 13, 16, 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 120])\n",
      "Time taken to run the function: 0.0024809837341308594 seconds\n",
      "torch.Size([1000, 5])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "\n",
    "dist_matrix = torch.rand(1000, 120)\n",
    "print(dist_matrix.shape)\n",
    "num_nearest_neighbors = 5\n",
    "\n",
    "start = time.time() \n",
    "ind = torch.topk(dist_matrix, num_nearest_neighbors, largest=False).indices\n",
    "end = time.time() \n",
    "\n",
    "print(f\"Time taken to run the function: {end - start} seconds\")\n",
    "print(ind.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ex shape:  torch.Size([32, 12, 40])\n",
      "M shape:  torch.Size([12, 40])\n",
      "[35  5 11 39 18]\n",
      "M prime shape:  torch.Size([12, 5])\n",
      "Sim shape:  torch.Size([40, 5])\n",
      "Neig shape:  torch.Size([12, 40, 4])\n",
      "M.unsqueeze(2) shape:  torch.Size([12, 40, 1])\n",
      "torch.Size([12, 40, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s7/md5b66vn4l39df_j063nqlp00000gn/T/ipykernel_95647/2407026106.py:33: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:278.)\n",
      "  neig1 = M[:, b]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "B, C, N = 32, 12, 40\n",
    "n_samples = 5\n",
    "k_neig = 5\n",
    "\n",
    "ex = torch.rand(B, C, N)\n",
    "print(\"Ex shape: \", ex.shape)\n",
    "\n",
    "M = ex[0]/torch.norm(ex[0], dim=0)  # Pick first item in patch and normalize the rows\n",
    "print(\"M shape: \", M.shape)\n",
    "\n",
    "rand_idx = np.random.choice(M.shape[1], n_samples, replace=False) \n",
    "print(rand_idx)\n",
    "\n",
    "M_prime = M[:, rand_idx]\n",
    "print(\"M prime shape: \", M_prime.shape)\n",
    "\n",
    "sim = M.T@M_prime\n",
    "print(\"Sim shape: \", sim.shape)\n",
    "\n",
    "\n",
    "# Make similarities between samples equal to -inf, so they are not considered when using topk\n",
    "sim[rand_idx, np.arange(n_samples)]  =  -np.inf  \n",
    "# print(sim[:rand_idx[0]])\n",
    "# print(sim[:rand_idx[0]].shape)\n",
    "\n",
    "\n",
    "# Only get k-1 neigbors (we'll add the selves later as the first nearest neigbor) \n",
    "_, indxs = torch.topk(sim, k_neig - 1, largest=True) \n",
    "b = [rand_idx[x] for x in indxs]\n",
    "neig1 = M[:, b]\n",
    "print(\"Neig shape: \", neig1.shape)\n",
    "print(\"M.unsqueeze(2) shape: \", M.unsqueeze(2).shape)\n",
    "\n",
    "# Add the selves as the first nearest neigbor\n",
    "neig2 = torch.concat([M.unsqueeze(2), neig1], dim=2)\n",
    "print(neig2.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[35  5 11 39 18]\n",
      "35\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.6918,  0.6979,  0.8874,  0.7272,  0.7101],\n",
       "        [ 1.0000,  0.7906,  0.7905,  0.7762,  0.8334,  0.7995],\n",
       "        [ 2.0000,  0.6744,  0.6935,  0.8854,  0.5431,  0.7086],\n",
       "        [ 3.0000,  0.8333,  0.7337,  0.7377,  0.6393,  0.8565],\n",
       "        [ 4.0000,  0.7755,  0.7808,  0.7749,  0.8573,  0.8554],\n",
       "        [ 5.0000,  0.7924,  1.0000,  0.7089,  0.6049,  0.7891],\n",
       "        [ 6.0000,  0.8282,  0.7659,  0.6740,  0.5203,  0.6992],\n",
       "        [ 7.0000,  0.8019,  0.7339,  0.6530,  0.7254,  0.7017],\n",
       "        [ 8.0000,  0.6802,  0.7508,  0.7341,  0.8118,  0.7243],\n",
       "        [ 9.0000,  0.8102,  0.9141,  0.8046,  0.5730,  0.8086],\n",
       "        [10.0000,  0.8104,  0.8393,  0.8194,  0.8174,  0.8018],\n",
       "        [11.0000,  0.8184,  0.7089,  1.0000,  0.6787,  0.7481],\n",
       "        [12.0000,  0.7721,  0.7163,  0.6784,  0.6350,  0.8817],\n",
       "        [13.0000,  0.7438,  0.6295,  0.6880,  0.6045,  0.6814],\n",
       "        [14.0000,  0.7740,  0.6331,  0.7568,  0.6083,  0.7601],\n",
       "        [15.0000,  0.7548,  0.8500,  0.7685,  0.6601,  0.8014],\n",
       "        [16.0000,  0.7438,  0.7087,  0.8422,  0.7318,  0.9218],\n",
       "        [17.0000,  0.7075,  0.8623,  0.6239,  0.5489,  0.7638],\n",
       "        [18.0000,  0.8078,  0.7891,  0.7481,  0.6745,  1.0000],\n",
       "        [19.0000,  0.9276,  0.8331,  0.8429,  0.7440,  0.8358],\n",
       "        [20.0000,  0.6292,  0.8168,  0.6243,  0.7248,  0.7393],\n",
       "        [21.0000,  0.7469,  0.8467,  0.6089,  0.6940,  0.8166],\n",
       "        [22.0000,  0.8405,  0.6660,  0.9082,  0.7476,  0.8192],\n",
       "        [23.0000,  0.7778,  0.8696,  0.6967,  0.6968,  0.9000],\n",
       "        [24.0000,  0.8946,  0.8374,  0.9004,  0.6186,  0.8053],\n",
       "        [25.0000,  0.8101,  0.6556,  0.8982,  0.5305,  0.7024],\n",
       "        [26.0000,  0.6446,  0.6797,  0.5493,  0.4234,  0.6084],\n",
       "        [27.0000,  0.8310,  0.7897,  0.8646,  0.7330,  0.7935],\n",
       "        [28.0000,  0.7102,  0.8177,  0.6910,  0.6980,  0.7611],\n",
       "        [29.0000,  0.8017,  0.7301,  0.8561,  0.6405,  0.7280],\n",
       "        [30.0000,  0.8245,  0.6440,  0.6775,  0.6188,  0.7465],\n",
       "        [31.0000,  0.8168,  0.8108,  0.6646,  0.5699,  0.8214],\n",
       "        [32.0000,  0.8204,  0.8172,  0.7894,  0.8019,  0.8302],\n",
       "        [33.0000,  0.6380,  0.5476,  0.6553,  0.7244,  0.7666],\n",
       "        [34.0000,  0.7192,  0.6924,  0.8190,  0.9326,  0.7669],\n",
       "        [35.0000,  1.0000,  0.7924,  0.8184,  0.6258,  0.8078],\n",
       "        [36.0000,  0.7331,  0.6805,  0.7065,  0.7432,  0.5418],\n",
       "        [37.0000,  0.8173,  0.7871,  0.7675,  0.5561,  0.8100],\n",
       "        [38.0000,  0.9214,  0.7198,  0.7797,  0.6703,  0.6747],\n",
       "        [39.0000,  0.6258,  0.6049,  0.6787,  1.0000,  0.6745]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(rand_idx)\n",
    "c = rand_idx[0]\n",
    "print(c)\n",
    "torch.concat([torch.arange(40).unsqueeze(1), sim], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1453, 0.4398, 0.3740, 0.3932, 0.1829, 0.4559, 0.2376, 0.0693, 0.0573,\n",
       "        0.2749, 0.3261, 0.0567])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M[:, c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1453, 0.4398, 0.3740, 0.3932, 0.1829, 0.4559, 0.2376, 0.0693, 0.0573,\n",
       "         0.2749, 0.3261, 0.0567],\n",
       "        [0.3231, 0.2965, 0.0038, 0.3717, 0.1529, 0.4523, 0.3680, 0.2733, 0.1466,\n",
       "         0.0133, 0.3904, 0.2395],\n",
       "        [0.3486, 0.2537, 0.2246, 0.4832, 0.1932, 0.0271, 0.0957, 0.1651, 0.1602,\n",
       "         0.4067, 0.4903, 0.1560],\n",
       "        [0.2857, 0.1100, 0.4676, 0.1616, 0.4580, 0.1462, 0.4051, 0.1387, 0.0167,\n",
       "         0.2577, 0.3864, 0.1761]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neig1[:, c, :].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1453, 0.4398, 0.3740, 0.3932, 0.1829, 0.4559, 0.2376, 0.0693, 0.0573,\n",
       "         0.2749, 0.3261, 0.0567],\n",
       "        [0.1453, 0.4398, 0.3740, 0.3932, 0.1829, 0.4559, 0.2376, 0.0693, 0.0573,\n",
       "         0.2749, 0.3261, 0.0567],\n",
       "        [0.3231, 0.2965, 0.0038, 0.3717, 0.1529, 0.4523, 0.3680, 0.2733, 0.1466,\n",
       "         0.0133, 0.3904, 0.2395],\n",
       "        [0.3486, 0.2537, 0.2246, 0.4832, 0.1932, 0.0271, 0.0957, 0.1651, 0.1602,\n",
       "         0.4067, 0.4903, 0.1560],\n",
       "        [0.2857, 0.1100, 0.4676, 0.1616, 0.4580, 0.1462, 0.4051, 0.1387, 0.0167,\n",
       "         0.2577, 0.3864, 0.1761]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neig2[:, c, :].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Distance/Similarity Matrix check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance matrix sanity check for all samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distance_matrix(matrix): \n",
    "   '''Calculating the distance matrix of the input matrix'''\n",
    "   norm_squared = torch.sum(matrix ** 2, dim=1, keepdim=True)\n",
    "   dot_product = torch.bmm(matrix.transpose(2, 1), matrix)\n",
    "   dist_matrix = norm_squared + norm_squared.transpose(2, 1) - 2 * dot_product\n",
    "   return torch.sqrt(dist_matrix) # May need to remove torch.sqrt - do not need that computation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance Matrix sanity check for N Sample "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distance_matrix_N(m1, m2):\n",
    "   '''Calculate the distance matrix between two input matrices'''\n",
    "   # to make it simple -> normalize the rows, normalize across c (channels), \n",
    "   norm_squared_1 = torch.sum(m1 ** 2, dim=1, keepdim=True)\n",
    "   norm_squared_2 = torch.sum(m2 ** 2, dim=1, keepdim=True).transpose(2, 1)\n",
    "   dot_product = torch.bmm(m1.transpose(2, 1), m2)\n",
    "\n",
    "   norm_squared_1 = norm_squared_1.permute(0, 2, 1)  \n",
    "   norm_squared_2 = norm_squared_2.permute(0, 2, 1)  \n",
    "\n",
    "   dist_matrix = norm_squared_1 + norm_squared_2 - 2 * dot_product\n",
    "   return torch.sqrt(dist_matrix)\n",
    "\n",
    "def calculate_distance_matrix_N_v2(matrix, matrix_sample):\n",
    "   '''Calculate distance matrix between two input matrices''' \n",
    "   norm_squared = torch.sum(matrix ** 2, dim=1, keepdim=True).permute(0, 2, 1)\n",
    "   norm_squared_sample = torch.sum(matrix_sample ** 2, dim=1, keepdim=True).transpose(2, 1).permute(0, 2, 1)\n",
    "   dot_product = torch.bmm(matrix.transpose(2, 1), matrix_sample)\n",
    "   dist_matrix = norm_squared + norm_squared_sample - 2 * dot_product\n",
    "   return torch.sqrt(dist_matrix)\n",
    "   \n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_matrix(m1, m2): \n",
    "   # Calculate the distance matrix using for-loops \n",
    "   dist_matrix = torch.zeros(m1.shape[0], m1.shape[2], m2.shape[2])\n",
    "   \n",
    "   for i in range(m1.shape[0]): \n",
    "      for j in range(m1.shape[2]): \n",
    "            for k in range(m2.shape[2]): \n",
    "               dist_matrix[i, j, k] = torch.norm(m1[i, :, j] -  m2[i, :, k])\n",
    "   return dist_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 40, 5])\n",
      "torch.Size([32, 40, 5])\n"
     ]
    }
   ],
   "source": [
    "m1 = torch.rand(32, 12, 40)\n",
    "m2 = torch.rand(32, 12, 5)\n",
    "\n",
    "a = calculate_distance_matrix_N(m1, m2)\n",
    "b = dist_matrix(m1, m2)\n",
    "c = calculate_distance_matrix_N_v2(m1, m2)\n",
    "print(a.shape)\n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.allclose(a, b))\n",
    "print(torch.allclose(a, c))\n",
    "print(torch.allclose(b, c))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity Matrix sanity check for N Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_a(matrix): \n",
    "   '''Calculate the similarity matrix of the input matrix'''\n",
    "   normalized_matrix = F.normalize(matrix, p=2, dim=1) # p=2 (L2 Norm - Euclidean Distance), dim=1 (across the channels)\n",
    "   dot_product = torch.bmm(normalized_matrix.transpose(2, 1), normalized_matrix)\n",
    "   similarity_matrix = dot_product \n",
    "   return similarity_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_b(m):\n",
    "    # Normalize the input matrix\n",
    "    normalized_matrix = F.normalize(m, p=2, dim=1)\n",
    "    \n",
    "    # Initialize the similarity matrix with zeros\n",
    "    similarity_matrix = torch.zeros(m.size(0), m.size(2), m.size(2))\n",
    "    \n",
    "    # Calculate the similarity (dot product) between each pair of vectors\n",
    "    for i in range(m.shape[0]): \n",
    "      for j in range(m.shape[2]): \n",
    "            for k in range(m.shape[2]): \n",
    "               similarity_matrix[i, j, k] = torch.dot(normalized_matrix[i, :, j],  normalized_matrix[i, :, k])\n",
    "    \n",
    "    return similarity_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 40, 40])\n",
      "torch.Size([32, 40, 40])\n",
      "tensor([1.0000, 0.6578, 0.7064])\n",
      "tensor([1.0000, 0.6578, 0.7064])\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "m = torch.rand(32, 12, 40)\n",
    "sim1 = sim_a(m)\n",
    "sim2 = sim_b(m)\n",
    "\n",
    "print(sim1.shape)\n",
    "print(sim2.shape)\n",
    "\n",
    "\n",
    "print(sim1[0, 0, :3])\n",
    "print(sim2[0, 0, :3]) \n",
    "\n",
    "print(torch.allclose(sim1, sim2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## For N Samples\n",
    "\n",
    "def sim_c(m1, m2): \n",
    "   normalized_matrix_1 = F.normalize(m1, p=2, dim=1) # p=2 (L2 Norm - Euclidean Distance), dim=1 (across the channels)\n",
    "   normalized_matrix_2 = F.normalize(m2, p=2, dim=1)\n",
    "   \n",
    "   dot_product = torch.bmm(normalized_matrix_1.transpose(2, 1), normalized_matrix_2)\n",
    "            \n",
    "   similarity_matrix = dot_product \n",
    "   return similarity_matrix\n",
    "\n",
    "def calculate_similarity_matrix_N(matrix, matrix_sample): \n",
    "   normalized_matrix = F.normalize(matrix, p=2, dim=1) # p=2 (L2 Norm - Euclidean Distance), dim=1 (across the channels)\n",
    "   normalized_matrix_sample = F.normalize(matrix_sample, p=2, dim=1)\n",
    "   similarity_matrix = dot_product = torch.bmm(normalized_matrix.transpose(2, 1), normalized_matrix_sample)\n",
    "   return similarity_matrix\n",
    "\n",
    "def sim_d(m1, m2): \n",
    "   \n",
    "   norm1 = F.normalize(m1, p=2, dim=1)\n",
    "   norm2 = F.normalize(m2, p=2, dim=1)\n",
    "       \n",
    "    # Initialize the similarity matrix with zeros\n",
    "   similarity_matrix = torch.zeros(m.size(0), m1.size(2), m2.size(2))\n",
    "\n",
    "   # Calculate the similarity (dot product) between each pair of vectors\n",
    "   for i in range(m1.shape[0]): \n",
    "      for j in range(m1.shape[2]): \n",
    "            for k in range(m2.shape[2]): \n",
    "               similarity_matrix[i, j, k] = torch.dot(norm1[i, :, j],  norm2[i, :, k])\n",
    "\n",
    "   return similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "m1 = torch.rand(32, 12, 40)\n",
    "m2 = torch.rand(32, 12, 5)\n",
    "\n",
    "sim3 = sim_c(m1, m2)\n",
    "sim4 = sim_d(m1, m2)\n",
    "sim5 = calculate_similarity_matrix_N(m1, m2)\n",
    "\n",
    "print()\n",
    "\n",
    "print(torch.allclose(sim3, sim4))\n",
    "print(torch.allclose(sim3, sim5))\n",
    "print(torch.allclose(sim4, sim5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Prime comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity check for topk for distance prime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prime(matrix, dist_matrix, num_nearest_neighbors): \n",
    "   '''Returns the convolution matrix of the NNT object using for-loops and vectorization'''\n",
    "   ### Note: For-Loop Implementation and Vectorization Implementation are the same\n",
    "   \n",
    "   ##For-Loop Implementation\n",
    "   \n",
    "   stack_list = [] \n",
    "   \n",
    "   for i in range(matrix.shape[0]): \n",
    "      \n",
    "       concat_list = [] \n",
    "       for j in range(matrix.shape[2]): \n",
    "           # Get the indices of the nearest neighbors\n",
    "           indices = torch.topk(dist_matrix[i, j, :], num_nearest_neighbors, largest=False).indices\n",
    "            \n",
    "           # Get the nearest neighbors\n",
    "           nearest_neighbors = matrix[i, :, indices]\n",
    "            \n",
    "           # Concatenate the nearest neighbors\n",
    "           concat_list.append(nearest_neighbors)\n",
    "      \n",
    "       # Concatenate the tensor list to create the convolution matrix \n",
    "       concat = torch.cat(concat_list, dim=1)\n",
    "       stack_list.append(concat)\n",
    "   prime = torch.stack(stack_list, dim= 0)\n",
    "   \n",
    "   \n",
    "   \n",
    "   return prime\n",
    "\n",
    "def prime_vmap_2d(matrix, magnitude_matrix, num_nearest_neighbors, largest=False): \n",
    "   # Vectorization / Vmap Implementation for Nearest Neighbor Tensor 2D\n",
    "   batched_process = torch.vmap(process_batch, in_dims=(0, 0, None), out_dims=0)\n",
    "   prime = batched_process(matrix, magnitude_matrix, num_nearest_neighbors, flatten=True, largest=largest)\n",
    "   return prime \n",
    "\n",
    "def process_batch(matrix, magnitude_matrix, num_nearest_neighbors, flatten=True, largest=False):\n",
    "      '''Process the batch of matrices''' \n",
    "      ind = torch.topk(magnitude_matrix, num_nearest_neighbors, largest=largest).indices\n",
    "      neigh = matrix[:, ind]\n",
    "      if flatten: \n",
    "         reshape = torch.flatten(neigh, start_dim=1)\n",
    "         return reshape\n",
    "      else: \n",
    "         return neigh\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = torch.rand(32, 12, 40)\n",
    "dist = calculate_distance_matrix(m)\n",
    "\n",
    "p1 = prime(m, dist, 5)\n",
    "p2 = prime_vmap_2d(m, dist, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3093, 0.3509, 0.1961])\n",
      "tensor([0.3093, 0.3509, 0.1961])\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(p1[0, 0, :3])\n",
    "print(p2[0, 0, :3])\n",
    "\n",
    "print(torch.allclose(p1, p2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity check for similarity prime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_prime(matrix, sim_mat, num_nearest_neighbors): \n",
    "   '''Returns the convolution matrix of the NNT object using for-loops and vectorization'''\n",
    "   ### Note: For-Loop Implementation and Vectorization Implementation are the same\n",
    "   \n",
    "   ##For-Loop Implementation\n",
    "   \n",
    "   stack_list = [] \n",
    "   \n",
    "   for i in range(matrix.shape[0]): \n",
    "      \n",
    "       concat_list = [] \n",
    "       for j in range(matrix.shape[2]): \n",
    "           # Get the indices of the nearest neighbors\n",
    "           indices = torch.topk(sim_mat[i, j, :], num_nearest_neighbors, largest=True).indices\n",
    "            \n",
    "           # Get the nearest neighbors\n",
    "           nearest_neighbors = matrix[i, :, indices]\n",
    "            \n",
    "           # Concatenate the nearest neighbors\n",
    "           concat_list.append(nearest_neighbors)\n",
    "      \n",
    "       # Concatenate the tensor list to create the convolution matrix \n",
    "       concat = torch.cat(concat_list, dim=1)\n",
    "       stack_list.append(concat)\n",
    "   prime = torch.stack(stack_list, dim= 0)\n",
    "   \n",
    "   \n",
    "   return prime\n",
    "\n",
    "def sim_prime_vmap_2d(matrix, magnitude_matrix, num_nearest_neighbors, largest=True): \n",
    "   # Vectorization / Vmap Implementation for Nearest Neighbor Tensor 2D\n",
    "   batched_process = torch.vmap(process_batch, in_dims=(0, 0, None), out_dims=0)\n",
    "   prime = batched_process(matrix, magnitude_matrix, num_nearest_neighbors, flatten=True, largest=largest)\n",
    "   return prime \n",
    "\n",
    "def sim_process_batch(matrix, magnitude_matrix, num_nearest_neighbors, flatten=True, largest=False):\n",
    "      '''Process the batch of matrices''' \n",
    "      ind = torch.topk(magnitude_matrix, num_nearest_neighbors, largest=largest).indices\n",
    "      neigh = matrix[:, ind]\n",
    "      if flatten: \n",
    "         reshape = torch.flatten(neigh, start_dim=1)\n",
    "         return reshape\n",
    "      else: \n",
    "         return neigh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = torch.rand(32, 12, 40)\n",
    "sim = sim_a(m)\n",
    "\n",
    "p1 = sim_prime(m, sim, 5)\n",
    "p2 = sim_prime_vmap_2d(m, sim, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8638, 0.8472, 0.8591],\n",
      "        [0.4595, 0.5199, 0.7578],\n",
      "        [0.7437, 0.4739, 0.5776]])\n",
      "tensor([[0.8638, 0.8472, 0.8591],\n",
      "        [0.4595, 0.5199, 0.7578],\n",
      "        [0.7437, 0.4739, 0.5776]])\n",
      "True\n",
      "torch.Size([32, 12, 200])\n"
     ]
    }
   ],
   "source": [
    "print(p1[0, 0:3, :3])\n",
    "print(p2[0, 0:3, :3])\n",
    "\n",
    "print(torch.allclose(p1, p2))\n",
    "\n",
    "print(p1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance prime for N sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "tensor([0.6720, 0.3938, 0.1533, 0.2187, 0.1533, 0.4430, 0.9430, 0.3938, 0.1533,\n",
      "        0.0167, 0.0978, 0.4430, 0.6502, 0.4430, 0.0167, 0.5355, 0.3938, 0.4430,\n",
      "        0.3531, 0.4430])\n",
      "tensor([0.6720, 0.3938, 0.1533, 0.2187, 0.1533, 0.4430, 0.9430, 0.3938, 0.1533,\n",
      "        0.0167, 0.0978, 0.4430, 0.6502, 0.4430, 0.0167, 0.5355, 0.3938, 0.4430,\n",
      "        0.3531, 0.4430])\n",
      "[83, 119, 239, 279, 283, 319, 328, 359, 374, 388, 439, 508, 523, 639, 683, 788, 799, 814, 839, 854, 919, 934, 963, 968, 1014, 1039, 1079, 1083, 1088, 1108, 1119, 1248]\n",
      "[3, 39, 14]\n",
      "[3, 39, 14]\n"
     ]
    }
   ],
   "source": [
    "# Og shape = [32, 12, 40] \n",
    "# prime1 shape = [32, 40, 5]\n",
    "# prime shape = [32, 12, 200]\n",
    "\n",
    "indices_list1 = [] \n",
    "indices_list2 = [] \n",
    "\n",
    "def prime_brute_N(matrix, magnitude_matrix, num_nearest_neighbors, rand_idx, largest = False):         \n",
    "   stack_list = [] \n",
    "\n",
    "   for i in range(matrix.shape[0]): \n",
    "      \n",
    "      concat_list = []\n",
    "      \n",
    "      for j in range(matrix.shape[2]): \n",
    "            \n",
    "         if j in rand_idx: \n",
    "            indices = torch.topk(magnitude_matrix[i, j, :], num_nearest_neighbors, largest=largest).indices\n",
    "            indices_list = [rand_idx[i] for i in indices]\n",
    "            nearest_neighbors = matrix[i, :, indices_list]\n",
    "         else: \n",
    "            indices = torch.topk(magnitude_matrix[i, j, :], num_nearest_neighbors - 1, largest=largest).indices\n",
    "            indices_list = [j] + [rand_idx[i] for i in indices]\n",
    "            nearest_neighbors = matrix[i, :, indices_list]\n",
    "            \n",
    "         indices_list1.append(indices_list)\n",
    "            \n",
    "         concat_list.append(nearest_neighbors)\n",
    "      \n",
    "      stacked_neighbors = torch.cat(concat_list, dim=1)\n",
    "      stack_list.append(stacked_neighbors)\n",
    "   \n",
    "\n",
    "   prime = torch.stack(stack_list, dim= 0)\n",
    "   return prime\n",
    "\n",
    "def prime_brute_N_v2(matrix, magnitude_matrix, num_nearest_neighbors, rand_idx,largest=False): \n",
    "   stack_list = [] \n",
    "   \n",
    "   for i in range(matrix.shape[0]): \n",
    "      concat_list = [] \n",
    "      \n",
    "      for j in range(matrix.shape[2]): \n",
    "         indices = torch.topk(magnitude_matrix[i, j, :], num_nearest_neighbors - 1, largest=largest).indices\n",
    "         indices_list = [j] + [rand_idx[i] for i in indices] \n",
    "         nearest_neighbors = matrix[i, :, indices_list]\n",
    "         concat_list.append(nearest_neighbors)\n",
    "   \n",
    "         indices_list2.append(indices_list)\n",
    "         \n",
    "      stacked_neighbors = torch.cat(concat_list, dim=1)\n",
    "      stack_list.append(stacked_neighbors)\n",
    "   \n",
    "   prime = torch.stack(stack_list, dim=0)\n",
    "   return prime\n",
    "\n",
    "rand_idx = [3, 8, 14, 28, 39]\n",
    "nnn = 3\n",
    "\n",
    "m1 = torch.rand(32, 12, 40)\n",
    "m2 = m1[:, :, rand_idx]\n",
    "dist = calculate_distance_matrix_N(m1, m2)\n",
    "\n",
    "p1 = prime_brute_N(m1, dist, nnn, rand_idx, False)\n",
    "\n",
    "dist[:, rand_idx, np.arange(len(rand_idx))] = np.inf\n",
    "\n",
    "p2 = prime_brute_N_v2(m1, dist, nnn, rand_idx, False) \n",
    "\n",
    "print(torch.equal(p1, p2))\n",
    "\n",
    "print(p1[0, 0, :20])\n",
    "print(p2[0, 0, :20])\n",
    "\n",
    "\n",
    "differing_indices = [i for i, (a, b) in enumerate(zip(indices_list1, indices_list2)) if a != b]\n",
    "\n",
    "# Print the indices\n",
    "print(differing_indices)\n",
    "print(indices_list1[3])\n",
    "print(indices_list2[3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " ...\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# differing_indices = [i for i, (a, b) in enumerate(zip(indices_list1, indices_list2)) if a != b]\n",
    "\n",
    "# # Print the indices\n",
    "# print(indices_list1[8])\n",
    "# print(indices_list2[8])\n",
    "\n",
    "# print(indices_list1[9])\n",
    "\n",
    "print(np.array(indices_list2) - np.array(indices_list1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def prime_vmap_2d_N(matrix, magnitude_matrix, num_nearest_neighbors, rand_idx, largest=False):\n",
    "    \n",
    "    batched_process = torch.vmap(process_batch_N, in_dims=(0, 0, None, None), out_dims=0)\n",
    "    prime = batched_process(matrix, magnitude_matrix, num_nearest_neighbors, rand_idx, flatten=True, largest=largest)\n",
    "    return prime\n",
    "\n",
    "def process_batch_N(matrix, magnitude_matrix, num_nearest_neighbors, rand_idx, flatten=True, largest=False):\n",
    "    topk_ind = torch.topk(magnitude_matrix, num_nearest_neighbors - 1, largest=largest).indices\n",
    "    mapped_tensor = rand_idx[topk_ind]\n",
    "    index_tensor = torch.arange(0, matrix.shape[1]).unsqueeze(1) # shape [40, 1]\n",
    "    final_tensor = torch.cat([index_tensor, mapped_tensor], dim=1)\n",
    "    print(final_tensor)\n",
    "    \n",
    "         \n",
    "    neigh = matrix[:, final_tensor]\n",
    "    if flatten:\n",
    "        reshape = torch.flatten(neigh, start_dim=1)\n",
    "        return reshape\n",
    "    else:\n",
    "        return neigh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 12, 40])\n",
      "torch.Size([32, 40, 5])\n",
      "BatchedTensor(lvl=1, bdim=0, value=\n",
      "    tensor([[[ 0, 28,  3],\n",
      "             [ 1, 28, 14],\n",
      "             [ 2, 28,  3],\n",
      "             ...,\n",
      "             [37,  8,  3],\n",
      "             [38,  3, 14],\n",
      "             [39, 28, 14]],\n",
      "\n",
      "            [[ 0, 39,  8],\n",
      "             [ 1,  8, 14],\n",
      "             [ 2, 14,  8],\n",
      "             ...,\n",
      "             [37,  3, 28],\n",
      "             [38, 14,  8],\n",
      "             [39, 28,  3]],\n",
      "\n",
      "            [[ 0,  3, 39],\n",
      "             [ 1,  3, 39],\n",
      "             [ 2, 28, 39],\n",
      "             ...,\n",
      "             [37, 14,  8],\n",
      "             [38, 28,  8],\n",
      "             [39,  8, 28]],\n",
      "\n",
      "            ...,\n",
      "\n",
      "            [[ 0,  8, 28],\n",
      "             [ 1,  3, 28],\n",
      "             [ 2, 39, 28],\n",
      "             ...,\n",
      "             [37, 39, 14],\n",
      "             [38, 14, 39],\n",
      "             [39,  3, 14]],\n",
      "\n",
      "            [[ 0,  3, 39],\n",
      "             [ 1,  3, 39],\n",
      "             [ 2,  3, 14],\n",
      "             ...,\n",
      "             [37,  3, 14],\n",
      "             [38,  3, 14],\n",
      "             [39, 28,  3]],\n",
      "\n",
      "            [[ 0, 39, 28],\n",
      "             [ 1, 28,  3],\n",
      "             [ 2,  3,  8],\n",
      "             ...,\n",
      "             [37, 14,  3],\n",
      "             [38, 28, 39],\n",
      "             [39, 28, 14]]])\n",
      ")\n",
      "torch.Size([32, 12, 120])\n"
     ]
    }
   ],
   "source": [
    "rand_idx = torch.tensor([3, 8, 14, 28, 39])\n",
    "rand_idx = [3, 8, 14, 28, 39]\n",
    "\n",
    "\n",
    "print(m1.shape) \n",
    "print(dist.shape)\n",
    "p3 = prime_vmap_2d_N(m1, dist, nnn, torch.tensor(rand_idx), False)\n",
    "print(p3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.allclose(p2, p3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2, 1],\n",
      "        [4, 3],\n",
      "        [0, 1]])\n",
      "tensor([[14,  8],\n",
      "        [39, 28],\n",
      "        [ 3,  8]])\n",
      "tensor([[ 0, 14,  8],\n",
      "        [ 1, 39, 28],\n",
      "        [ 2,  3,  8]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Example tensor of size [40, 2]\n",
    "original_tensor = torch.randint(0, 5, (40, 2))\n",
    "\n",
    "# Mapping list: the index corresponds to the number in the original tensor\n",
    "mapping_list = [3, 8, 14, 28, 39]\n",
    "\n",
    "# Convert the mapping list to a tensor\n",
    "mapping_tensor = torch.tensor(mapping_list)\n",
    "\n",
    "# Use the original tensor to index the mapping tensor\n",
    "mapped_tensor = mapping_tensor[original_tensor]\n",
    "\n",
    "# Create a tensor that adds numbers from 0 to 39\n",
    "index_tensor = torch.arange(40).unsqueeze(1)  # shape [40, 1]\n",
    "\n",
    "# Concatenate the index tensor with the mapped tensor\n",
    "final_tensor = torch.cat((index_tensor, mapped_tensor), dim=1)\n",
    "\n",
    "print(original_tensor[:3, :])\n",
    "print(mapped_tensor[:3, :])\n",
    "print(final_tensor[:3, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.3040, 1.3568, 1.3979, 1.2008, 1.6860],\n",
      "        [1.3195, 1.2407, 1.0779, 0.9359, 1.3165],\n",
      "        [1.0957, 1.2363, 1.1946, 1.0849, 1.1731],\n",
      "        [   inf, 1.6678, 1.3483, 1.0666, 1.4366],\n",
      "        [1.5869, 2.0976, 1.2488, 1.7155, 1.7232],\n",
      "        [0.7085, 1.6939, 1.4109, 1.3193, 1.4974],\n",
      "        [1.4074, 1.3709, 1.3628, 1.5359, 1.6381],\n",
      "        [1.2147, 1.7285, 1.4156, 1.1246, 1.6689],\n",
      "        [1.6678,    inf, 1.3386, 1.2787, 1.5047],\n",
      "        [1.2714, 1.0765, 1.2748, 0.9211, 1.3587]])\n",
      "torch.Size([32, 40, 5])\n",
      "torch.Size([32, 40, 2])\n"
     ]
    }
   ],
   "source": [
    "rand_idx = [3, 8, 14, 28, 39]\n",
    "nnn = 3\n",
    "\n",
    "m1 = torch.rand(32, 12, 40)\n",
    "m2 = m1[:, :, rand_idx]\n",
    "dist = calculate_distance_matrix_N(m1, m2)\n",
    "\n",
    "dist[:, rand_idx, np.arange(len(rand_idx))] = np.inf\n",
    "print(dist[0, 0:10, :])\n",
    "print(dist.shape)\n",
    "\n",
    "ind = torch.topk(dist, nnn-1, largest=False).indices\n",
    "print(ind.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MK",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
