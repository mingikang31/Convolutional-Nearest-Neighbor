{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speed comparison with different convolution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torch\n",
    "import torch \n",
    "from torch import nn\n",
    "from torch.nn import Conv1d\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Train + Data \n",
    "import sys \n",
    "sys.path.append('../Layers')\n",
    "from pixelshuffle import PixelShuffle1D, PixelUnshuffle1D\n",
    "\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Convolutional layers time test\n",
    "- Conv1d(3, 3, kernel_size=3, stride=1, padding=1) vs Conv1d(3, 3, kernel_size=3, stride=3)\n",
    "-  (32, 3, 224) vs. (32, 3, 224*3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = torch.randn(32, 3, 224).to('mps')\n",
    "\n",
    "# original = nn.Conv1d(3, 3, 3, stride=1, padding=1).to('mps')\n",
    "\n",
    "# start = time.time()\n",
    "\n",
    "# for i in range(1000):\n",
    "#     o_out = original(x)\n",
    "    \n",
    "# end = time.time()\n",
    "# print(\"Original Conv1d Time: \", end - start)\n",
    "\n",
    "# print(o_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x1 = torch.randn(32, 3, 224*3).to('mps')\n",
    "\n",
    "# prime = nn.Conv1d(3, 3, 3, stride = 3).to('mps')\n",
    "\n",
    "# start = time.time()\n",
    "# for i in range(1000):\n",
    "#     p_out = prime(x1)\n",
    "# end = time.time()\n",
    "\n",
    "# print(\"Prime Conv1d Time: \", end - start)\n",
    "\n",
    "# print(p_out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### i. (32, 3, 224) Conv1d(3, 3, kernel_size=3, stride=1, padding=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS device is available!\n",
      "Running benchmark with batch size 800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mingikang/miniforge3/envs/ML/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS Time: 0.0796 seconds\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "\n",
    "# Check if MPS is available\n",
    "if torch.backends.mps.is_available():\n",
    "    device_mps = torch.device(\"mps\")\n",
    "    print(\"MPS device is available!\")\n",
    "else:\n",
    "    device_mps = torch.device(\"cpu\")\n",
    "    print(\"MPS device not found, using CPU instead\")\n",
    "\n",
    "device_cpu = torch.device(\"cpu\")\n",
    "\n",
    "# Create proper input for Conv1d: [batch_size, channels, length]\n",
    "batch_size = 800\n",
    "x = torch.randn(batch_size, 3, 150)\n",
    "\n",
    "# Define models and optimizer\n",
    "def benchmark_device(device, iterations=100):\n",
    "    # Move data and model to the specified device\n",
    "    x_device = x.to(device)\n",
    "    model = nn.Conv1d(3, 16, kernel_size=3, stride=1, padding=1).to(device)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "    \n",
    "    # Warmup\n",
    "    for _ in range(5):\n",
    "        out = model(x_device)\n",
    "        loss = out.sum()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "    # Benchmark\n",
    "    torch.cuda.synchronize() if device.type == 'cuda' else None\n",
    "    if device.type == 'mps':\n",
    "        torch.mps.synchronize()\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    for _ in range(iterations):\n",
    "        # Forward pass\n",
    "        out = model(x_device)\n",
    "        \n",
    "        # Compute \"loss\"\n",
    "        loss = out.sum()\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "    torch.cuda.synchronize() if device.type == 'cuda' else None\n",
    "    if device.type == 'mps':\n",
    "        torch.mps.synchronize()\n",
    "    \n",
    "    end = time.time()\n",
    "    return end - start\n",
    "\n",
    "# Run benchmarks\n",
    "print(f\"Running benchmark with batch size {batch_size}\")\n",
    "\n",
    "# time_cpu = benchmark_device(device_cpu)\n",
    "# print(f\"CPU Time: {time_cpu:.4f} seconds\")\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    time_mps = benchmark_device(device_mps)\n",
    "    print(f\"MPS Time: {time_mps:.4f} seconds\")\n",
    "    # print(f\"MPS Speedup: {time_cpu/time_mps:.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ii. (32, 3, 224*3) Conv1d(3, 3, kernel_size=3, stride=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS device is available!\n",
      "Running benchmark with batch size 800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mingikang/miniforge3/envs/ML/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS Time: 0.0789 seconds\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "\n",
    "# Check if MPS is available\n",
    "if torch.backends.mps.is_available():\n",
    "    device_mps = torch.device(\"mps\")\n",
    "    print(\"MPS device is available!\")\n",
    "else:\n",
    "    device_mps = torch.device(\"cpu\")\n",
    "    print(\"MPS device not found, using CPU instead\")\n",
    "\n",
    "device_cpu = torch.device(\"cpu\")\n",
    "\n",
    "# Create proper input for Conv1d: [batch_size, channels, length]\n",
    "batch_size = 800\n",
    "x = torch.randn(batch_size, 3, 150*3)\n",
    "\n",
    "# Define models and optimizer\n",
    "def benchmark_device(device, iterations=100):\n",
    "    # Move data and model to the specified device\n",
    "    x_device = x.to(device)\n",
    "    model = nn.Conv1d(3, 16, kernel_size=3, stride=3).to(device)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "    \n",
    "    # Warmup\n",
    "    for _ in range(5):\n",
    "        out = model(x_device)\n",
    "        loss = out.sum()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "    # Benchmark\n",
    "    torch.cuda.synchronize() if device.type == 'cuda' else None\n",
    "    if device.type == 'mps':\n",
    "        torch.mps.synchronize()\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    for _ in range(iterations):\n",
    "        # Forward pass\n",
    "        out = model(x_device)\n",
    "        \n",
    "        # Compute \"loss\"\n",
    "        loss = out.sum()\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "    torch.cuda.synchronize() if device.type == 'cuda' else None\n",
    "    if device.type == 'mps':\n",
    "        torch.mps.synchronize()\n",
    "    \n",
    "    end = time.time()\n",
    "    return end - start\n",
    "\n",
    "# Run benchmarks\n",
    "print(f\"Running benchmark with batch size {batch_size}\")\n",
    "\n",
    "# time_cpu = benchmark_device(device_cpu)\n",
    "# print(f\"CPU Time: {time_cpu:.4f} seconds\")\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    time_mps = benchmark_device(device_mps)\n",
    "    print(f\"MPS Time: {time_mps:.4f} seconds\")\n",
    "    # print(f\"MPS Speedup: {time_cpu/time_mps:.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- CPU time is way faster for nn.Conv1d(3, 16, kernel_size=3, stride=3) for (3, 224*3)\n",
    "- GPU time is slower for nn.Conv1d(3, 16, kernel_size=3, stride=1, padding=1) for (3, 224)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. ConvNN 1d close examine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv1d_NN(nn.Module):\n",
    "    \"\"\"\n",
    "    Convolution 1D Nearest Neighbor Layer for Convolutional Neural Networks.\n",
    "    \n",
    "    Attributes:\n",
    "        in_channels (int): Number of input channels.\n",
    "        out_channels (int): Number of output channels.\n",
    "        K (int): Number of Nearest Neighbors for consideration.\n",
    "        stride (int): Stride size.\n",
    "        padding (int): Padding size.\n",
    "        shuffle_pattern (str): Shuffle pattern.\n",
    "        shuffle_scale (int): Shuffle scale factor.\n",
    "        samples (int/str): Number of samples to consider.\n",
    "        magnitude_type (str): Distance or Similarity.\n",
    "        \n",
    "    Notes:\n",
    "        - K must be same as stride. K == stride.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 in_channels, \n",
    "                 out_channels, \n",
    "                 K=3, \n",
    "                 stride=3, \n",
    "                 padding=0, \n",
    "                 shuffle_pattern='N/A', \n",
    "                 shuffle_scale=2, \n",
    "                 samples='all', \n",
    "                 magnitude_type='similarity'\n",
    "                 ): \n",
    "        \n",
    "        \"\"\"\n",
    "        Initializes the Conv1d_NN module.\n",
    "        \n",
    "        Parameters:\n",
    "            in_channels (int): Number of input channels.\n",
    "            out_channels (int): Number of output channels.\n",
    "            K (int): Number of Nearest Neighbors for consideration.\n",
    "            stride (int): Stride size.\n",
    "            padding (int): Padding size.\n",
    "            shuffle_pattern (str): Shuffle pattern: \"B\", \"A\", \"BA\".\n",
    "            shuffle_scale (int): Shuffle scale factor.\n",
    "            samples (int/str): Number of samples to consider.\n",
    "            magnitude_type (str): Distance or Similarity.\n",
    "        \"\"\"\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.K = K\n",
    "        self.stride = stride \n",
    "        self.padding = padding\n",
    "        self.shuffle_pattern = shuffle_pattern \n",
    "        self.shuffle_scale = shuffle_scale\n",
    "        self.samples = int(samples) if samples != 'all' else samples \n",
    "        self.magnitude_type = magnitude_type \n",
    "        self.maximum = True if self.magnitude_type == 'similarity' else False\n",
    "        \n",
    "        # Unshuffle layer \n",
    "        self.unshuffle_layer = PixelUnshuffle1D(downscale_factor=self.shuffle_scale)\n",
    "        \n",
    "        # Shuffle Layer \n",
    "        self.shuffle_layer = PixelShuffle1D(upscale_factor=self.shuffle_scale)\n",
    "        \n",
    "        # Channels for Conv1d Layer\n",
    "        self.in_channels = in_channels * shuffle_scale if self.shuffle_pattern in [\"BA\", \"B\"] else in_channels\n",
    "        self.out_channels = out_channels * shuffle_scale if self.shuffle_pattern in [\"BA\", \"A\"] else out_channels\n",
    "\n",
    "        # Conv1d Layer \n",
    "        self.conv1d_layer = Conv1d(in_channels=self.in_channels, \n",
    "                                    out_channels=self.out_channels, \n",
    "                                    kernel_size=self.K, \n",
    "                                    stride=self.stride, \n",
    "                                    padding=self.padding)\n",
    "        \n",
    "        self.random_idx_times = []\n",
    "\n",
    "        \n",
    "        self.matrix_magnitude_times = []\n",
    "        self.prime_times = []\n",
    "        self.conv1d_times = []\n",
    "        \n",
    "\n",
    "    def forward(self, x): \n",
    "        # Consider all samples \n",
    "        if self.samples == 'all': \n",
    "            # Unshuffle Layer \n",
    "            if self.shuffle_pattern in [\"B\", \"BA\"]:\n",
    "                x1 = self.unshuffle_layer(x)\n",
    "            else:\n",
    "                x1 = x\n",
    "            \n",
    "            matrix_magnitude_start = time.time()\n",
    "            # Calculate Distance/Similarity Matrix + Prime Vmap 2D\n",
    "            if self.magnitude_type == 'distance': \n",
    "                matrix_magnitude = self.calculate_distance_matrix(x1)\n",
    "            elif self.magnitude_type == 'similarity':\n",
    "                matrix_magnitude = self.calculate_similarity_matrix(x1)\n",
    "            matrix_magnitude_end = time.time()\n",
    "            self.matrix_magnitude_times.append(matrix_magnitude_end - matrix_magnitude_start)\n",
    "                \n",
    "            prime_start = time.time()\n",
    "            prime_2d = self.prime_vmap_2d(x1, matrix_magnitude, self.K, self.maximum) \n",
    "            prime_end = time.time()\n",
    "            self.prime_times.append(prime_end - prime_start)\n",
    "            \n",
    "            # Conv1d Layer\n",
    "            conv1d_start = time.time()\n",
    "            x2 = self.conv1d_layer(prime_2d)\n",
    "            conv1d_end = time.time()\n",
    "            self.conv1d_times.append(conv1d_end - conv1d_start)\n",
    "            \n",
    "            \n",
    "            # Shuffle Layer \n",
    "            if self.shuffle_pattern in [\"A\", \"BA\"]:\n",
    "                x3 = self.shuffle_layer(x2)\n",
    "            else:\n",
    "                x3 = x2\n",
    "            \n",
    "            return x3\n",
    "        \n",
    "        # Consider N samples\n",
    "        else: \n",
    "            # Unshuffle Layer \n",
    "            if self.shuffle_pattern in [\"B\", \"BA\"]:\n",
    "                x1 = self.unshuffle_layer(x)\n",
    "            else:\n",
    "                x1 = x\n",
    "                \n",
    "                \n",
    "            random_idx_start = time.time()\n",
    "            # Calculate Distance/Similarity Matrix + Prime Vmap 2D\n",
    "            rand_idx = torch.randperm(x1.shape[2], device=x1.device)[:self.samples]\n",
    "            x1_sample = x1[:, :, rand_idx]\n",
    "            random_idx_end = time.time()\n",
    "            self.random_idx_times.append(random_idx_end - random_idx_start)\n",
    "            \n",
    "            \n",
    "            \n",
    "            matrix_magnitude_start = time.time()\n",
    "            if self.magnitude_type == 'distance':\n",
    "                matrix_magnitude = self.calculate_distance_matrix_N(x1, x1_sample)\n",
    "            elif self.magnitude_type == 'similarity':\n",
    "                matrix_magnitude = self.calculate_similarity_matrix_N(x1, x1_sample)\n",
    "                \n",
    "            if self.magnitude_type == 'distance':\n",
    "                matrix_magnitude[:, rand_idx, np.arange(len(rand_idx))] = np.inf \n",
    "            elif self.magnitude_type == 'similarity':\n",
    "                matrix_magnitude[:, rand_idx, np.arange(len(rand_idx))] = -np.inf\n",
    "            matrix_magnitude_end = time.time()\n",
    "            self.matrix_magnitude_times.append(matrix_magnitude_end - matrix_magnitude_start)\n",
    "            \n",
    "            \n",
    "            matrix_magnitude_end = time.time()\n",
    "            self.matrix_magnitude_times.append(matrix_magnitude_end - matrix_magnitude_start)\n",
    "            \n",
    "            prime_start = time.time()\n",
    "            prime = self.prime_vmap_2d_N(x1, matrix_magnitude, self.K, rand_idx, self.maximum)\n",
    "            prime_end = time.time()\n",
    "            self.prime_times.append(prime_end - prime_start)\n",
    "            \n",
    "            # Conv1d Layer\n",
    "            conv1d_start = time.time()\n",
    "            x2 = self.conv1d_layer(prime)\n",
    "            conv1d_end = time.time()\n",
    "            self.conv1d_times.append(conv1d_end - conv1d_start)\n",
    "            \n",
    "            # Shuffle Layer\n",
    "            if self.shuffle_pattern in [\"A\", \"BA\"]:\n",
    "                x3 = self.shuffle_layer(x2)\n",
    "            else:\n",
    "                x3 = x2\n",
    "            \n",
    "            return x3\n",
    "    \n",
    "    ### All Samples ###\n",
    "    @staticmethod\n",
    "    def calculate_distance_matrix(matrix):\n",
    "        \"\"\"Calculates distance matrix of the input matrix\"\"\"\n",
    "        norm_squared = torch.sum(matrix ** 2, dim=1, keepdim=True)\n",
    "        dot_product = torch.bmm(matrix.transpose(2, 1), matrix)\n",
    "        dist_matrix = norm_squared + norm_squared.transpose(2, 1) - 2 * dot_product\n",
    "        return torch.sqrt(dist_matrix)\n",
    "\n",
    "    @staticmethod \n",
    "    def calculate_similarity_matrix(matrix): \n",
    "        \"\"\"Calculates similarity matrix of the input matrix\"\"\"\n",
    "        normalized_matrix = F.normalize(matrix, p=2, dim=1) # p=2 (L2 Norm - Euclidean Distance), dim=1 (across the channels)\n",
    "        dot_product = torch.bmm(normalized_matrix.transpose(2, 1), normalized_matrix)\n",
    "        similarity_matrix = dot_product \n",
    "        return similarity_matrix\n",
    "    \n",
    "    @staticmethod \n",
    "    def prime_vmap_2d(matrix, magnitude_matrix, num_nearest_neighbors, maximum): \n",
    "        \"\"\"Vectorization / Vmap Implementation for Nearest Neighbor Tensor 2D\"\"\"\n",
    "        batched_process = torch.vmap(Conv1d_NN.process_batch, in_dims=(0, 0, None), out_dims=0)\n",
    "        prime = batched_process(matrix, magnitude_matrix, num_nearest_neighbors, flatten=True, maximum=maximum)\n",
    "        return prime \n",
    "\n",
    "    @staticmethod \n",
    "    def prime_vmap_3d(matrix, magnitude_matrix, num_nearest_neighbors, maximum): \n",
    "        \"\"\"Vectorization / Vmap Implementation for Nearest Neighbor Tensor 3D\"\"\"\n",
    "        batched_process = torch.vmap(Conv1d_NN.process_batch, in_dims=(0, 0, None), out_dims=0)\n",
    "        prime = batched_process(matrix, magnitude_matrix, num_nearest_neighbors, flatten=False, maximum=maximum)\n",
    "        return prime\n",
    "\n",
    "    @staticmethod \n",
    "    def process_batch(matrix, magnitude_matrix, num_nearest_neighbors, flatten, maximum): \n",
    "        \"\"\"Process the batch of matrices by finding the K nearest neighbors with reshaping.\"\"\"\n",
    "        ind = torch.topk(magnitude_matrix, num_nearest_neighbors, largest=maximum).indices \n",
    "        neigh = matrix[:, ind]\n",
    "        if flatten: \n",
    "            reshape = torch.flatten(neigh, start_dim=1)\n",
    "            return reshape\n",
    "        return neigh\n",
    "    \n",
    "    ### N Samples ### \n",
    "    @staticmethod \n",
    "    def calculate_distance_matrix_N(matrix, matrix_sample):\n",
    "        \"\"\"Calculates distance matrix between two input matrices\"\"\" \n",
    "        norm_squared = torch.sum(matrix ** 2, dim=1, keepdim=True).permute(0, 2, 1)\n",
    "        norm_squared_sample = torch.sum(matrix_sample ** 2, dim=1, keepdim=True).transpose(2, 1).permute(0, 2, 1)\n",
    "        dot_product = torch.bmm(matrix.transpose(2, 1), matrix_sample)\n",
    "        dist_matrix = norm_squared + norm_squared_sample - 2 * dot_product\n",
    "        return torch.sqrt(dist_matrix)\n",
    "        \n",
    "    @staticmethod\n",
    "    def calculate_similarity_matrix_N(matrix, matrix_sample): \n",
    "        \"\"\"Calculates similarity matrix between two input matrices\"\"\"\n",
    "        normalized_matrix = F.normalize(matrix, p=2, dim=1) # p=2 (L2 Norm - Euclidean Distance), dim=1 (across the channels)\n",
    "        normalized_matrix_sample = F.normalize(matrix_sample, p=2, dim=1)\n",
    "        similarity_matrix = dot_product = torch.bmm(normalized_matrix.transpose(2, 1), normalized_matrix_sample)\n",
    "        return similarity_matrix\n",
    "\n",
    "    @staticmethod\n",
    "    def prime_vmap_2d_N(matrix, magnitude_matrix, num_nearest_neighbors, rand_idx, maximum): \n",
    "        \"\"\"Vectorization / Vmap Implementation for Nearest Neighbor Tensor 2D\"\"\"\n",
    "        batched_process = torch.vmap(Conv1d_NN.process_batch_N, in_dims=(0, 0, None, None), out_dims=0)\n",
    "        prime = batched_process(matrix, magnitude_matrix, num_nearest_neighbors, rand_idx, flatten=True, maximum=maximum)\n",
    "        return prime \n",
    "    \n",
    "    @staticmethod\n",
    "    def prime_vmap_3d_N(matrix, magnitude_matrix, num_nearest_neighbors, rand_idx, maximum): \n",
    "        \"\"\"Vectorization / Vmap Implementation for Nearest Neighbor Tensor 3D\"\"\"\n",
    "        batched_process = torch.vmap(Conv1d_NN.process_batch_N, in_dims=(0, 0, None, None), out_dims=0)\n",
    "        prime = batched_process(matrix, magnitude_matrix, num_nearest_neighbors, rand_idx, flatten=False, maximum=maximum)\n",
    "        return prime\n",
    "    \n",
    "    @staticmethod\n",
    "    def process_batch_N(matrix, magnitude_matrix, num_nearest_neighbors, rand_idx, flatten, maximum): \n",
    "        \"\"\"Process the batch of matrices by finding the K nearest neighbors with reshaping.\"\"\"\n",
    "        topk_ind = torch.topk(magnitude_matrix, num_nearest_neighbors - 1, largest=maximum).indices\n",
    "        device = topk_ind.device\n",
    "        rand_idx = rand_idx.to(device) # same device as topk_ind\n",
    "        mapped_tensor = rand_idx[topk_ind] \n",
    "        index_tensor = torch.arange(0, matrix.shape[1], device=device).unsqueeze(1) # shape [40, 1]\n",
    "        final_tensor = torch.cat([index_tensor, mapped_tensor], dim=1)\n",
    "        neigh = matrix[:, final_tensor] \n",
    "        if flatten: \n",
    "            reshape = torch.flatten(neigh, start_dim=1)\n",
    "            return reshape\n",
    "        return neigh\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS device is available!\n",
      "Running benchmark with batch size 800\n",
      "MPS Time: 8.8121 seconds\n",
      "\n",
      "Matix Magnitude Times:  0.04259228706359863\n",
      "Prime Times:  9.166929483413696\n",
      "Conv1d Times:  0.022477149963378906\n"
     ]
    }
   ],
   "source": [
    "'''All Samples'''\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "\n",
    "# Check if MPS is available\n",
    "if torch.backends.mps.is_available():\n",
    "    device_mps = torch.device(\"mps\")\n",
    "    print(\"MPS device is available!\")\n",
    "else:\n",
    "    device_mps = torch.device(\"cpu\")\n",
    "    print(\"MPS device not found, using CPU instead\")\n",
    "\n",
    "device_cpu = torch.device(\"cpu\")\n",
    "\n",
    "# Create proper input for Conv1d: [batch_size, channels, length]\n",
    "batch_size = 800\n",
    "x = torch.randn(batch_size, 3, 150)\n",
    "\n",
    "# Define models and optimizer\n",
    "def benchmark_device(device, iterations=100):\n",
    "    # Move data and model to the specified device\n",
    "    x_device = x.to(device)\n",
    "    model = Conv1d_NN(3, 16, K=3, stride=3).to(device)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "    \n",
    "    # Warmup\n",
    "    for _ in range(5):\n",
    "        out = model(x_device)\n",
    "        loss = out.sum()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "    # Benchmark\n",
    "    torch.cuda.synchronize() if device.type == 'cuda' else None\n",
    "    if device.type == 'mps':\n",
    "        torch.mps.synchronize()\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    for _ in range(iterations):\n",
    "        # Forward pass\n",
    "        out = model(x_device)\n",
    "        \n",
    "        # Compute \"loss\"\n",
    "        loss = out.sum()\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "    torch.cuda.synchronize() if device.type == 'cuda' else None\n",
    "    if device.type == 'mps':\n",
    "        torch.mps.synchronize()\n",
    "    \n",
    "    end = time.time()\n",
    "    \n",
    "    return ((end - start), model)\n",
    "\n",
    "# Run benchmarks\n",
    "print(f\"Running benchmark with batch size {batch_size}\")\n",
    "\n",
    "# time_cpu = benchmark_device(device_cpu)\n",
    "# print(f\"CPU Time: {time_cpu:.4f} seconds\")\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    benchmark = benchmark_device(device_mps)\n",
    "    time_mps = benchmark[0]\n",
    "    model = benchmark[1]\n",
    "    print(f\"MPS Time: {time_mps:.4f} seconds\")\n",
    "    # print(f\"MPS Speedup: {time_cpu/time_mps:.2f}x\")\n",
    "    \n",
    "print()\n",
    "print(\"Matix Magnitude Times: \", sum(model.matrix_magnitude_times))\n",
    "print(\"Prime Times: \", sum(model.prime_times))\n",
    "print(\"Conv1d Times: \", sum(model.conv1d_times))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS device is available!\n",
      "Running benchmark with batch size 800\n",
      "MPS Time: 6.6426 seconds\n",
      "\n",
      "Random Index Times:  0.04142451286315918\n",
      "Matix Magnitude Times:  0.5385489463806152\n",
      "Prime Times:  6.592907428741455\n",
      "Conv1d Times:  0.02121138572692871\n"
     ]
    }
   ],
   "source": [
    "'''50 Samples'''\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "\n",
    "# Check if MPS is available\n",
    "if torch.backends.mps.is_available():\n",
    "    device_mps = torch.device(\"mps\")\n",
    "    print(\"MPS device is available!\")\n",
    "else:\n",
    "    device_mps = torch.device(\"cpu\")\n",
    "    print(\"MPS device not found, using CPU instead\")\n",
    "\n",
    "device_cpu = torch.device(\"cpu\")\n",
    "\n",
    "# Create proper input for Conv1d: [batch_size, channels, length]\n",
    "batch_size = 800\n",
    "x = torch.randn(batch_size, 3, 150)\n",
    "\n",
    "# Define models and optimizer\n",
    "def benchmark_device(device, iterations=100):\n",
    "    # Move data and model to the specified device\n",
    "    x_device = x.to(device)\n",
    "    model = Conv1d_NN(3, 16, K=3, stride=3, samples=50).to(device)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "    \n",
    "    # Warmup\n",
    "    for _ in range(5):\n",
    "        out = model(x_device)\n",
    "        loss = out.sum()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "    # Benchmark\n",
    "    torch.cuda.synchronize() if device.type == 'cuda' else None\n",
    "    if device.type == 'mps':\n",
    "        torch.mps.synchronize()\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    for _ in range(iterations):\n",
    "        # Forward pass\n",
    "        out = model(x_device)\n",
    "        \n",
    "        # Compute \"loss\"\n",
    "        loss = out.sum()\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "    torch.cuda.synchronize() if device.type == 'cuda' else None\n",
    "    if device.type == 'mps':\n",
    "        torch.mps.synchronize()\n",
    "    \n",
    "    end = time.time()\n",
    "    \n",
    "    return ((end - start), model)\n",
    "\n",
    "# Run benchmarks\n",
    "print(f\"Running benchmark with batch size {batch_size}\")\n",
    "\n",
    "# time_cpu = benchmark_device(device_cpu)\n",
    "# print(f\"CPU Time: {time_cpu:.4f} seconds\")\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    benchmark = benchmark_device(device_mps)\n",
    "    time_mps = benchmark[0]\n",
    "    model = benchmark[1]\n",
    "    print(f\"MPS Time: {time_mps:.4f} seconds\")\n",
    "    # print(f\"MPS Speedup: {time_cpu/time_mps:.2f}x\")\n",
    "    \n",
    "print()\n",
    "print(\"Random Index Times: \", sum(model.random_idx_times))\n",
    "print(\"Matix Magnitude Times: \", sum(model.matrix_magnitude_times))\n",
    "print(\"Prime Times: \", sum(model.prime_times))\n",
    "print(\"Conv1d Times: \", sum(model.conv1d_times))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Conv1d_NN_optimized(nn.Module): \n",
    "    \"\"\"\n",
    "    Convolution 1D Nearest Neighbor Layer for Convolutional Neural Networks.\n",
    "    \n",
    "    Attributes:\n",
    "        in_channels (int): Number of input channels.\n",
    "        out_channels (int): Number of output channels.\n",
    "        K (int): Number of Nearest Neighbors for consideration.\n",
    "        stride (int): Stride size.\n",
    "        padding (int): Padding size.\n",
    "        shuffle_pattern (str): Shuffle pattern.\n",
    "        shuffle_scale (int): Shuffle scale factor.\n",
    "        samples (int/str): Number of samples to consider.\n",
    "        magnitude_type (str): Distance or Similarity.\n",
    "        \n",
    "    Notes:\n",
    "        - K must be same as stride. K == stride.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 in_channels, \n",
    "                 out_channels, \n",
    "                 K=3, \n",
    "                 stride=3, \n",
    "                 padding=0, \n",
    "                 shuffle_pattern='N/A', \n",
    "                 shuffle_scale=2, \n",
    "                 samples='all', \n",
    "                 magnitude_type='similarity'\n",
    "                 ): \n",
    "        \n",
    "        \"\"\"\n",
    "        Initializes the Conv1d_NN module.\n",
    "        \n",
    "        Parameters:\n",
    "            in_channels (int): Number of input channels.\n",
    "            out_channels (int): Number of output channels.\n",
    "            K (int): Number of Nearest Neighbors for consideration.\n",
    "            stride (int): Stride size.\n",
    "            padding (int): Padding size.\n",
    "            shuffle_pattern (str): Shuffle pattern: \"B\", \"A\", \"BA\".\n",
    "            shuffle_scale (int): Shuffle scale factor.\n",
    "            samples (int/str): Number of samples to consider.\n",
    "            magnitude_type (str): Distance or Similarity.\n",
    "        \"\"\"\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.K = K\n",
    "        self.stride = stride \n",
    "        self.padding = padding\n",
    "        self.shuffle_pattern = shuffle_pattern \n",
    "        self.shuffle_scale = shuffle_scale\n",
    "        self.samples = int(samples) if samples != 'all' else samples \n",
    "        self.magnitude_type = magnitude_type \n",
    "        self.maximum = True if self.magnitude_type == 'similarity' else False\n",
    "        \n",
    "        # Unshuffle layer \n",
    "        self.unshuffle_layer = PixelUnshuffle1D(downscale_factor=self.shuffle_scale)\n",
    "        \n",
    "        # Shuffle Layer \n",
    "        self.shuffle_layer = PixelShuffle1D(upscale_factor=self.shuffle_scale)\n",
    "        \n",
    "        # Channels for Conv1d Layer\n",
    "        self.in_channels = in_channels * shuffle_scale if self.shuffle_pattern in [\"BA\", \"B\"] else in_channels\n",
    "        self.out_channels = out_channels * shuffle_scale if self.shuffle_pattern in [\"BA\", \"A\"] else out_channels\n",
    "\n",
    "        # Conv1d Layer \n",
    "        self.conv1d_layer = Conv1d(in_channels=self.in_channels, \n",
    "                                    out_channels=self.out_channels, \n",
    "                                    kernel_size=self.K, \n",
    "                                    stride=self.stride, \n",
    "                                    padding=self.padding)\n",
    "        \n",
    "        self.random_idx_times = []\n",
    "\n",
    "        \n",
    "        self.matrix_magnitude_times = []\n",
    "        self.prime_times = []\n",
    "        self.conv1d_times = []\n",
    "\n",
    "    def forward(self, x): \n",
    "        # Consider all samples \n",
    "        if self.samples == 'all': \n",
    "            # Unshuffle Layer \n",
    "            if self.shuffle_pattern in [\"B\", \"BA\"]:\n",
    "                x1 = self.unshuffle_layer(x)\n",
    "            else:\n",
    "                x1 = x\n",
    "            \n",
    "            matrix_magnitude_start = time.time()    \n",
    "            # Calculate Distance/Similarity Matrix + Prime Vmap 2D\n",
    "            if self.magnitude_type == 'distance': \n",
    "                matrix_magnitude = self._calculate_distance_matrix(x1)\n",
    "            elif self.magnitude_type == 'similarity':\n",
    "                matrix_magnitude = self._calculate_similarity_matrix(x1)\n",
    "            matrix_magnitude_end = time.time()\n",
    "            self.matrix_magnitude_times.append(matrix_magnitude_end - matrix_magnitude_start)\n",
    "                \n",
    "                \n",
    "                \n",
    "            prime_start = time.time()\n",
    "            prime_2d = self._prime(x1, matrix_magnitude, self.K, self.maximum) \n",
    "            prime_end = time.time() \n",
    "            self.prime_times.append(prime_end - prime_start)\n",
    "            \n",
    "            conv1d_start = time.time()\n",
    "            # Conv1d Layer\n",
    "            x2 = self.conv1d_layer(prime_2d)\n",
    "            conv1d_end = time.time()\n",
    "            self.conv1d_times.append(conv1d_end - conv1d_start)\n",
    "            \n",
    "            # Shuffle Layer \n",
    "            if self.shuffle_pattern in [\"A\", \"BA\"]:\n",
    "                x3 = self.shuffle_layer(x2)\n",
    "            else:\n",
    "                x3 = x2\n",
    "            \n",
    "            return x3\n",
    "        \n",
    "        # Consider N samples\n",
    "        else: \n",
    "            # Unshuffle Layer \n",
    "            if self.shuffle_pattern in [\"B\", \"BA\"]:\n",
    "                x1 = self.unshuffle_layer(x)\n",
    "            else:\n",
    "                x1 = x\n",
    "                \n",
    "            random_idx_start = time.time()\n",
    "            # Calculate Distance/Similarity Matrix + Prime Vmap 2D\n",
    "            rand_idx = torch.randperm(x1.shape[2], device=x1.device)[:self.samples]\n",
    "            x1_sample = x1[:, :, rand_idx]\n",
    "            \n",
    "            random_idx_end = time.time()\n",
    "            self.random_idx_times.append(random_idx_end - random_idx_start)\n",
    "                \n",
    "            \n",
    "            \n",
    "            \n",
    "            matrix_magnitude_start = time.time()\n",
    "            if self.magnitude_type == 'distance':\n",
    "                matrix_magnitude = self._calculate_distance_matrix_N(x1, x1_sample)\n",
    "            elif self.magnitude_type == 'similarity':\n",
    "                matrix_magnitude = self._calculate_similarity_matrix_N(x1, x1_sample)\n",
    "                \n",
    "            range_idx = torch.arange(len(rand_idx), device=x1.device)\n",
    "                \n",
    "        \n",
    "            if self.magnitude_type == 'distance':\n",
    "                matrix_magnitude[:, rand_idx, range_idx] = float('inf') \n",
    "            elif self.magnitude_type == 'similarity':\n",
    "                matrix_magnitude[:, rand_idx, range_idx] = float('-inf')\n",
    "                \n",
    "            matrix_magnitude_end = time.time()\n",
    "            self.matrix_magnitude_times.append(matrix_magnitude_end - matrix_magnitude_start)\n",
    "                \n",
    "            \n",
    "            prime_start = time.time()\n",
    "            prime = self._prime_N(x1, matrix_magnitude, self.K, rand_idx, self.maximum)\n",
    "            prime_end = time.time()\n",
    "            self.prime_times.append(prime_end - prime_start)\n",
    "            \n",
    "            \n",
    "            # Conv1d Layer\n",
    "            conv1d_start = time.time()\n",
    "            x2 = self.conv1d_layer(prime)\n",
    "            conv1d_end = time.time()\n",
    "            self.conv1d_times.append(conv1d_end - conv1d_start)\n",
    "            \n",
    "            \n",
    "            # Shuffle Layer\n",
    "            if self.shuffle_pattern in [\"A\", \"BA\"]:\n",
    "                x3 = self.shuffle_layer(x2)\n",
    "            else:\n",
    "                x3 = x2\n",
    "            \n",
    "            return x3\n",
    "    \n",
    "    \n",
    "    def _calculate_distance_matrix(self, matrix, sqrt=False):\n",
    "        norm_squared = torch.sum(matrix ** 2, dim=1, keepdim=True)\n",
    "        dot_product = torch.bmm(matrix.transpose(2, 1), matrix)\n",
    "        dist_matrix = norm_squared + norm_squared.transpose(2, 1) - 2 * dot_product\n",
    "        \n",
    "        dist_matrix = torch.clamp(dist_matrix, min=0) # remove negative values\n",
    "        \n",
    "        if sqrt:\n",
    "            dist_matrix = torch.sqrt(dist_matrix)\n",
    "        return dist_matrix\n",
    "    \n",
    "    def _calculate_distance_matrix_N(self, matrix, matrix_sample, sqrt=False):\n",
    "        norm_squared = torch.sum(matrix ** 2, dim=1, keepdim=True).permute(0, 2, 1)\n",
    "        norm_squared_sample = torch.sum(matrix_sample ** 2, dim=1, keepdim=True).transpose(2, 1).permute(0, 2, 1)\n",
    "        \n",
    "        dot_product = torch.bmm(matrix.transpose(2, 1), matrix_sample)\n",
    "        \n",
    "        dist_matrix = norm_squared + norm_squared_sample - 2 * dot_product\n",
    "        \n",
    "        dist_matrix = torch.clamp(dist_matrix, min=0) # remove negative values\n",
    "        \n",
    "        if sqrt:\n",
    "            dist_matrix = torch.sqrt(dist_matrix)\n",
    "        return dist_matrix\n",
    "    \n",
    "    \n",
    "    def _calculate_similarity_matrix(self, matrix):\n",
    "        norm_matrix = F.normalize(matrix, p=2, dim=1) # p=2 (L2 Norm - Euclidean Distance), dim=1 (across the channels)\n",
    "        similarity_matrix = torch.bmm(norm_matrix.transpose(2, 1), norm_matrix)\n",
    "        return similarity_matrix\n",
    "    \n",
    "    def _calculate_similarity_matrix_N(self, matrix, matrix_sample):\n",
    "        norm_matrix = F.normalize(matrix, p=2, dim=1) # p=2 (L2 Norm - Euclidean Distance), dim=1 (across the channels)\n",
    "        norm_sample = F.normalize(matrix_sample, p=2, dim=1)\n",
    "        similarity_matrix = torch.bmm(norm_matrix.transpose(2, 1), norm_sample)\n",
    "        return similarity_matrix\n",
    "\n",
    "    def _prime(self, matrix, magnitude_matrix, K, maximum):\n",
    "        b, c, t = matrix.shape \n",
    "\n",
    "        _, topk_indices = torch.topk(magnitude_matrix, k = K, dim=2, largest=maximum)\n",
    "        \n",
    "        tk = topk_indices.shape[-1]\n",
    "        \n",
    "        assert K == tk, \"Error: K must be same as tk. K == tk.\"\n",
    "        \n",
    "        indices_expanded = topk_indices.unsqueeze(1).expand(b, c, t, tk)\n",
    "        batch_indices = torch.arange(b).view(b, 1, 1, 1).expand(b, c, t, tk)\n",
    "        channel_indices = torch.arange(c).view(1, c, 1, 1).expand(b, c, t, tk)\n",
    "        \n",
    "        prime = matrix[batch_indices, channel_indices, indices_expanded]\n",
    "        prime = prime.view(b, c, -1)\n",
    "        return prime\n",
    "    \n",
    "    def _prime_N(self, matrix, magnitude_matrix, K, rand_idx, maximum):\n",
    "        \n",
    "        b, c, t = matrix.shape\n",
    "\n",
    "        _, topk_indices = torch.topk(magnitude_matrix, k=K - 1, dim=2, largest=maximum)\n",
    "        tk = topk_indices.shape[-1]\n",
    "        assert K == tk + 1, \"Error: K must be same as tk + 1. K == tk + 1.\"\n",
    "        \n",
    "        mapped_tensor = rand_idx[topk_indices]\n",
    "\n",
    "\n",
    "        token_indices = torch.arange(t, device=matrix.device).view(1, t, 1).expand(b, t, 1)\n",
    "        \n",
    "        final_indices = torch.cat([token_indices, mapped_tensor], dim=2)\n",
    "\n",
    "        indices_expanded = final_indices.unsqueeze(1).expand(b, c, t, K)\n",
    "        \n",
    "        batch_indices = torch.arange(b, device=matrix.device).view(b, 1, 1, 1).expand(b, c, t, K)\n",
    "        channel_indices = torch.arange(c, device=matrix.device).view(1, c, 1, 1).expand(b, c, t, K)\n",
    "\n",
    "        prime = matrix[batch_indices, channel_indices, indices_expanded]  \n",
    "        \n",
    "        prime = prime.view(b, c, -1)\n",
    "        return prime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS device is available!\n",
      "Running benchmark with batch size 800\n",
      "MPS Time: 8.8645 seconds\n",
      "\n",
      "Random Index Times:  0\n",
      "Matix Magnitude Times:  0.025761127471923828\n",
      "Prime Times:  9.175337314605713\n",
      "Conv1d Times:  0.021328210830688477\n"
     ]
    }
   ],
   "source": [
    "'''All Samples'''\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "\n",
    "# Check if MPS is available\n",
    "if torch.backends.mps.is_available():\n",
    "    device_mps = torch.device(\"mps\")\n",
    "    print(\"MPS device is available!\")\n",
    "else:\n",
    "    device_mps = torch.device(\"cpu\")\n",
    "    print(\"MPS device not found, using CPU instead\")\n",
    "\n",
    "device_cpu = torch.device(\"cpu\")\n",
    "\n",
    "# Create proper input for Conv1d: [batch_size, channels, length]\n",
    "batch_size = 800\n",
    "x = torch.randn(batch_size, 3, 150)\n",
    "\n",
    "# Define models and optimizer\n",
    "def benchmark_device(device, iterations=100):\n",
    "    # Move data and model to the specified device\n",
    "    x_device = x.to(device)\n",
    "    model = Conv1d_NN_optimized(3, 16, K=3, stride=3).to(device)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "    \n",
    "    # Warmup\n",
    "    for _ in range(5):\n",
    "        out = model(x_device)\n",
    "        loss = out.sum()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "    # Benchmark\n",
    "    torch.cuda.synchronize() if device.type == 'cuda' else None\n",
    "    if device.type == 'mps':\n",
    "        torch.mps.synchronize()\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    for _ in range(iterations):\n",
    "        # Forward pass\n",
    "        out = model(x_device)\n",
    "        \n",
    "        # Compute \"loss\"\n",
    "        loss = out.sum()\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "    torch.cuda.synchronize() if device.type == 'cuda' else None\n",
    "    if device.type == 'mps':\n",
    "        torch.mps.synchronize()\n",
    "    \n",
    "    end = time.time()\n",
    "    \n",
    "    return ((end - start), model)\n",
    "\n",
    "# Run benchmarks\n",
    "print(f\"Running benchmark with batch size {batch_size}\")\n",
    "\n",
    "# time_cpu = benchmark_device(device_cpu)\n",
    "# print(f\"CPU Time: {time_cpu:.4f} seconds\")\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    benchmark = benchmark_device(device_mps)\n",
    "    time_mps = benchmark[0]\n",
    "    model = benchmark[1]\n",
    "    print(f\"MPS Time: {time_mps:.4f} seconds\")\n",
    "    # print(f\"MPS Speedup: {time_cpu/time_mps:.2f}x\")\n",
    "\n",
    "print()\n",
    "print(\"Random Index Times: \", sum(model.random_idx_times))\n",
    "print(\"Matix Magnitude Times: \", sum(model.matrix_magnitude_times))\n",
    "print(\"Prime Times: \", sum(model.prime_times))\n",
    "print(\"Conv1d Times: \", sum(model.conv1d_times))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS device is available!\n",
      "Running benchmark with batch size 800\n",
      "MPS Time: 6.3435 seconds\n",
      "\n",
      "Random Index Times:  0.02911543846130371\n",
      "Matix Magnitude Times:  0.08023738861083984\n",
      "Prime Times:  2.34340500831604\n",
      "Conv1d Times:  0.011876106262207031\n"
     ]
    }
   ],
   "source": [
    "'''50 Samples'''\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "\n",
    "# Check if MPS is available\n",
    "if torch.backends.mps.is_available():\n",
    "    device_mps = torch.device(\"mps\")\n",
    "    print(\"MPS device is available!\")\n",
    "else:\n",
    "    device_mps = torch.device(\"cpu\")\n",
    "    print(\"MPS device not found, using CPU instead\")\n",
    "\n",
    "device_cpu = torch.device(\"cpu\")\n",
    "\n",
    "# Create proper input for Conv1d: [batch_size, channels, length]\n",
    "batch_size = 800\n",
    "x = torch.randn(batch_size, 3, 150)\n",
    "\n",
    "# Define models and optimizer\n",
    "def benchmark_device(device, iterations=100):\n",
    "    # Move data and model to the specified device\n",
    "    x_device = x.to(device)\n",
    "    model = Conv1d_NN_optimized(3, 16, K=3, stride=3, samples=50).to(device)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "    \n",
    "    # Warmup\n",
    "    for _ in range(5):\n",
    "        out = model(x_device)\n",
    "        loss = out.sum()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "    # Benchmark\n",
    "    torch.cuda.synchronize() if device.type == 'cuda' else None\n",
    "    if device.type == 'mps':\n",
    "        torch.mps.synchronize()\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    for _ in range(iterations):\n",
    "        # Forward pass\n",
    "        out = model(x_device)\n",
    "        \n",
    "        # Compute \"loss\"\n",
    "        loss = out.sum()\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "    torch.cuda.synchronize() if device.type == 'cuda' else None\n",
    "    if device.type == 'mps':\n",
    "        torch.mps.synchronize()\n",
    "    \n",
    "    end = time.time()\n",
    "    \n",
    "    return ((end - start), model)\n",
    "\n",
    "# Run benchmarks\n",
    "print(f\"Running benchmark with batch size {batch_size}\")\n",
    "\n",
    "# time_cpu = benchmark_device(device_cpu)\n",
    "# print(f\"CPU Time: {time_cpu:.4f} seconds\")\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    benchmark = benchmark_device(device_mps)\n",
    "    time_mps = benchmark[0]\n",
    "    model = benchmark[1]\n",
    "    print(f\"MPS Time: {time_mps:.4f} seconds\")\n",
    "    # print(f\"MPS Speedup: {time_cpu/time_mps:.2f}x\")\n",
    "    \n",
    "print()\n",
    "print(\"Random Index Times: \", sum(model.random_idx_times))\n",
    "print(\"Matix Magnitude Times: \", sum(model.matrix_magnitude_times))\n",
    "print(\"Prime Times: \", sum(model.prime_times))\n",
    "print(\"Conv1d Times: \", sum(model.conv1d_times))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimized V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Conv1d_NN_optimized_v2(nn.Module): \n",
    "    \"\"\"\n",
    "    Convolution 1D Nearest Neighbor Layer for Convolutional Neural Networks.\n",
    "    \n",
    "    Attributes:\n",
    "        in_channels (int): Number of input channels.\n",
    "        out_channels (int): Number of output channels.\n",
    "        K (int): Number of Nearest Neighbors for consideration.\n",
    "        stride (int): Stride size.\n",
    "        padding (int): Padding size.\n",
    "        shuffle_pattern (str): Shuffle pattern.\n",
    "        shuffle_scale (int): Shuffle scale factor.\n",
    "        samples (int/str): Number of samples to consider.\n",
    "        magnitude_type (str): Distance or Similarity.\n",
    "        \n",
    "    Notes:\n",
    "        - K must be same as stride. K == stride.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 in_channels, \n",
    "                 out_channels, \n",
    "                 K=3, \n",
    "                 stride=3, \n",
    "                 padding=0, \n",
    "                 shuffle_pattern='N/A', \n",
    "                 shuffle_scale=2, \n",
    "                 samples='all', \n",
    "                 magnitude_type='similarity'\n",
    "                 ): \n",
    "        \n",
    "        \"\"\"\n",
    "        Initializes the Conv1d_NN module.\n",
    "        \n",
    "        Parameters:\n",
    "            in_channels (int): Number of input channels.\n",
    "            out_channels (int): Number of output channels.\n",
    "            K (int): Number of Nearest Neighbors for consideration.\n",
    "            stride (int): Stride size.\n",
    "            padding (int): Padding size.\n",
    "            shuffle_pattern (str): Shuffle pattern: \"B\", \"A\", \"BA\".\n",
    "            shuffle_scale (int): Shuffle scale factor.\n",
    "            samples (int/str): Number of samples to consider.\n",
    "            magnitude_type (str): Distance or Similarity.\n",
    "        \"\"\"\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.K = K\n",
    "        self.stride = stride \n",
    "        self.padding = padding\n",
    "        self.shuffle_pattern = shuffle_pattern \n",
    "        self.shuffle_scale = shuffle_scale\n",
    "        self.samples = int(samples) if samples != 'all' else samples \n",
    "        self.magnitude_type = magnitude_type \n",
    "        self.maximum = True if self.magnitude_type == 'similarity' else False\n",
    "        \n",
    "        # Unshuffle layer \n",
    "        self.unshuffle_layer = PixelUnshuffle1D(downscale_factor=self.shuffle_scale)\n",
    "        \n",
    "        # Shuffle Layer \n",
    "        self.shuffle_layer = PixelShuffle1D(upscale_factor=self.shuffle_scale)\n",
    "        \n",
    "        # Channels for Conv1d Layer\n",
    "        self.in_channels = in_channels * shuffle_scale if self.shuffle_pattern in [\"BA\", \"B\"] else in_channels\n",
    "        self.out_channels = out_channels * shuffle_scale if self.shuffle_pattern in [\"BA\", \"A\"] else out_channels\n",
    "\n",
    "        # Conv1d Layer \n",
    "        self.conv1d_layer = Conv1d(in_channels=self.in_channels, \n",
    "                                    out_channels=self.out_channels, \n",
    "                                    kernel_size=self.K, \n",
    "                                    stride=self.stride, \n",
    "                                    padding=self.padding)\n",
    "        \n",
    "        self.random_idx_times = []\n",
    "\n",
    "        \n",
    "        self.matrix_magnitude_times = []\n",
    "        self.prime_times = []\n",
    "        self.conv1d_times = []\n",
    "        \n",
    "\n",
    "    def forward(self, x): \n",
    "        # Consider all samples \n",
    "        if self.samples == 'all': \n",
    "            # Unshuffle Layer \n",
    "            if self.shuffle_pattern in [\"B\", \"BA\"]:\n",
    "                x1 = self.unshuffle_layer(x)\n",
    "            else:\n",
    "                x1 = x\n",
    "            \n",
    "            matrix_magnitude_start = time.time()    \n",
    "            # Calculate Distance/Similarity Matrix + Prime Vmap 2D\n",
    "            if self.magnitude_type == 'distance': \n",
    "                matrix_magnitude = self._calculate_distance_matrix(x1)\n",
    "            elif self.magnitude_type == 'similarity':\n",
    "                matrix_magnitude = self._calculate_similarity_matrix(x1)\n",
    "            matrix_magnitude_end = time.time()\n",
    "            self.matrix_magnitude_times.append(matrix_magnitude_end - matrix_magnitude_start)\n",
    "                \n",
    "                \n",
    "                \n",
    "            prime_start = time.time()\n",
    "            prime_2d = self._prime(x1, matrix_magnitude, self.K, self.maximum) \n",
    "            prime_end = time.time() \n",
    "            self.prime_times.append(prime_end - prime_start)\n",
    "            \n",
    "            conv1d_start = time.time()\n",
    "            # Conv1d Layer\n",
    "            x2 = self.conv1d_layer(prime_2d)\n",
    "            conv1d_end = time.time()\n",
    "            self.conv1d_times.append(conv1d_end - conv1d_start)\n",
    "            \n",
    "            # Shuffle Layer \n",
    "            if self.shuffle_pattern in [\"A\", \"BA\"]:\n",
    "                x3 = self.shuffle_layer(x2)\n",
    "            else:\n",
    "                x3 = x2\n",
    "            \n",
    "            return x3\n",
    "        \n",
    "        # Consider N samples\n",
    "        else: \n",
    "            # Unshuffle Layer \n",
    "            if self.shuffle_pattern in [\"B\", \"BA\"]:\n",
    "                x1 = self.unshuffle_layer(x)\n",
    "            else:\n",
    "                x1 = x\n",
    "                \n",
    "            random_idx_start = time.time()\n",
    "            # Calculate Distance/Similarity Matrix + Prime Vmap 2D\n",
    "            rand_idx = torch.randperm(x1.shape[2], device=x1.device)[:self.samples]\n",
    "            x1_sample = x1[:, :, rand_idx]\n",
    "            \n",
    "            random_idx_end = time.time()\n",
    "            self.random_idx_times.append(random_idx_end - random_idx_start)\n",
    "                \n",
    "            \n",
    "            \n",
    "            \n",
    "            matrix_magnitude_start = time.time()\n",
    "            if self.magnitude_type == 'distance':\n",
    "                matrix_magnitude = self._calculate_distance_matrix_N(x1, x1_sample)\n",
    "            elif self.magnitude_type == 'similarity':\n",
    "                matrix_magnitude = self._calculate_similarity_matrix_N(x1, x1_sample)\n",
    "                \n",
    "            range_idx = torch.arange(len(rand_idx), device=x1.device)\n",
    "                \n",
    "        \n",
    "            if self.magnitude_type == 'distance':\n",
    "                matrix_magnitude[:, rand_idx, range_idx] = float('inf') \n",
    "            elif self.magnitude_type == 'similarity':\n",
    "                matrix_magnitude[:, rand_idx, range_idx] = float('-inf')\n",
    "                \n",
    "            matrix_magnitude_end = time.time()\n",
    "            self.matrix_magnitude_times.append(matrix_magnitude_end - matrix_magnitude_start)\n",
    "                \n",
    "            \n",
    "            prime_start = time.time()\n",
    "            prime = self._prime_N(x1, matrix_magnitude, self.K, rand_idx, self.maximum)\n",
    "            prime_end = time.time()\n",
    "            self.prime_times.append(prime_end - prime_start)\n",
    "            \n",
    "            \n",
    "            # Conv1d Layer\n",
    "            conv1d_start = time.time()\n",
    "            x2 = self.conv1d_layer(prime)\n",
    "            conv1d_end = time.time()\n",
    "            self.conv1d_times.append(conv1d_end - conv1d_start)\n",
    "            \n",
    "            \n",
    "            # Shuffle Layer\n",
    "            if self.shuffle_pattern in [\"A\", \"BA\"]:\n",
    "                x3 = self.shuffle_layer(x2)\n",
    "            else:\n",
    "                x3 = x2\n",
    "            \n",
    "            return x3\n",
    "    \n",
    "    \n",
    "    def _calculate_distance_matrix(self, matrix, sqrt=False):\n",
    "        norm_squared = torch.sum(matrix ** 2, dim=1, keepdim=True)\n",
    "        dot_product = torch.bmm(matrix.transpose(2, 1), matrix)\n",
    "        dist_matrix = norm_squared + norm_squared.transpose(2, 1) - 2 * dot_product\n",
    "        \n",
    "        dist_matrix = torch.clamp(dist_matrix, min=0) # remove negative values\n",
    "        \n",
    "        if sqrt:\n",
    "            dist_matrix = torch.sqrt(dist_matrix)\n",
    "        return dist_matrix\n",
    "    \n",
    "    def _calculate_distance_matrix_N(self, matrix, matrix_sample, sqrt=False):\n",
    "        norm_squared = torch.sum(matrix ** 2, dim=1, keepdim=True).permute(0, 2, 1)\n",
    "        norm_squared_sample = torch.sum(matrix_sample ** 2, dim=1, keepdim=True).transpose(2, 1).permute(0, 2, 1)\n",
    "        \n",
    "        dot_product = torch.bmm(matrix.transpose(2, 1), matrix_sample)\n",
    "        \n",
    "        dist_matrix = norm_squared + norm_squared_sample - 2 * dot_product\n",
    "        \n",
    "        dist_matrix = torch.clamp(dist_matrix, min=0) # remove negative values\n",
    "        \n",
    "        if sqrt:\n",
    "            dist_matrix = torch.sqrt(dist_matrix)\n",
    "        return dist_matrix\n",
    "    \n",
    "    \n",
    "    def _calculate_similarity_matrix(self, matrix):\n",
    "        norm_matrix = F.normalize(matrix, p=2, dim=1) # p=2 (L2 Norm - Euclidean Distance), dim=1 (across the channels)\n",
    "        similarity_matrix = torch.bmm(norm_matrix.transpose(2, 1), norm_matrix)\n",
    "        return similarity_matrix\n",
    "    \n",
    "    def _calculate_similarity_matrix_N(self, matrix, matrix_sample):\n",
    "        norm_matrix = F.normalize(matrix, p=2, dim=1) # p=2 (L2 Norm - Euclidean Distance), dim=1 (across the channels)\n",
    "        norm_sample = F.normalize(matrix_sample, p=2, dim=1)\n",
    "        similarity_matrix = torch.bmm(norm_matrix.transpose(2, 1), norm_sample)\n",
    "        return similarity_matrix\n",
    "\n",
    "    def _prime(self, matrix, magnitude_matrix, K, maximum):\n",
    "        b, c, t = matrix.shape\n",
    "        # Get top-K indices: shape [b, t, K]\n",
    "        _, topk_indices = torch.topk(magnitude_matrix, k=K, dim=2, largest=maximum)\n",
    "        \n",
    "        # Expand indices to add channel dimension: [b, 1, t, K] then expand to [b, c, t, K]\n",
    "        topk_indices_exp = topk_indices.unsqueeze(1).expand(b, c, t, K)\n",
    "        \n",
    "        # Unsqueeze matrix and expand so that the gathered dimension has size K.\n",
    "        # matrix.unsqueeze(-1) yields shape [b, c, t, 1]\n",
    "        # Then expand to [b, c, t, K] and force contiguous memory.\n",
    "        matrix_expanded = matrix.unsqueeze(-1).expand(b, c, t, K).contiguous()\n",
    "        \n",
    "        # Gather along the token dimension (dim=2) using the expanded indices.\n",
    "        prime = torch.gather(matrix_expanded, dim=2, index=topk_indices_exp)\n",
    "        \n",
    "        # Flatten the token and neighbor dimensions: [b, c, t*K]\n",
    "        prime = prime.view(b, c, -1)\n",
    "        return prime\n",
    "    \n",
    "    def _prime_N(self, matrix, magnitude_matrix, K, rand_idx, maximum):\n",
    "        b, c, t = matrix.shape\n",
    "\n",
    "        # Get top-(K-1) indices from the magnitude matrix; shape: [b, t, K-1]\n",
    "        _, topk_indices = torch.topk(magnitude_matrix, k=K - 1, dim=2, largest=maximum)\n",
    "        tk = topk_indices.shape[-1]\n",
    "        assert K == tk + 1, \"Error: K must be same as tk + 1. K == tk + 1.\"\n",
    "\n",
    "        # Map indices from the sampled space to the full token indices using rand_idx.\n",
    "        # mapped_tensor will have shape: [b, t, K-1]\n",
    "        mapped_tensor = rand_idx[topk_indices]\n",
    "\n",
    "        # Create self indices for each token; shape: [1, t, 1] then expand to [b, t, 1]\n",
    "        token_indices = torch.arange(t, device=matrix.device).view(1, t, 1).expand(b, t, 1)\n",
    "\n",
    "        # Concatenate self index with neighbor indices to form final indices; shape: [b, t, K]\n",
    "        final_indices = torch.cat([token_indices, mapped_tensor], dim=2)\n",
    "\n",
    "        # Expand final_indices to include the channel dimension; result shape: [b, c, t, K]\n",
    "        indices_expanded = final_indices.unsqueeze(1).expand(b, c, t, K)\n",
    "\n",
    "        # Expand matrix to shape [b, c, t, 1] and then to [b, c, t, K] (ensuring contiguous memory)\n",
    "        matrix_expanded = matrix.unsqueeze(-1).expand(b, c, t, K).contiguous()\n",
    "\n",
    "        # Gather neighbor features along the token dimension (dim=2)\n",
    "        prime = torch.gather(matrix_expanded, dim=2, index=indices_expanded)  # shape: [b, c, t, K]\n",
    "\n",
    "        # Flatten the token and neighbor dimensions into one: [b, c, t*K]\n",
    "        prime = prime.view(b, c, -1)\n",
    "        return prime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS device is available!\n",
      "Running benchmark with batch size 800\n",
      "MPS Time: 8.6103 seconds\n",
      "\n",
      "Random Index Times:  0\n",
      "Matix Magnitude Times:  5.652441740036011\n",
      "Prime Times:  0.09897708892822266\n",
      "Conv1d Times:  0.01589179039001465\n"
     ]
    }
   ],
   "source": [
    "'''All Samples'''\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "\n",
    "# Check if MPS is available\n",
    "if torch.backends.mps.is_available():\n",
    "    device_mps = torch.device(\"mps\")\n",
    "    print(\"MPS device is available!\")\n",
    "else:\n",
    "    device_mps = torch.device(\"cpu\")\n",
    "    print(\"MPS device not found, using CPU instead\")\n",
    "\n",
    "device_cpu = torch.device(\"cpu\")\n",
    "\n",
    "# Create proper input for Conv1d: [batch_size, channels, length]\n",
    "batch_size = 800\n",
    "x = torch.randn(batch_size, 3, 150)\n",
    "\n",
    "# Define models and optimizer\n",
    "def benchmark_device(device, iterations=100):\n",
    "    # Move data and model to the specified device\n",
    "    x_device = x.to(device)\n",
    "    model = Conv1d_NN_optimized_v2(3, 16, K=3, stride=3).to(device)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "    \n",
    "    # Warmup\n",
    "    for _ in range(5):\n",
    "        out = model(x_device)\n",
    "        loss = out.sum()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "    # Benchmark\n",
    "    torch.cuda.synchronize() if device.type == 'cuda' else None\n",
    "    if device.type == 'mps':\n",
    "        torch.mps.synchronize()\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    for _ in range(iterations):\n",
    "        # Forward pass\n",
    "        out = model(x_device)\n",
    "        \n",
    "        # Compute \"loss\"\n",
    "        loss = out.sum()\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "    torch.cuda.synchronize() if device.type == 'cuda' else None\n",
    "    if device.type == 'mps':\n",
    "        torch.mps.synchronize()\n",
    "    \n",
    "    end = time.time()\n",
    "    \n",
    "    return ((end - start), model)\n",
    "\n",
    "# Run benchmarks\n",
    "print(f\"Running benchmark with batch size {batch_size}\")\n",
    "\n",
    "# time_cpu = benchmark_device(device_cpu)\n",
    "# print(f\"CPU Time: {time_cpu:.4f} seconds\")\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    benchmark = benchmark_device(device_mps)\n",
    "    time_mps = benchmark[0]\n",
    "    model = benchmark[1]\n",
    "    print(f\"MPS Time: {time_mps:.4f} seconds\")\n",
    "    # print(f\"MPS Speedup: {time_cpu/time_mps:.2f}x\")\n",
    "\n",
    "print()\n",
    "print(\"Random Index Times: \", sum(model.random_idx_times))\n",
    "print(\"Matix Magnitude Times: \", sum(model.matrix_magnitude_times))\n",
    "print(\"Prime Times: \", sum(model.prime_times))\n",
    "print(\"Conv1d Times: \", sum(model.conv1d_times))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS device is available!\n",
      "Running benchmark with batch size 800\n",
      "MPS Time: 6.2555 seconds\n",
      "\n",
      "Random Index Times:  0.05554485321044922\n",
      "Matix Magnitude Times:  0.08896684646606445\n",
      "Prime Times:  2.3018600940704346\n",
      "Conv1d Times:  0.0177919864654541\n"
     ]
    }
   ],
   "source": [
    "'''50 Samples'''\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "\n",
    "# Check if MPS is available\n",
    "if torch.backends.mps.is_available():\n",
    "    device_mps = torch.device(\"mps\")\n",
    "    print(\"MPS device is available!\")\n",
    "else:\n",
    "    device_mps = torch.device(\"cpu\")\n",
    "    print(\"MPS device not found, using CPU instead\")\n",
    "\n",
    "device_cpu = torch.device(\"cpu\")\n",
    "\n",
    "# Create proper input for Conv1d: [batch_size, channels, length]\n",
    "batch_size = 800\n",
    "x = torch.randn(batch_size, 3, 150)\n",
    "\n",
    "# Define models and optimizer\n",
    "def benchmark_device(device, iterations=100):\n",
    "    # Move data and model to the specified device\n",
    "    x_device = x.to(device)\n",
    "    model = Conv1d_NN_optimized_v2(3, 16, K=3, stride=3, samples=50).to(device)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "    \n",
    "    # Warmup\n",
    "    for _ in range(5):\n",
    "        out = model(x_device)\n",
    "        loss = out.sum()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "    # Benchmark\n",
    "    torch.cuda.synchronize() if device.type == 'cuda' else None\n",
    "    if device.type == 'mps':\n",
    "        torch.mps.synchronize()\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    for _ in range(iterations):\n",
    "        # Forward pass\n",
    "        out = model(x_device)\n",
    "        \n",
    "        # Compute \"loss\"\n",
    "        loss = out.sum()\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "    torch.cuda.synchronize() if device.type == 'cuda' else None\n",
    "    if device.type == 'mps':\n",
    "        torch.mps.synchronize()\n",
    "    \n",
    "    end = time.time()\n",
    "    \n",
    "    return ((end - start), model)\n",
    "\n",
    "# Run benchmarks\n",
    "print(f\"Running benchmark with batch size {batch_size}\")\n",
    "\n",
    "# time_cpu = benchmark_device(device_cpu)\n",
    "# print(f\"CPU Time: {time_cpu:.4f} seconds\")\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    benchmark = benchmark_device(device_mps)\n",
    "    time_mps = benchmark[0]\n",
    "    model = benchmark[1]\n",
    "    print(f\"MPS Time: {time_mps:.4f} seconds\")\n",
    "    # print(f\"MPS Speedup: {time_cpu/time_mps:.2f}x\")\n",
    "    \n",
    "print()\n",
    "print(\"Random Index Times: \", sum(model.random_idx_times))\n",
    "print(\"Matix Magnitude Times: \", sum(model.matrix_magnitude_times))\n",
    "print(\"Prime Times: \", sum(model.prime_times))\n",
    "print(\"Conv1d Times: \", sum(model.conv1d_times))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SOMETHING IS WRONG WITH ConvNN1d Optimized N Random Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
