{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Double Checking matrix prime calculations for random sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mingikang/miniforge3/envs/ML/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Torch\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim \n",
    "\n",
    "\n",
    "# Train + Data \n",
    "import sys \n",
    "sys.path.append('../Layers')\n",
    "from Conv1d_NN import * \n",
    "from Conv2d_NN import * \n",
    "from Conv1d_NN_spatial import *\n",
    "from Conv2d_NN_spatial import * \n",
    "\n",
    "sys.path.append('../Data')\n",
    "from CIFAR10 import * \n",
    "\n",
    "\n",
    "sys.path.append('../Train')\n",
    "from train2d import * \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "ex1 = torch.rand(1, 5, 5)\n",
    "print(ex1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "ds_Reg = Conv1d_NN.calculate_distance_matrix(ex1)\n",
    "print(ds_Reg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "ds_Spatial = Conv1d_NN_spatial.calculate_distance_matrix_N(ex1, ex1)\n",
    "print(ds_Spatial.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = torch.equal(ds_Reg, ds_Spatial)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., nan, 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., nan]]])\n"
     ]
    }
   ],
   "source": [
    "sub = ds_Reg - ds_Spatial\n",
    "print(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "tensor([[[0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]]])\n"
     ]
    }
   ],
   "source": [
    "sm_reg = Conv1d_NN.calculate_similarity_matrix(ex1)\n",
    "\n",
    "sm_spatial = Conv1d_NN_spatial.calculate_similarity_matrix_N(ex1, ex1)\n",
    "\n",
    "result = torch.equal(sm_reg, sm_spatial)\n",
    "print(result)\n",
    "\n",
    "sub = sm_reg - sm_spatial\n",
    "print(sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Spatial sampling indices for batch processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_sample shape:  torch.Size([32, 12, 14, 14])\n",
      "x_sample_flatten shape:  torch.Size([32, 12, 196])\n",
      "x2 shape:  torch.Size([32, 12, 196])\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "x1 = torch.randn(32, 12, 14, 14)\n",
    "sample_padding = 0\n",
    "samples = 14\n",
    "\n",
    "# Generate equally spaced indices for rows (x) and columns (y)\n",
    "x_ind = torch.round(torch.linspace(sample_padding,\n",
    "                                   x1.shape[2] - sample_padding - 1,\n",
    "                                   samples)).to(torch.int)\n",
    "y_ind = torch.round(torch.linspace(sample_padding,\n",
    "                                   x1.shape[3] - sample_padding - 1,\n",
    "                                   samples)).to(torch.int)\n",
    "\n",
    "# Create a meshgrid of indices\n",
    "x_grid, y_grid = torch.meshgrid(x_ind, y_ind, indexing='ij')\n",
    "\n",
    "x_sample = x1[:, :, x_grid, y_grid]\n",
    "print(\"x_sample shape: \", x_sample.shape)\n",
    "\n",
    "x_sample_flatten = x_sample.flatten(start_dim=2)\n",
    "print(\"x_sample_flatten shape: \", x_sample_flatten.shape)\n",
    "\n",
    "\n",
    "flatten = nn.Flatten(start_dim=2)\n",
    "x2 = flatten(x1)\n",
    "print(\"x2 shape: \", x2.shape)\n",
    "\n",
    "result = torch.equal(x_sample_flatten, x2)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3x3 Sample pixel positions (flattened indices): tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195],\n",
      "       dtype=torch.int32)\n",
      "torch.Size([32, 12, 196])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Sample input tensor dimensions [32, 12, 14, 14]\n",
    "x1 = torch.randn(32, 12, 14, 14)\n",
    "sample_padding = 0\n",
    "samples = 14  # We want a 3x3 sample\n",
    "\n",
    "# Generate equally spaced indices for rows (x) and columns (y)\n",
    "x_ind = torch.round(torch.linspace(sample_padding,\n",
    "                                   x1.shape[2] - sample_padding - 1,\n",
    "                                   samples)).to(torch.int)\n",
    "y_ind = torch.round(torch.linspace(sample_padding,\n",
    "                                   x1.shape[3] - sample_padding - 1,\n",
    "                                   samples)).to(torch.int)\n",
    "\n",
    "# Create a meshgrid of indices\n",
    "x_grid, y_grid = torch.meshgrid(x_ind, y_ind, indexing='ij')\n",
    "\n",
    "# Flatten the grid indices (each will have 'samples*samples' = 9 values)\n",
    "x_idx_flat = x_grid.flatten()  # Row indices\n",
    "y_idx_flat = y_grid.flatten()  # Column indices\n",
    "\n",
    "# To get the corresponding flattened indices for a 14x14 matrix:\n",
    "width = x1.shape[3]  # This is 14\n",
    "flat_indices = x_idx_flat * width + y_idx_flat\n",
    "\n",
    "print(\"3x3 Sample pixel positions (flattened indices):\", flat_indices)\n",
    "\n",
    "flatten = nn.Flatten(start_dim=2)\n",
    "x1 = torch.randn(32, 12, 14, 14)\n",
    "x2 = flatten(x1)\n",
    "print(x2.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Adding Spatial Coordinate channels -> + 2 channels for x coord & y coord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 5, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Example tensor of shape [18, 3, 32, 32]\n",
    "x = torch.randn(18, 3, 32, 32)\n",
    "\n",
    "# Create 2 extra channels of ones with shape [18, 2, 32, 32]\n",
    "ones_channels = torch.ones(x.size(0), 2, x.size(2), x.size(3), device=x.device, dtype=x.dtype)\n",
    "\n",
    "# Concatenate along the channel axis (dim=1)\n",
    "x_with_extra = torch.cat([x, ones_channels], dim=1)\n",
    "\n",
    "print(x_with_extra.shape)  # Expected shape: [18, 5, 32, 32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The last two channels are filled with 1s.\n",
      "The last two channels are filled with 1s.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Assume x_with_extra is your [18, 5, 32, 32] tensor.\n",
    "# Method 1: Using a boolean equal check\n",
    "if torch.all(x_with_extra[:, -2:, :, :] == 1):\n",
    "    print(\"The last two channels are filled with 1s.\")\n",
    "\n",
    "# Method 2: Using torch.allclose for floating point comparisons\n",
    "ones_tensor = torch.ones_like(x_with_extra[:, -2:, :, :])\n",
    "if torch.allclose(x_with_extra[:, -2:, :, :], ones_tensor):\n",
    "    print(\"The last two channels are filled with 1s.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last channel values:\n",
      "tensor([[[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         ...,\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         ...,\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         ...,\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         ...,\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         ...,\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         ...,\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.]]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Last channel values:\")\n",
    "print(x_with_extra[:, -1, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_grid.shape:  torch.Size([32, 32])\n",
      "y_grid.shape:  torch.Size([32, 32])\n",
      "Final shape: torch.Size([18, 5, 32, 32])\n",
      "torch.Size([32, 32])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 2 spatial channels of x coord and y coord\n",
    "x_ind = torch.arange(0, 32)\n",
    "y_ind = torch.arange(0, 32)\n",
    "\n",
    "x_grid, y_grid = torch.meshgrid(x_ind, y_ind, indexing='ij')\n",
    "\n",
    "print(\"x_grid.shape: \", x_grid.shape)\n",
    "print(\"y_grid.shape: \", y_grid.shape)\n",
    "\n",
    "ex = torch.randn(18, 3, 32, 32)\n",
    "\n",
    "# Expand x_grid and y_grid to have a batch dimension\n",
    "x_grid_expanded = x_grid.unsqueeze(0).expand(ex.size(0), -1, -1)  # Shape: [18, 32, 32]\n",
    "y_grid_expanded = y_grid.unsqueeze(0).expand(ex.size(0), -1, -1)  # Shape: [18, 32, 32]\n",
    "\n",
    "# Add a channel dimension\n",
    "x_grid_channeled = x_grid_expanded.unsqueeze(1)  # Shape: [18, 1, 32, 32]\n",
    "y_grid_channeled = y_grid_expanded.unsqueeze(1)  # Shape: [18, 1, 32, 32]\n",
    "\n",
    "\n",
    "\n",
    "# Concatenate along the channel dimension\n",
    "x_spatial_channel = torch.cat([ex, x_grid_channeled, y_grid_channeled], dim=1)\n",
    "print(\"Final shape:\", x_spatial_channel.shape)  # Expected shape: [18, 5, 32, 32]\n",
    "\n",
    "print(x_spatial_channel[-1, -1, :, :].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coordinate_channels(tensor_shape):\n",
    "    x_ind = torch.arange(0, tensor_shape[2])\n",
    "    y_ind = torch.arange(0, tensor_shape[3])\n",
    "    \n",
    "    x_grid, y_grid = torch.meshgrid(x_ind, y_ind, indexing='ij')\n",
    "    \n",
    "    x_grid = x_grid.float().unsqueeze(0).expand(tensor_shape[0], -1, -1).unsqueeze(1)\n",
    "    y_grid = y_grid.float().unsqueeze(0).expand(tensor_shape[0], -1, -1).unsqueeze(1)\n",
    "    \n",
    "    xy_grid = torch.cat((x_grid, y_grid), dim=1)\n",
    "    xy_grid_normalized = F.normalize(xy_grid, p=2, dim=1)\n",
    "    return xy_grid_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "IPython -- An enhanced Interactive Python\n",
      "=========================================\n",
      "\n",
      "IPython offers a fully compatible replacement for the standard Python\n",
      "interpreter, with convenient shell features, special commands, command\n",
      "history mechanism and output results caching.\n",
      "\n",
      "At your system command line, type 'ipython -h' to see the command line\n",
      "options available. This document only describes interactive features.\n",
      "\n",
      "GETTING HELP\n",
      "------------\n",
      "\n",
      "Within IPython you have various way to access help:\n",
      "\n",
      "  ?         -> Introduction and overview of IPython's features (this screen).\n",
      "  object?   -> Details about 'object'.\n",
      "  object??  -> More detailed, verbose information about 'object'.\n",
      "  %quickref -> Quick reference of all IPython specific syntax and magics.\n",
      "  help      -> Access Python's own help system.\n",
      "\n",
      "If you are in terminal IPython you can quit this screen by pressing `q`.\n",
      "\n",
      "\n",
      "MAIN FEATURES\n",
      "-------------\n",
      "\n",
      "* Access to the standard Python help with object docstrings and the Python\n",
      "  manuals. Simply type 'help' (no quotes) to invoke it.\n",
      "\n",
      "* Magic commands: type %magic for information on the magic subsystem.\n",
      "\n",
      "* System command aliases, via the %alias command or the configuration file(s).\n",
      "\n",
      "* Dynamic object information:\n",
      "\n",
      "  Typing ?word or word? prints detailed information about an object. Certain\n",
      "  long strings (code, etc.) get snipped in the center for brevity.\n",
      "\n",
      "  Typing ??word or word?? gives access to the full information without\n",
      "  snipping long strings. Strings that are longer than the screen are printed\n",
      "  through the less pager.\n",
      "\n",
      "  The ?/?? system gives access to the full source code for any object (if\n",
      "  available), shows function prototypes and other useful information.\n",
      "\n",
      "  If you just want to see an object's docstring, type '%pdoc object' (without\n",
      "  quotes, and without % if you have automagic on).\n",
      "\n",
      "* Tab completion in the local namespace:\n",
      "\n",
      "  At any time, hitting tab will complete any available python commands or\n",
      "  variable names, and show you a list of the possible completions if there's\n",
      "  no unambiguous one. It will also complete filenames in the current directory.\n",
      "\n",
      "* Search previous command history in multiple ways:\n",
      "\n",
      "  - Start typing, and then use arrow keys up/down or (Ctrl-p/Ctrl-n) to search\n",
      "    through the history items that match what you've typed so far.\n",
      "\n",
      "  - Hit Ctrl-r: opens a search prompt. Begin typing and the system searches\n",
      "    your history for lines that match what you've typed so far, completing as\n",
      "    much as it can.\n",
      "\n",
      "  - %hist: search history by index.\n",
      "\n",
      "* Persistent command history across sessions.\n",
      "\n",
      "* Logging of input with the ability to save and restore a working session.\n",
      "\n",
      "* System shell with !. Typing !ls will run 'ls' in the current directory.\n",
      "\n",
      "* The reload command does a 'deep' reload of a module: changes made to the\n",
      "  module since you imported will actually be available without having to exit.\n",
      "\n",
      "* Verbose and colored exception traceback printouts. See the magic xmode and\n",
      "  xcolor functions for details (just type %magic).\n",
      "\n",
      "* Input caching system:\n",
      "\n",
      "  IPython offers numbered prompts (In/Out) with input and output caching. All\n",
      "  input is saved and can be retrieved as variables (besides the usual arrow\n",
      "  key recall).\n",
      "\n",
      "  The following GLOBAL variables always exist (so don't overwrite them!):\n",
      "  _i: stores previous input.\n",
      "  _ii: next previous.\n",
      "  _iii: next-next previous.\n",
      "  _ih : a list of all input _ih[n] is the input from line n.\n",
      "\n",
      "  Additionally, global variables named _i<n> are dynamically created (<n>\n",
      "  being the prompt counter), such that _i<n> == _ih[<n>]\n",
      "\n",
      "  For example, what you typed at prompt 14 is available as _i14 and _ih[14].\n",
      "\n",
      "  You can create macros which contain multiple input lines from this history,\n",
      "  for later re-execution, with the %macro function.\n",
      "\n",
      "  The history function %hist allows you to see any part of your input history\n",
      "  by printing a range of the _i variables. Note that inputs which contain\n",
      "  magic functions (%) appear in the history with a prepended comment. This is\n",
      "  because they aren't really valid Python code, so you can't exec them.\n",
      "\n",
      "* Output caching system:\n",
      "\n",
      "  For output that is returned from actions, a system similar to the input\n",
      "  cache exists but using _ instead of _i. Only actions that produce a result\n",
      "  (NOT assignments, for example) are cached. If you are familiar with\n",
      "  Mathematica, IPython's _ variables behave exactly like Mathematica's %\n",
      "  variables.\n",
      "\n",
      "  The following GLOBAL variables always exist (so don't overwrite them!):\n",
      "  _ (one underscore): previous output.\n",
      "  __ (two underscores): next previous.\n",
      "  ___ (three underscores): next-next previous.\n",
      "\n",
      "  Global variables named _<n> are dynamically created (<n> being the prompt\n",
      "  counter), such that the result of output <n> is always available as _<n>.\n",
      "\n",
      "  Finally, a global dictionary named _oh exists with entries for all lines\n",
      "  which generated output.\n",
      "\n",
      "* Directory history:\n",
      "\n",
      "  Your history of visited directories is kept in the global list _dh, and the\n",
      "  magic %cd command can be used to go to any entry in that list.\n",
      "\n",
      "* Auto-parentheses and auto-quotes (adapted from Nathan Gray's LazyPython)\n",
      "\n",
      "  1. Auto-parentheses\n",
      "        \n",
      "     Callable objects (i.e. functions, methods, etc) can be invoked like\n",
      "     this (notice the commas between the arguments)::\n",
      "       \n",
      "         In [1]: callable_ob arg1, arg2, arg3\n",
      "       \n",
      "     and the input will be translated to this::\n",
      "       \n",
      "         callable_ob(arg1, arg2, arg3)\n",
      "       \n",
      "     This feature is off by default (in rare cases it can produce\n",
      "     undesirable side-effects), but you can activate it at the command-line\n",
      "     by starting IPython with `--autocall 1`, set it permanently in your\n",
      "     configuration file, or turn on at runtime with `%autocall 1`.\n",
      "\n",
      "     You can force auto-parentheses by using '/' as the first character\n",
      "     of a line.  For example::\n",
      "       \n",
      "          In [1]: /globals             # becomes 'globals()'\n",
      "       \n",
      "     Note that the '/' MUST be the first character on the line!  This\n",
      "     won't work::\n",
      "       \n",
      "          In [2]: print /globals    # syntax error\n",
      "\n",
      "     In most cases the automatic algorithm should work, so you should\n",
      "     rarely need to explicitly invoke /. One notable exception is if you\n",
      "     are trying to call a function with a list of tuples as arguments (the\n",
      "     parenthesis will confuse IPython)::\n",
      "       \n",
      "          In [1]: zip (1,2,3),(4,5,6)  # won't work\n",
      "       \n",
      "     but this will work::\n",
      "       \n",
      "          In [2]: /zip (1,2,3),(4,5,6)\n",
      "          ------> zip ((1,2,3),(4,5,6))\n",
      "          Out[2]= [(1, 4), (2, 5), (3, 6)]\n",
      "\n",
      "     IPython tells you that it has altered your command line by\n",
      "     displaying the new command line preceded by -->.  e.g.::\n",
      "       \n",
      "          In [18]: callable list\n",
      "          -------> callable (list)\n",
      "\n",
      "  2. Auto-Quoting\n",
      "    \n",
      "     You can force auto-quoting of a function's arguments by using ',' as\n",
      "     the first character of a line.  For example::\n",
      "       \n",
      "          In [1]: ,my_function /home/me   # becomes my_function(\"/home/me\")\n",
      "\n",
      "     If you use ';' instead, the whole argument is quoted as a single\n",
      "     string (while ',' splits on whitespace)::\n",
      "       \n",
      "          In [2]: ,my_function a b c   # becomes my_function(\"a\",\"b\",\"c\")\n",
      "          In [3]: ;my_function a b c   # becomes my_function(\"a b c\")\n",
      "\n",
      "     Note that the ',' MUST be the first character on the line!  This\n",
      "     won't work::\n",
      "       \n",
      "          In [4]: x = ,my_function /home/me    # syntax error\n"
     ]
    }
   ],
   "source": [
    "ex = torch.randn(18, 3, 32, 32)\n",
    "xy_grid = coordinate_channels(ex.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 2, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "print(xy_grid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0000, 0.7071, 0.8944, 0.9487, 0.9701, 0.9806, 0.9864, 0.9899, 0.9923,\n",
      "        0.9939, 0.9950, 0.9959, 0.9965, 0.9971, 0.9975, 0.9978, 0.9981, 0.9983,\n",
      "        0.9985, 0.9986, 0.9988, 0.9989, 0.9990, 0.9991, 0.9991, 0.9992, 0.9993,\n",
      "        0.9993, 0.9994, 0.9994, 0.9994, 0.9995])\n"
     ]
    }
   ],
   "source": [
    "print(xy_grid[-1, -1, 1, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch normalization + transposed convolutional layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.BatchNorm2d"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
