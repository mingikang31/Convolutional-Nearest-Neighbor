{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef908e60",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4caa1e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "\n",
    "def parse_training_results(file_path):\n",
    "    \"\"\"Parse training results from text file into a pandas DataFrame\"\"\"\n",
    "    \n",
    "    # Read the file\n",
    "    with open(file_path, 'r') as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    # Initialize lists to store data\n",
    "    epochs = []\n",
    "    times = []\n",
    "    train_losses = []\n",
    "    train_acc_top1 = []\n",
    "    train_acc_top5 = []\n",
    "    test_losses = []\n",
    "    test_acc_top1 = []\n",
    "    test_acc_top5 = []\n",
    "    \n",
    "    # Regular expression to match each epoch line\n",
    "    pattern = r'\\[Epoch (\\d+)\\] Time: ([\\d.]+)s.*?Train.*?Loss: ([\\d.]+).*?Top1: ([\\d.]+)%.*?Top5: ([\\d.]+)%.*?Test.*?Loss: ([\\d.]+).*?Top1: ([\\d.]+)%.*?Top5: ([\\d.]+)%'\n",
    "    \n",
    "    # Find all matches\n",
    "    matches = re.findall(pattern, content)\n",
    "    \n",
    "    for match in matches:\n",
    "        epochs.append(int(match[0]))\n",
    "        times.append(float(match[1]))\n",
    "        train_losses.append(float(match[2]))\n",
    "        train_acc_top1.append(float(match[3]))\n",
    "        train_acc_top5.append(float(match[4]))\n",
    "        test_losses.append(float(match[5]))\n",
    "        test_acc_top1.append(float(match[6]))\n",
    "        test_acc_top5.append(float(match[7]))\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'epoch': epochs,\n",
    "        'time': times,\n",
    "        'train_loss': train_losses,\n",
    "        'train_accuracy_top1': train_acc_top1,\n",
    "        'train_accuracy_top5': train_acc_top5,\n",
    "        'test_loss': test_losses,\n",
    "        'test_accuracy_top1': test_acc_top1,\n",
    "        'test_accuracy_top5': test_acc_top5\n",
    "    })\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def n_last_average_stats(df, last_n_epochs=5):\n",
    "    \"\"\"Calculate average stats over the last N epochs\"\"\"\n",
    "    if len(df) < last_n_epochs:\n",
    "        last_n_epochs = len(df)\n",
    "    \n",
    "    return {\n",
    "        \"ave_train_loss\": df['train_loss'].tail(last_n_epochs).mean(),\n",
    "        \"ave_test_loss\": df['test_loss'].tail(last_n_epochs).mean(),\n",
    "        \"ave_train_accuracy_top1\": df['train_accuracy_top1'].tail(last_n_epochs).mean(),\n",
    "        \"ave_train_accuracy_top5\": df['train_accuracy_top5'].tail(last_n_epochs).mean(),\n",
    "        \"ave_test_accuracy_top1\": df['test_accuracy_top1'].tail(last_n_epochs).mean(),\n",
    "        \"ave_test_accuracy_top5\": df['test_accuracy_top5'].tail(last_n_epochs).mean()\n",
    "    }\n",
    "\n",
    "def best_stats(df):\n",
    "    \"\"\"Calculate best accuracy achieved during training\"\"\"\n",
    "    return {\n",
    "        \"best_train_accuracy_top1\": df['train_accuracy_top1'].max(),\n",
    "        \"best_train_accuracy_top5\": df['train_accuracy_top5'].max(),\n",
    "        \"best_test_accuracy_top1\": df['test_accuracy_top1'].max(),\n",
    "        \"best_test_accuracy_top5\": df['test_accuracy_top5'].max()\n",
    "    }\n",
    "\n",
    "def parse_params_gflops(file_dir):\n",
    "    \"\"\"Parse training results from text file into a pandas DataFrame\"\"\"\n",
    "\n",
    "    train_path = os.path.join(file_dir, \"train_eval_results.txt\")\n",
    "    args_path = os.path.join(file_dir, \"args.txt\")\n",
    "    \n",
    "    # Read the file\n",
    "    with open(train_path, 'r') as f:\n",
    "        train_content = f.readline()\n",
    "\n",
    "    with open(args_path, 'r') as f:\n",
    "        args_content = f.readlines()\n",
    "\n",
    "    total_params = args_content[-2].strip().split(\": \")[1]\n",
    "    trainable_params = args_content[-1].strip().split(\": \")[1]\n",
    "\n",
    "    gflops = re.search(r'GFLOPs: ([\\d.]+)', train_content).group(1)\n",
    "\n",
    "    return {\n",
    "        \"total_params\": int(total_params),\n",
    "        \"trainable_params\": int(trainable_params),\n",
    "        \"gflops\": float(gflops)\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22020ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Directory: /Users/mingikang/Developer/Convolutional-Nearest-Neighbor/Final_Output/N_test_cos\n",
      "Root Directory: /Users/mingikang/Developer/Convolutional-Nearest-Neighbor\n"
     ]
    }
   ],
   "source": [
    "import sys \n",
    "import os\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "\n",
    "curr_dir = os.getcwd()\n",
    "root_dir = os.path.abspath(os.path.join(curr_dir, '..', '..'))\n",
    "\n",
    "print(\"Current Directory:\", curr_dir)\n",
    "print(\"Root Directory:\", root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d5318c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Model        Dataset    Type   N  BestAcc    AvgAcc  TotalParams  \\\n",
      "0  ConvNN  VGG11-CIFAR10  random   4  59.2969  58.07030    130015690   \n",
      "1  ConvNN  VGG11-CIFAR10  random   6  57.6074  57.11914    130015690   \n",
      "2  ConvNN  VGG11-CIFAR10  random   8  57.4805  56.76760    130015690   \n",
      "3  ConvNN  VGG11-CIFAR10  random  10  57.5098  56.29102    130015690   \n",
      "4  ConvNN  VGG11-CIFAR10  random  12  57.0020  56.33398    130015690   \n",
      "\n",
      "   TrainableParams    GFLOPs  \n",
      "0        130015690  0.297096  \n",
      "1        130015690  0.300706  \n",
      "2        130015690  0.304211  \n",
      "3        130015690  0.308719  \n",
      "4        130015690  0.310849  \n"
     ]
    }
   ],
   "source": [
    "datasets = [\"VGG11-CIFAR10\", \"VGG11-CIFAR100\"]\n",
    "bratio = [\"1000\", \"0500\"]\n",
    "type = [\"random\", \"spatial\"]\n",
    "Ns = [\"4\", \"6\", \"8\", \"10\", \"12\", \"14\", \"16\", \"18\", \"20\", \"22\", \"24\", \"26\", \"28\", \"30\", \"32\"]\n",
    "rows = []\n",
    "for ds in datasets: \n",
    "    for br in bratio:\n",
    "        for t in type:\n",
    "            for n in Ns:\n",
    "\n",
    "                model_name = f\"BranchingConvNN_{t}_NS{n}_col_col_br{br}_s42\"\n",
    "                model_path = os.path.join(curr_dir, ds, model_name, \"train_eval_results.txt\")\n",
    "\n",
    "\n",
    "                df = parse_training_results(model_path)\n",
    "                avg_stats = n_last_average_stats(df, last_n_epochs=5)\n",
    "                best_acc = best_stats(df)\n",
    "\n",
    "                gflops_path = os.path.join(curr_dir, ds, model_name)\n",
    "                gflops = parse_params_gflops(gflops_path)\n",
    "                \n",
    "                if br == \"1000\":\n",
    "                    model = \"ConvNN\"\n",
    "                else: \n",
    "                    model = \"Branching\"\n",
    "    \n",
    "                rows.append({\n",
    "                    \"Model\": model, \n",
    "                    \"Dataset\": ds,\n",
    "                    \"Type\": t,\n",
    "                    \"N\": int(n),\n",
    "                    \"BestAcc\": best_acc[\"best_test_accuracy_top1\"],\n",
    "                    \"AvgAcc\": avg_stats[\"ave_test_accuracy_top1\"],\n",
    "                    \"TotalParams\": gflops[\"total_params\"],\n",
    "                    \"TrainableParams\": gflops[\"trainable_params\"],\n",
    "                    \"GFLOPs\": gflops[\"gflops\"]\n",
    "                })\n",
    "\n",
    "\n",
    "conv_cifar10 = \"/Users/mingikang/Developer/Convolutional-Nearest-Neighbor/Final_Output/loss_test_cos_first**/VGG11-CIFAR10/lr_1e-4/BranchingConvNN_K9_col_col_br0000_s42/train_eval_results.txt\"\n",
    "\n",
    "conv_cifar100 = \"/Users/mingikang/Developer/Convolutional-Nearest-Neighbor/Final_Output/loss_test_cos_first**/VGG11-CIFAR100/lr_1e-4/BranchingConvNN_K9_col_col_br0000_s42/train_eval_results.txt\"\n",
    "\n",
    "branching_cifar10 = \"/Users/mingikang/Developer/Convolutional-Nearest-Neighbor/Final_Output/loss_test_cos_first**/VGG11-CIFAR10/lr_1e-4/BranchingConvNN_K9_col_col_br0500_s42/train_eval_results.txt\"\n",
    "branching_cifar100 = \"/Users/mingikang/Developer/Convolutional-Nearest-Neighbor/Final_Output/loss_test_cos_first**/VGG11-CIFAR100/lr_1e-4/BranchingConvNN_K9_col_col_br0500_s42/train_eval_results.txt\"\n",
    "\n",
    "convnn_cifar10 = \"/Users/mingikang/Developer/Convolutional-Nearest-Neighbor/Final_Output/loss_test_cos_first**/VGG11-CIFAR10/lr_1e-4/BranchingConvNN_K9_col_col_br1000_s42/train_eval_results.txt\"\n",
    "\n",
    "convnn_cifar100 = \"/Users/mingikang/Developer/Convolutional-Nearest-Neighbor/Final_Output/loss_test_cos_first**/VGG11-CIFAR100/lr_1e-4/BranchingConvNN_K9_col_col_br1000_s42/train_eval_results.txt\"\n",
    "\n",
    "conv_cifar10_df = parse_training_results(conv_cifar10)\n",
    "conv_cifar100_df = parse_training_results(conv_cifar100)\n",
    "branching_cifar10_df = parse_training_results(branching_cifar10)\n",
    "branching_cifar100_df = parse_training_results(branching_cifar100)\n",
    "convnn_cifar10_df = parse_training_results(convnn_cifar10)\n",
    "convnn_cifar100_df = parse_training_results(convnn_cifar100)\n",
    "\n",
    "conv_cifar10_best = best_stats(conv_cifar10_df)\n",
    "conv_cifar100_best = best_stats(conv_cifar100_df)\n",
    "branching_cifar10_best = best_stats(branching_cifar10_df)\n",
    "branching_cifar100_best = best_stats(branching_cifar100_df)\n",
    "convnn_cifar10_best = best_stats(convnn_cifar10_df)\n",
    "convnn_cifar100_best = best_stats(convnn_cifar100_df)\n",
    "\n",
    "\n",
    "conv_cifar10_avg = n_last_average_stats(conv_cifar10_df, last_n_epochs=5)\n",
    "conv_cifar100_avg = n_last_average_stats(conv_cifar100_df, last_n_epochs=5)\n",
    "branching_cifar10_avg = n_last_average_stats(branching_cifar10_df, last_n_epochs=5)\n",
    "branching_cifar100_avg = n_last_average_stats(branching_cifar100_df, last_n_epochs=5)\n",
    "convnn_cifar10_avg = n_last_average_stats(convnn_cifar10_df, last_n_epochs=5)\n",
    "convnn_cifar100_avg = n_last_average_stats(convnn_cifar100_df, last_n_epochs=5)\n",
    "\n",
    "\n",
    "# Gflops \n",
    "\n",
    "conv_cifar10 = \"/Users/mingikang/Developer/Convolutional-Nearest-Neighbor/Final_Output/loss_test_cos_first**/VGG11-CIFAR10/lr_1e-4/BranchingConvNN_K9_col_col_br0000_s42/\"\n",
    "\n",
    "conv_cifar100 = \"/Users/mingikang/Developer/Convolutional-Nearest-Neighbor/Final_Output/loss_test_cos_first**/VGG11-CIFAR100/lr_1e-4/BranchingConvNN_K9_col_col_br0000_s42/\"\n",
    "\n",
    "branching_cifar10 = \"/Users/mingikang/Developer/Convolutional-Nearest-Neighbor/Final_Output/loss_test_cos_first**/VGG11-CIFAR10/lr_1e-4/BranchingConvNN_K9_col_col_br0500_s42/\"\n",
    "branching_cifar100 = \"/Users/mingikang/Developer/Convolutional-Nearest-Neighbor/Final_Output/loss_test_cos_first**/VGG11-CIFAR100/lr_1e-4/BranchingConvNN_K9_col_col_br0500_s42/\"\n",
    "\n",
    "convnn_cifar10 = \"/Users/mingikang/Developer/Convolutional-Nearest-Neighbor/Final_Output/loss_test_cos_first**/VGG11-CIFAR10/lr_1e-4/BranchingConvNN_K9_col_col_br1000_s42/\"\n",
    "\n",
    "convnn_cifar100 = \"/Users/mingikang/Developer/Convolutional-Nearest-Neighbor/Final_Output/loss_test_cos_first**/VGG11-CIFAR100/lr_1e-4/BranchingConvNN_K9_col_col_br1000_s42/\"\n",
    "\n",
    "conv_cifar10_gflops = parse_params_gflops(conv_cifar10)\n",
    "conv_cifar100_gflops = parse_params_gflops(conv_cifar100)\n",
    "branching_cifar10_gflops = parse_params_gflops(branching_cifar10)\n",
    "branching_cifar100_gflops = parse_params_gflops(branching_cifar100)\n",
    "convnn_cifar10_gflops = parse_params_gflops(convnn_cifar10)\n",
    "convnn_cifar100_gflops = parse_params_gflops(convnn_cifar100)\n",
    "\n",
    "\n",
    "rows.append({\n",
    "    \"Model\": \"Convolution\", \n",
    "    \"Dataset\": \"VGG11-CIFAR10\",\n",
    "    \"Type\": \"baseline\",\n",
    "    \"N\": 0,\n",
    "    \"BestAcc\": conv_cifar10_best[\"best_test_accuracy_top1\"],\n",
    "    \"AvgAcc\": conv_cifar10_avg[\"ave_test_accuracy_top1\"],\n",
    "    \"TotalParams\": conv_cifar10_gflops[\"total_params\"],\n",
    "    \"TrainableParams\": conv_cifar10_gflops[\"trainable_params\"],\n",
    "    \"GFLOPs\": conv_cifar10_gflops[\"gflops\"]\n",
    "})\n",
    "\n",
    "rows.append({\n",
    "    \"Model\": \"Convolution\", \n",
    "    \"Dataset\": \"VGG11-CIFAR100\",\n",
    "    \"Type\": \"baseline\",\n",
    "    \"N\": 0,\n",
    "    \"BestAcc\": conv_cifar100_best[\"best_test_accuracy_top1\"],\n",
    "    \"AvgAcc\": conv_cifar100_avg[\"ave_test_accuracy_top1\"],\n",
    "    \"TotalParams\": conv_cifar100_gflops[\"total_params\"],\n",
    "    \"TrainableParams\": conv_cifar100_gflops[\"trainable_params\"],\n",
    "    \"GFLOPs\": conv_cifar100_gflops[\"gflops\"]\n",
    "})\n",
    "\n",
    "\n",
    "rows.append({\n",
    "    \"Model\": \"ConvNN\", \n",
    "    \"Dataset\": \"VGG11-CIFAR10\",\n",
    "    \"Type\": \"all\",\n",
    "    \"N\": -1,\n",
    "    \"BestAcc\": convnn_cifar10_best[\"best_test_accuracy_top1\"],\n",
    "    \"AvgAcc\": convnn_cifar10_avg[\"ave_test_accuracy_top1\"],\n",
    "    \"TotalParams\": convnn_cifar10_gflops[\"total_params\"],\n",
    "    \"TrainableParams\": convnn_cifar10_gflops[\"trainable_params\"],\n",
    "    \"GFLOPs\": convnn_cifar10_gflops[\"gflops\"]\n",
    "})\n",
    "\n",
    "rows.append({\n",
    "    \"Model\": \"ConvNN\", \n",
    "    \"Dataset\": \"VGG11-CIFAR100\",\n",
    "    \"Type\": \"all\",\n",
    "    \"N\": -1,\n",
    "    \"BestAcc\": convnn_cifar100_best[\"best_test_accuracy_top1\"],\n",
    "    \"AvgAcc\": convnn_cifar100_avg[\"ave_test_accuracy_top1\"],\n",
    "    \"TotalParams\": convnn_cifar100_gflops[\"total_params\"],\n",
    "    \"TrainableParams\": convnn_cifar100_gflops[\"trainable_params\"],\n",
    "    \"GFLOPs\": convnn_cifar100_gflops[\"gflops\"]\n",
    "})\n",
    "\n",
    "\n",
    "rows.append({\n",
    "    \"Model\": \"Branching\", \n",
    "    \"Dataset\": \"VGG11-CIFAR10\",\n",
    "    \"Type\": \"all\",\n",
    "    \"N\": -1,\n",
    "    \"BestAcc\": branching_cifar10_best[\"best_test_accuracy_top1\"],\n",
    "    \"AvgAcc\": branching_cifar10_avg[\"ave_test_accuracy_top1\"],\n",
    "    \"TotalParams\": branching_cifar10_gflops[\"total_params\"],\n",
    "    \"TrainableParams\": branching_cifar10_gflops[\"trainable_params\"],\n",
    "    \"GFLOPs\": branching_cifar10_gflops[\"gflops\"]\n",
    "})\n",
    "\n",
    "rows.append({\n",
    "    \"Model\": \"Branching\", \n",
    "    \"Dataset\": \"VGG11-CIFAR100\",\n",
    "    \"Type\": \"all\",\n",
    "    \"N\": -1,\n",
    "    \"BestAcc\": branching_cifar100_best[\"best_test_accuracy_top1\"],\n",
    "    \"AvgAcc\": branching_cifar100_avg[\"ave_test_accuracy_top1\"],\n",
    "    \"TotalParams\": branching_cifar100_gflops[\"total_params\"],\n",
    "    \"TrainableParams\": branching_cifar100_gflops[\"trainable_params\"],\n",
    "    \"GFLOPs\": branching_cifar100_gflops[\"gflops\"]\n",
    "})\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame(rows)\n",
    "results_df.to_csv(os.path.join(curr_dir, \"N_test_cos_results.csv\"), index=False)\n",
    "print(results_df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f892163",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"/Users/mingikang/Developer/Convolutional-Nearest-Neighbor/Final_Output/N_test_cos/\"\n",
    "\n",
    "\n",
    "# os.joinpath(base_path, dataset, f\"BranchingConvNN_random_NS{N}_col_col_br{b}_s42\", \"training_results.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28da1159",
   "metadata": {},
   "source": [
    "## Gflops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "077ab598",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_params_gflops(file_dir):\n",
    "    \"\"\"Parse training results from text file into a pandas DataFrame\"\"\"\n",
    "\n",
    "    train_path = os.path.join(file_dir, \"train_eval_results.txt\")\n",
    "    args_path = os.path.join(file_dir, \"args.txt\")\n",
    "    \n",
    "    # Read the file\n",
    "    with open(train_path, 'r') as f:\n",
    "        train_content = f.readline()\n",
    "\n",
    "    with open(args_path, 'r') as f:\n",
    "        args_content = f.readlines()\n",
    "\n",
    "    total_params = args_content[-2].strip().split(\": \")[1]\n",
    "    trainable_params = args_content[-1].strip().split(\": \")[1]\n",
    "\n",
    "    gflops = re.search(r'GFLOPs: ([\\d.]+)', train_content).group(1)\n",
    "\n",
    "    return {\n",
    "        \"total_params\": int(total_params),\n",
    "        \"trainable_params\": int(trainable_params),\n",
    "        \"gflops\": float(gflops)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf07d8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
